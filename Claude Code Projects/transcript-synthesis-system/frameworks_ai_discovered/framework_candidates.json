[
  {
    "name": "AI Workflow Implementation Framework",
    "type": "process_framework",
    "confidence": 0.98,
    "description": "A phased methodology for identifying, evaluating, and implementing AI-enhanced workflows in organizations, moving from discovery through to rollout",
    "components": [
      "Discovery Phase - Comprehensive workflow identification and assessment",
      "Refinement Phase - Detailed pilot planning with business case and MVP definition",
      "Build and Pilot Phase - Prototype development using minimum viable solutions",
      "Rollout and Training Phase - Implementation with change management and training"
    ],
    "evidence_quote": "The next phase I'm calling refinement, which is basically once we say, okay, we've got this list and we've got some that have bubbled to the top, now we have to actually dig in and essentially build what the pilot plan is for this workflow... Then we will actually build and pilot the MVP or the prototype... and then the rollout and the training and the implementation.",
    "source_transcript": "transcripts_normalized/Refining AI Workflows and Strategies for Effective Implementation 2025-08-12 11_09 transcript.json",
    "source_date": "2025-08-12"
  },
  {
    "name": "Refinement Phase Dual-Component Framework",
    "type": "model_framework",
    "confidence": 0.92,
    "description": "Two parallel components required to properly plan an AI workflow pilot before building",
    "components": [
      "Provisional business case - Investment justification for the workflow",
      "Minimum viable solution - Test and prototype specification to validate AI capability"
    ],
    "evidence_quote": "there's two components to that. There's what is the provisional kind of business case to invest behind this workflow? And what is the minimum viable solution to test and prototype whether AI can actually get to the output that the organization or division needs.",
    "source_transcript": "transcripts_normalized/Refining AI Workflows and Strategies for Effective Implementation 2025-08-12 11_09 transcript.json",
    "source_date": "2025-08-12"
  },
  {
    "name": "Pre-Build Discovery Requirements Framework",
    "type": "process_framework",
    "confidence": 0.9,
    "description": "Essential discovery activities that must occur before building AI solutions to ensure proper scoping and pricing",
    "components": [
      "Current workflow documentation - What are they actually doing",
      "Output specification - What's the output and quality bars",
      "Accuracy requirements - What level of accuracy is required",
      "Technical environment assessment - What platforms and tools do they have access to",
      "Skill level evaluation - What's the level of technical skill set or requirement needed"
    ],
    "evidence_quote": "first we just have to do some work. We have to sit down with the person who's doing the RFP process and say, what are they actually doing? What's the output? What are the quality bars that they have? Right. Like, let's talk about what level of accuracy is required... What kind of platforms and tools do they have access to... What's the level of technical, kind of, you know, skill set or requirement that's needed",
    "source_transcript": "transcripts_normalized/Refining AI Workflows and Strategies for Effective Implementation 2025-08-12 11_09 transcript.json",
    "source_date": "2025-08-12"
  },
  {
    "name": "Pricing and Staffing Prerequisites Framework",
    "type": "decision_framework",
    "confidence": 0.88,
    "description": "Logic for determining when an organization has sufficient information to make investment decisions on AI workflow redesign",
    "components": [
      "Vendor needs detailed workflow understanding to price and staff",
      "Client needs cost and output estimates to approve investment",
      "Both depend on refinement phase completion"
    ],
    "evidence_quote": "we need to do that to be able to price it and staff it. And they need that output to know whether they should invest at the cost needed to get the output required.",
    "source_transcript": "transcripts_normalized/Refining AI Workflows and Strategies for Effective Implementation 2025-08-12 11_09 transcript.json",
    "source_date": "2025-08-12"
  },
  {
    "name": "Minimum Viable Prototyping Framework",
    "type": "scaling_framework",
    "confidence": 0.94,
    "description": "Strategy for prototyping AI solutions using low-cost, off-the-shelf tools before investing in custom development",
    "components": [
      "Start with cheapest minimum viable solution",
      "Use off-the-shelf tools (e.g., custom GPTs)",
      "Integrate with low/no-code tools",
      "Validate before building custom applications",
      "Apply same approach internally as recommended to clients"
    ],
    "evidence_quote": "you want to prototype this and the cheapest kind of minimum viable solution that you can. And the benefit of AI is you can do a lot of that using tools that are off the shelf. Even if we think we've found a workflow that needs a custom built application, we would still highly recommend the organization prototype using if they have GPT, custom GPTs, maybe some integrations with other low or no code tools",
    "source_transcript": "transcripts_normalized/Refining AI Workflows and Strategies for Effective Implementation 2025-08-12 11_09 transcript.json",
    "source_date": "2025-08-12"
  },
  {
    "name": "Post-Pilot Decision and Implementation Framework",
    "type": "process_framework",
    "confidence": 0.85,
    "description": "Structured evaluation and implementation process following the pilot phase",
    "components": [
      "30-day pilot execution",
      "Success evaluation - Did this work or not",
      "Training materials preparation",
      "Maintenance documentation for teams",
      "Change management for larger organizations"
    ],
    "evidence_quote": "if we run the 30 day pilot then we have to actually say okay, did this work or did this not? And if it did, here's the training, here's the information that the team needs to maintain the thing that we've built for them or here's, you know, if it's a much larger organization, the change management that has to be done",
    "source_transcript": "transcripts_normalized/Refining AI Workflows and Strategies for Effective Implementation 2025-08-12 11_09 transcript.json",
    "source_date": "2025-08-12"
  },
  {
    "name": "Parallel Work Stream Engagement Framework",
    "type": "engagement_framework",
    "confidence": 0.87,
    "description": "Strategy for selling and delivering multiple related but distinct service offerings simultaneously",
    "components": [
      "Deep dive/transformation plan as separate deliverable",
      "Workflow discovery as parallel work stream",
      "Combined sales approach with separate scopes",
      "Interview efficiency through concurrent execution"
    ],
    "evidence_quote": "There would be two parallel work streams, basically... the scope of the transformation plan or the deep dive stays what it is today... I do think there is value in selling that as what would appear to the client as an integrated process. I understand it's two separate scopes.",
    "source_transcript": "transcripts_normalized/Refining AI Workflows and Strategies for Effective Implementation 2025-08-12 11_09 transcript.json",
    "source_date": "2025-08-12"
  },
  {
    "name": "Common Implementation Gap Framework",
    "type": "decision_framework",
    "confidence": 0.91,
    "description": "Identification of the critical missing step most organizations skip when implementing AI workflows",
    "components": [
      "Organizations typically jump directly to building AI tools",
      "Missing step: Detailed workflow analysis and requirements gathering",
      "Risk: Building solutions without understanding actual needs and constraints",
      "Solution: Insert refinement phase before building"
    ],
    "evidence_quote": "this is like a really important step. And I think we're seeing that it's the step that most organizations are missing, right? They're like, we want to redesign our RFP process, so let's jump right to building the AI tool. And it's like, okay, first we just have to do some work.",
    "source_transcript": "transcripts_normalized/Refining AI Workflows and Strategies for Effective Implementation 2025-08-12 11_09 transcript.json",
    "source_date": "2025-08-12"
  },
  {
    "name": "AI Maturity Deep Dive Process",
    "type": "process_framework",
    "confidence": 0.98,
    "description": "A phased consulting methodology for assessing and implementing AI within client organizations, consisting of assessment, diagnosis, and recommendations phases.",
    "components": [
      "Phase 1: AI Maturity Deep Dive (assessment)",
      "Employee survey across organization",
      "Stakeholder interviews (leadership-focused with employee input)",
      "Initial insights readout (showing strengths/weaknesses with evidence)",
      "Roadmap presentation (customized recommendations and sequencing)"
    ],
    "evidence_quote": "we ideally come into a services client with our AI maturity deep dive... we start off by doing our survey to all employees... And then we do a bunch of interviews that go across leadership and. And some employees as well... So once we do all of that assessment work, we then need to share it with the client. So we do that in two blocks... the first one is... the, like, initial insights readout... All of it to show where they stand... the next deck is our plan or set of recommendations, and that's a roadmap of projects and activities and sequenc that they should take to get ROI from AI.",
    "source_transcript": "transcripts_normalized/Company Lunch & Learn 2025-09-26 13_01 transcript.json",
    "source_date": "2025-09-26"
  },
  {
    "name": "Two-Block Client Deliverable Structure",
    "type": "engagement_framework",
    "confidence": 0.95,
    "description": "A structured approach to presenting assessment findings to clients in two sequential deliverables: diagnostic insights followed by actionable recommendations.",
    "components": [
      "Block 1: Initial insights readout (survey data, interview quotes, strengths/weaknesses analysis)",
      "Block 2: Recommendations roadmap (custom projects, activities, and sequencing for ROI)"
    ],
    "evidence_quote": "we then need to share it with the client. So we do that in two blocks. So the first one is what I'll go through today... that's the, like, initial insights readout. So that's focused on data from. From the survey analysis and then also, like, quotes and insights from the interviews... the next deck is our plan or set of recommendations, and that's a roadmap of projects and activities and sequenc that they should take to get ROI from AI.",
    "source_transcript": "transcripts_normalized/Company Lunch & Learn 2025-09-26 13_01 transcript.json",
    "source_date": "2025-09-26"
  },
  {
    "name": "Stakeholder Interview Prioritization Framework",
    "type": "decision_framework",
    "confidence": 0.9,
    "description": "A strategic approach to interview allocation that prioritizes leadership input for strategy while using surveys to capture broader employee perspectives.",
    "components": [
      "Leadership interviews (strategy and execution ownership)",
      "Employee interviews (bottoms-up use case input)",
      "Employee surveys (broader perspective capture)"
    ],
    "evidence_quote": "we do a bunch of interviews that go across leadership and. And some employees as well. It does tend to skew more towards leaders. And I think that's a good thing because they're kind of setting the strategy and tone and going to be responsible for making a lot of these things happen. And then the employees, we already have a lot of their perspective from. From the survey, but they also give really good, like, bottoms up, use case input.",
    "source_transcript": "transcripts_normalized/Company Lunch & Learn 2025-09-26 13_01 transcript.json",
    "source_date": "2025-09-26"
  },
  {
    "name": "AI Organizational Assessment Model",
    "type": "model_framework",
    "confidence": 0.92,
    "description": "A multi-dimensional assessment model that evaluates both technical proficiency and organizational readiness, revealing potential gaps between capability and implementation effectiveness.",
    "components": [
      "Proficiency measurement (technical skills)",
      "Organizational readiness assessment (leadership, culture, structure)",
      "Culture evaluation (e.g., builder mentality)",
      "Customized category structure based on data findings"
    ],
    "evidence_quote": "when we just measured proficiency, if that's the only data we had, I would have been telling General Catalyst, oh, you guys are great. You guys are really proficient and like, everything's good. But since Taylor Power has been a big driver of this on our team, we have all these great overall readiness questions. There's a huge contrast between they have proficiency, but they have very weak readiness... Structure these like categories and the data behind them... Sometimes we have. But we don't always say like a culture. And that's such a good point for them.",
    "source_transcript": "transcripts_normalized/Company Lunch & Learn 2025-09-26 13_01 transcript.json",
    "source_date": "2025-09-26"
  },
  {
    "name": "Pain-Driven Motivation Framework",
    "type": "engagement_framework",
    "confidence": 0.88,
    "description": "A client engagement approach that uses evidence-based insights to help clients feel organizational pain points and build motivation for transformation.",
    "components": [
      "Present data-backed evidence of strengths and weaknesses",
      "Create awareness of pain points",
      "Build motivation for action",
      "Transition to solution recommendations"
    ],
    "evidence_quote": "All of it to show where they stand. So where are they strong and where are they weak with, like, evidence behind it and get them feeling the pain and motivated to take action. Which then transitions in the next deck, which I'm not gonna walk through, but the next deck is our plan or set of recommendations",
    "source_transcript": "transcripts_normalized/Company Lunch & Learn 2025-09-26 13_01 transcript.json",
    "source_date": "2025-09-26"
  },
  {
    "name": "Product Documentation Development Process",
    "type": "process_framework",
    "confidence": 0.98,
    "description": "A sequential workflow for moving from product discovery to engineering execution through structured documentation stages",
    "components": [
      "Discovery (from clients, products team, or operations)",
      "Brief creation in Notion (high-level summary)",
      "Prioritization evaluation",
      "PRD creation (detailed product requirements document)",
      "Requirement transposition to JIRA user stories",
      "Engineering execution"
    ],
    "evidence_quote": "I think we have, you know, a fairly standard process when it comes to starting with discovery... Then it is on someone... needs to write a document... we call it a brief... then that eventually if we want to actually build something, we would use that notion brief and link it to our JIRA system... We would do a prioritization process... then we begin what is like a full blown prd... those requirements are transposed back into jira",
    "source_transcript": "transcripts_normalized/PRD Use Case Discussion 2025-10-03 15_01 transcript.json",
    "source_date": "2025-10-03"
  },
  {
    "name": "Document-to-Engineering Translation Model",
    "type": "model_framework",
    "confidence": 0.92,
    "description": "A two-system model separating human-readable documentation from engineering task management",
    "components": [
      "Notion layer (human language documentation - briefs and PRDs)",
      "JIRA layer (engineering workflows and user stories)",
      "Manual transposition bridge between systems"
    ],
    "evidence_quote": "So we're kind of bouncing between Notion and JIRA here with documents in Notion engineering tasks in jira... those requirements in the requirements document essentially have to be transposed into user stories in JIRA",
    "source_transcript": "transcripts_normalized/PRD Use Case Discussion 2025-10-03 15_01 transcript.json",
    "source_date": "2025-10-03"
  },
  {
    "name": "Prioritization Gate Decision Framework",
    "type": "decision_framework",
    "confidence": 0.87,
    "description": "A go/no-go decision point that determines whether discovery moves forward to full PRD development",
    "components": [
      "Evaluation criterion: sufficient information availability",
      "Binary decision: Yes (proceed to PRD) or No (return/defer)",
      "Decision occurs after brief creation, before PRD development"
    ],
    "evidence_quote": "We would do a prioritization process on that to evaluate, okay, do we have enough information here to, to go work on this? And we would say at that point, yes or no. And assuming we're in the yes case, then, then we begin what is like a full blown prd",
    "source_transcript": "transcripts_normalized/PRD Use Case Discussion 2025-10-03 15_01 transcript.json",
    "source_date": "2025-10-03"
  },
  {
    "name": "Audience Transformation Framework",
    "type": "process_framework",
    "confidence": 0.85,
    "description": "A methodology for translating requirements between different stakeholder perspectives",
    "components": [
      "Business requirement format (what the business needs)",
      "User story format (what the end user expects)",
      "Perspective shift from business to user voice"
    ],
    "evidence_quote": "sometimes I say like here's the requirement and it's written more as like a business requirement, what the business needs and then sometimes we have to rewrite that as like the actual user of the technology, what they expect... So as an expert, I. I expect to do this and this with my expert workspace tool",
    "source_transcript": "transcripts_normalized/PRD Use Case Discussion 2025-10-03 15_01 transcript.json",
    "source_date": "2025-10-03"
  },
  {
    "name": "AI-Enhanced Workflow Standardization Framework",
    "type": "scaling_framework",
    "confidence": 0.9,
    "description": "A proposed approach to standardize AI usage across the product documentation process",
    "components": [
      "Universal AI tool adoption (ChatGPT/Claude)",
      "Standardized processes for AI-assisted brief writing",
      "Standardized prompts and inputs",
      "Three identified intervention points for AI integration"
    ],
    "evidence_quote": "in an ideal future state, Everybody is using ChatGPT or Cloud or whatever ultimate tool that you decide to support them in their process... I think that what this sounds like is there are. I'm seeing like at least three clear places where you could have some standardization of what is the process of doing this thing with AI",
    "source_transcript": "transcripts_normalized/PRD Use Case Discussion 2025-10-03 15_01 transcript.json",
    "source_date": "2025-10-03"
  },
  {
    "name": "Three-Point Optimization Framework",
    "type": "model_framework",
    "confidence": 0.93,
    "description": "A model identifying three key intervention opportunities in the documentation workflow",
    "components": [
      "Automating PRD creation",
      "Automating product brief creation",
      "Minimizing manual transposition between Notion and JIRA"
    ],
    "evidence_quote": "And then I think the big issues are, or the big opportunities are automating the creation of the PRDs, the creation of the product briefs and then potentially minimizing the need to transpose the written document into the user stories",
    "source_transcript": "transcripts_normalized/PRD Use Case Discussion 2025-10-03 15_01 transcript.json",
    "source_date": "2025-10-03"
  },
  {
    "name": "Competitive Feature Synthesis Framework",
    "type": "model_framework",
    "confidence": 0.92,
    "description": "A model for building product features by extracting and combining the best capabilities from multiple competitors rather than copying any single one",
    "components": [
      "Plus AI: Usability and ease of use",
      "Present: Templates and visuals",
      "Genspark: Prompting and collaborative thinking experience",
      "LA: Prompting capabilities (to be shortened)"
    ],
    "evidence_quote": "Plus AI has the experience in terms of usability and ease of use, but Present has the templates that we would like, the visuals. Genspark has the prompting experience we would like to a small degree. I still want ours to be a little bit collaborative and interactive.",
    "source_transcript": "transcripts_normalized/igk-srzo-vax summary 2025-09-11 16_40 transcript.json",
    "source_date": "2025-09-11"
  },
  {
    "name": "Journey-Based Feature Prioritization Framework",
    "type": "process_framework",
    "confidence": 0.89,
    "description": "A methodology for determining product features by first mapping the complete user journey, then prioritizing features based on that journey rather than starting with isolated features",
    "components": [
      "Map the complete journey experience ('put the world on a page')",
      "Identify all possible features (50-100 features)",
      "Prioritize features from the full set",
      "Start with prioritized subset (e.g., 40 features)"
    ],
    "evidence_quote": "I like something you described two weeks ago where so in the journey phase in my mind, tell me if this makes sense. Like we put the world on a page. Like we say this is the journey experience and then we prioritize. Right. So that journey tells us then you're going to have 50 features, 100 features, and it's okay, we're starting with this 40.",
    "source_transcript": "transcripts_normalized/igk-srzo-vax summary 2025-09-11 16_40 transcript.json",
    "source_date": "2025-09-11"
  },
  {
    "name": "Collaborative AI-Human Deck Creation Process",
    "type": "process_framework",
    "confidence": 0.88,
    "description": "An iterative, conversational approach to presentation creation where AI guides users through deck preparation rather than requiring complete upfront specifications",
    "components": [
      "User provides initial high-level prompt (e.g., topic/goal)",
      "AI proposes structure and pages (e.g., 'page one to ten')",
      "User provides feedback on proposal",
      "Collaborative iteration between AI, user, and team members",
      "AI helps develop thinking and story structure throughout"
    ],
    "evidence_quote": "it's not necessarily just spitting out the content. He's working with you to say, okay, you know, and it's even helping you think. Like, it's like, all right, what are you trying to do? And I can say something like, hey, I'm trying to build a deck that tells me about the opportunities in pest control. It's like, oh, yeah, that's a great idea. In the past. Here's what I think you need to be thinking about page one to ten. What do you think about that? And then I give you feedback.",
    "source_transcript": "transcripts_normalized/igk-srzo-vax summary 2025-09-11 16_40 transcript.json",
    "source_date": "2025-09-11"
  },
  {
    "name": "Dual-Track Validation Framework",
    "type": "process_framework",
    "confidence": 0.85,
    "description": "A parallel approach to product development where internal prototyping proceeds alongside external customer validation without blocking each other",
    "components": [
      "Internal team develops feature list and priorities",
      "Create prototype based on internal intuition",
      "Simultaneously conduct customer interviews for validation",
      "Use informal network for quick feedback rounds",
      "Iterate based on combined internal and external input"
    ],
    "evidence_quote": "I think once we have that list, what we could do is at least I have, between Karen and I, unless we have a small network of like companies we can just. I, it would just be very informal, just people that make debts, like consultants or whatever. And to say let's go through this, like how do you, you know what makes sense?",
    "source_transcript": "transcripts_normalized/igk-srzo-vax summary 2025-09-11 16_40 transcript.json",
    "source_date": "2025-09-11"
  },
  {
    "name": "Enterprise Deck Output Framework",
    "type": "model_framework",
    "confidence": 0.87,
    "description": "A multi-component output model for presentation tools that addresses the full enterprise use case beyond just slides",
    "components": [
      "Slide content (visual presentation)",
      "Presenter notes (guidance for speakers)",
      "Key takeaways (summary for stakeholders)",
      "Coherent narrative structure"
    ],
    "evidence_quote": "Number one is what presenter notes. Like, so the way PowerPoint is most people want to put up presenter notes and most people are making decks for other people. Right. And they try to put their presenter notes in there, but it really doesn't. Most people don't use that functionality. If we can have that part as part of this, where it's like the presenter notes also is an output that this is producing and it's like putting it in there, that's a huge advantage",
    "source_transcript": "transcripts_normalized/igk-srzo-vax summary 2025-09-11 16_40 transcript.json",
    "source_date": "2025-09-11"
  },
  {
    "name": "Low-Friction Input Principle",
    "type": "decision_framework",
    "confidence": 0.86,
    "description": "A design principle that prioritizes minimal upfront input requirements because users typically don't know their complete requirements at the start",
    "components": [
      "Reduce initial input requirements",
      "Allow for emergent understanding during process",
      "Contrast with competitors requiring 'colossal' upfront prompts",
      "Enable iterative refinement"
    ],
    "evidence_quote": "One of the things that all these other platforms don't do well is they require the input to be a lot from the beginning. But most people doing decks don't actually know what they're going to do once they start the deck.",
    "source_transcript": "transcripts_normalized/igk-srzo-vax summary 2025-09-11 16_40 transcript.json",
    "source_date": "2025-09-11"
  },
  {
    "name": "Workshop Profitability Model",
    "type": "model_framework",
    "confidence": 0.9,
    "description": "A cost structure model for workshop delivery that distinguishes between one-time fixed costs and recurring delivery costs to assess long-term profitability",
    "components": [
      "Upfront fixed costs (content creation, internal team time)",
      "Recurring delivery costs (instructor payments at set rates)",
      "Content refresh costs (quarterly or monthly updates)",
      "Recruitment costs (bringing in 2-3 more instructors)",
      "Cost depreciation across workshop lifetime"
    ],
    "evidence_quote": "It's really just thinking what is the upfront work going to be for our internal team to create the content? Because again if we're not doing any customizations, that is a one time fixed cost that will be, you know, depreciated across the lifetime.",
    "source_transcript": "transcripts_normalized/OpenAI Brief Brainstorm 2025-10-23 16_29 transcript.json",
    "source_date": "2025-10-23"
  },
  {
    "name": "Instructor Talent Acquisition Decision Framework",
    "type": "decision_framework",
    "confidence": 0.88,
    "description": "A decision logic for choosing between inbound vs outbound recruitment and determining whether to upskill lecturers in AI or AI experts in lecturing",
    "components": [
      "IF doing outbound recruitment THEN face quality/vetting challenges",
      "IF doing inbound recruitment THEN need more strategic approach",
      "IF candidate is good lecturer THEN teach them AI",
      "IF candidate is good AI person THEN teach them how to lecture",
      "IF instructor lacks preparation THEN terminate relationship"
    ],
    "evidence_quote": "maybe one of the things we do is like home grow talent to extent where we take good lecturers and teach them AI. Or maybe we take good AI people and teach them how to lecture.",
    "source_transcript": "transcripts_normalized/OpenAI Brief Brainstorm 2025-10-23 16_29 transcript.json",
    "source_date": "2025-10-23"
  },
  {
    "name": "Resource Allocation Priority Framework",
    "type": "decision_framework",
    "confidence": 0.85,
    "description": "Logic for allocating existing talent based on profitability and opportunity assessment",
    "components": [
      "Assess current resource utilization and profitability",
      "Prioritize higher-profit opportunities with existing talent",
      "Avoid pulling resources from profitable activities",
      "Find alternative resources for new initiatives"
    ],
    "evidence_quote": "Tawny is great but like she right now is our best asset and resource for our enterprise workshop. So I obviously don't want to pull Tawny from that to put her on this stuff because we need her where she already is. That's much more profitable for us.",
    "source_transcript": "transcripts_normalized/OpenAI Brief Brainstorm 2025-10-23 16_29 transcript.json",
    "source_date": "2025-10-23"
  },
  {
    "name": "Workshop Scaling Cost Model",
    "type": "scaling_framework",
    "confidence": 0.82,
    "description": "Framework for achieving profitability at scale by reducing customization, using retainers, and leveraging existing materials",
    "components": [
      "Build on existing materials (OpenAI materials)",
      "Minimize customizations to reduce lift",
      "Use retainer contracts with instructors for lower rates",
      "Leverage internal talent as primary resource",
      "Supplement with contracted talent pool",
      "Smooth costs over time for long-term profitability"
    ],
    "evidence_quote": "if we're not doing any customizations, the lift is actually quite low once the workshops have been created. And it seems to me like we'll probably be doing more amendment than like true, like from zero to, from zero to one creation here.",
    "source_transcript": "transcripts_normalized/OpenAI Brief Brainstorm 2025-10-23 16_29 transcript.json",
    "source_date": "2025-10-23"
  },
  {
    "name": "Instructor Quality Control Framework",
    "type": "process_framework",
    "confidence": 0.87,
    "description": "Standardization process for ensuring consistent instructor quality through documentation and enforcement",
    "components": [
      "Create instructor handbook with standards",
      "Define preparation requirements",
      "Establish performance consequences",
      "Upskill instructors to meet 'section standard'",
      "Codify requirements for instructor evaluation"
    ],
    "evidence_quote": "Like we need to have a handbook for our instructors. So certain things of like if it seems like you haven't prepped you will be fired. Do you know what I mean? Like the things that are currently missing right now to really make that like because right now it's sort of like up to each person to prepare to do whatever it is that they need to do.",
    "source_transcript": "transcripts_normalized/OpenAI Brief Brainstorm 2025-10-23 16_29 transcript.json",
    "source_date": "2025-10-23"
  },
  {
    "name": "Content Refresh Maintenance Model",
    "type": "process_framework",
    "confidence": 0.78,
    "description": "Ongoing process for keeping workshop content current with rapidly evolving AI tools",
    "components": [
      "Establish refresh cadence (quarterly or monthly)",
      "Monitor new feature releases from platforms",
      "Update workshop materials accordingly",
      "Account for refresh costs in pricing model"
    ],
    "evidence_quote": "And of course, you know, we'll probably have to do a quarterly refresh. Right? Or even a monthly refresh because Chat DBT is constantly putting out new, new workshops.",
    "source_transcript": "transcripts_normalized/OpenAI Brief Brainstorm 2025-10-23 16_29 transcript.json",
    "source_date": "2025-10-23"
  },
  {
    "name": "Three-Workflow AI Implementation Framework",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "A phased approach to implementing AI solutions by extracting multiple workflows from a broader process and prioritizing three specific workflows to build and pilot",
    "components": [
      "Generating the brief",
      "Evaluating brief",
      "Drafting a PRD"
    ],
    "evidence_quote": "Keira has kind of extracted out multiple workflows and then prioritized those three as the ones to build and pilot AI solutions for. So the three listed in the email the generating the brief, the evaluating brief, and then the drafting a PRD.",
    "source_transcript": "transcripts_normalized/Section x Asurion_ Workflow Redesign Weekly Sync 2025-10-28 12_30 transcript.json",
    "source_date": "2025-10-28"
  },
  {
    "name": "Three-Phased AI Transformation Strategy",
    "type": "process_framework",
    "confidence": 0.95,
    "description": "A sequential approach to AI adoption that progresses from immediate value delivery, to systematization and training, to company-wide scaling",
    "components": [
      "Phase 1: Implement immediate value workflows based on current work patterns",
      "Phase 2: Systematize power user insights through training and knowledge capture",
      "Phase 3: Scale playbook across organization (3-6 months out)"
    ],
    "evidence_quote": "So that's a way to get for the product team value immediately based on how work is done today. Then based on both what we've seen be successful and also from my understanding Dave's push a bit in the session, there's also how is work going to fundamentally change in the future... And then lastly, I know we're all familiar with this, but that's the more company wide solution to say also for you guys, here's a playbook that you can scale across the org.",
    "source_transcript": "transcripts_normalized/Section x Asurion_ Workflow Redesign Weekly Sync 2025-10-28 12_30 transcript.json",
    "source_date": "2025-10-28"
  },
  {
    "name": "Power User Knowledge Extraction Framework",
    "type": "process_framework",
    "confidence": 0.88,
    "description": "A methodology for capturing and systematizing how power users utilize tools and extending that knowledge to the broader team",
    "components": [
      "Identify power users of the tool",
      "Document their use cases",
      "Systematize the approaches",
      "Extend to rest of team"
    ],
    "evidence_quote": "But what that really means is let's talk to some of the power users who are using VEO or whatever tool now. What are their use cases and systematizing that so it can be extended out to the rest of the team.",
    "source_transcript": "transcripts_normalized/Section x Asurion_ Workflow Redesign Weekly Sync 2025-10-28 12_30 transcript.json",
    "source_date": "2025-10-28"
  },
  {
    "name": "Tool Selection vs. Value Realization Framework",
    "type": "decision_framework",
    "confidence": 0.85,
    "description": "A principle distinguishing between tool adoption and actual value creation, requiring readiness assessment before workflow transformation",
    "components": [
      "Tool selection does not equal valuable use",
      "Assess team readiness",
      "Conduct exploration work before full workflow redesign",
      "Delay full transformation until foundation is ready"
    ],
    "evidence_quote": "The team has already selected a Vibe coding tool which is great, but we all know this just choosing a tool doesn't translate into valuable use of that tool... And then that lays the foundation for three, six months from now. We can fully redo that workflow with Vibe coding, but the team just isn't ready right now",
    "source_transcript": "transcripts_normalized/Section x Asurion_ Workflow Redesign Weekly Sync 2025-10-28 12_30 transcript.json",
    "source_date": "2025-10-28"
  },
  {
    "name": "Current State to Future State Workflow Evolution Model",
    "type": "model_framework",
    "confidence": 0.87,
    "description": "A two-layer approach that separates delivering value in current workflows from fundamentally transforming future workflows",
    "components": [
      "Layer 1: How work is done today - immediate value delivery",
      "Layer 2: How work will fundamentally change in the future - transformational change"
    ],
    "evidence_quote": "So that's a way to get for the product team value immediately based on how work is done today. Then based on both what we've seen be successful and also from my understanding Dave's push a bit in the session, there's also how is work going to fundamentally change in the future?",
    "source_transcript": "transcripts_normalized/Section x Asurion_ Workflow Redesign Weekly Sync 2025-10-28 12_30 transcript.json",
    "source_date": "2025-10-28"
  },
  {
    "name": "Pilot to Production Scaling Framework",
    "type": "scaling_framework",
    "confidence": 0.83,
    "description": "A methodology for scaling solutions from team-specific implementations to organization-wide playbooks",
    "components": [
      "Build and pilot AI solutions for specific team workflows",
      "Create systematized playbook from pilot learnings",
      "Scale playbook across organization"
    ],
    "evidence_quote": "And then lastly, I know we're all familiar with this, but that's the more company wide solution to say also for you guys, here's a playbook that you can scale across the org.",
    "source_transcript": "transcripts_normalized/Section x Asurion_ Workflow Redesign Weekly Sync 2025-10-28 12_30 transcript.json",
    "source_date": "2025-10-28"
  },
  {
    "name": "Workflow Optimization Progression Framework",
    "type": "process_framework",
    "confidence": 0.95,
    "description": "A four-stage methodology for progressively optimizing workflows using AI, moving from manual processes through templating, ad-hoc AI assistance, to fully redesigned AI-powered workflows",
    "components": [
      "Stage 1: 100% Manual Effort (baseline: 9+ hours)",
      "Stage 2: Process Optimization with Templates (reduce by ~2 hours)",
      "Stage 3: Ad-hoc AI Assistance as Thought Partner (reduce by ~3 hours)",
      "Stage 4: Fully Redesigned Process with Custom AI (reduce to 60-90 minutes)"
    ],
    "evidence_quote": "it was 100% manual effort...And then I was like, you know what? I'm an ops person. I'm going to optimize my process by templating...Doing that helped me cut about two hours out of my process...started using AI to assist me, really using AI as a thought partner...That helped me cut down another three hours...And then fully redesigned process using AI of a custom GP...I was able to get my workflow to be nearly five times faster",
    "source_transcript": "transcripts_normalized/Kyra Atekwana's Zoom Meeting summary 2025-09-25 07_09 transcript.json",
    "source_date": "2025-09-25"
  },
  {
    "name": "Lecture Development Process Framework",
    "type": "process_framework",
    "confidence": 0.9,
    "description": "A structured approach to creating educational lecture content involving instructor collaboration, synthesis, and presentation design",
    "components": [
      "Prepare interview questions",
      "Interview the instructors",
      "Synthesizing insights",
      "Think about deck layout",
      "Create framework to showcase ideas",
      "Complete deck production"
    ],
    "evidence_quote": "Interviewing the instructors, synthesizing, thinking about what the deck layout was going to be, creating a brand new framework to showcase their ideas, all of that stuff",
    "source_transcript": "transcripts_normalized/Kyra Atekwana's Zoom Meeting summary 2025-09-25 07_09 transcript.json",
    "source_date": "2025-09-25"
  },
  {
    "name": "Framework Simplification Model",
    "type": "model_framework",
    "confidence": 0.85,
    "description": "A templating approach that standardizes complex frameworks into a three-step structure with opportunities for customization",
    "components": [
      "Boil frameworks down to three steps",
      "Create template for storytelling each step",
      "Provide opportunities to dig deeper",
      "Allow breaks from framework structure"
    ],
    "evidence_quote": "at the end of the day, most of the frameworks can be boiled down into sort of three steps as opposed to making it this big really unique thing. And then we can create a template for how you tell that story of each step of the framework and provide an opportunity to sort of dig deeper to make things break out of the framework",
    "source_transcript": "transcripts_normalized/Kyra Atekwana's Zoom Meeting summary 2025-09-25 07_09 transcript.json",
    "source_date": "2025-09-25"
  },
  {
    "name": "Workshop Learning Outcomes Framework",
    "type": "process_framework",
    "confidence": 0.88,
    "description": "A three-step learning methodology for enabling participants to implement AI workflow optimization",
    "components": [
      "Identify opportunities where you can get leverage with AI",
      "Understand AI superpowers and how they impact workflow",
      "Identify what the right solution is for optimization"
    ],
    "evidence_quote": "by the end of this workshop, you'll be able to identify your opportunities where you can get leverage with AI and then think about the superpowers that AI has that will help you understand how it can impact your workflow. And then we want to help you identify what the right solution is",
    "source_transcript": "transcripts_normalized/Kyra Atekwana's Zoom Meeting summary 2025-09-25 07_09 transcript.json",
    "source_date": "2025-09-25"
  },
  {
    "name": "Workflow Communication Framework",
    "type": "engagement_framework",
    "confidence": 0.82,
    "description": "A structured approach to presenting workflow redesign concepts by showing the process, defining terms, and explaining methodology",
    "components": [
      "Show concrete workflow example",
      "Define what workflow means",
      "Explain workflow redesign concept",
      "Teach recognition and determination methods",
      "Summarize end-to-end design"
    ],
    "evidence_quote": "this is a workflow. This is what we mean when we talk about workflow...I will teach you how to recognize and determine what your workflow is. And then once you've done, I would then summarize at the end of that process to say this is. This end to end design is what we would we mean by workflow redesign",
    "source_transcript": "transcripts_normalized/Kyra Atekwana's Zoom Meeting summary 2025-09-25 07_09 transcript.json",
    "source_date": "2025-09-25"
  },
  {
    "name": "Time Savings Measurement Framework",
    "type": "measurement_framework",
    "confidence": 0.9,
    "description": "A methodology for quantifying workflow improvement by measuring time reduction at each optimization stage and calculating overall efficiency gains",
    "components": [
      "Establish baseline time (9+ hours or 2 days)",
      "Measure time savings at each stage",
      "Calculate efficiency multiplier (5x faster)",
      "Express final state in absolute time (60-90 minutes)"
    ],
    "evidence_quote": "it was 100% manual effort...nine plus hours...helped me cut about two hours out of my process...three times faster...helped me cut down another three hours...Build one of these decks in honestly, really 90 minutes, like 60 to 90 minutes...I was able to get my workflow to be nearly five times faster",
    "source_transcript": "transcripts_normalized/Kyra Atekwana's Zoom Meeting summary 2025-09-25 07_09 transcript.json",
    "source_date": "2025-09-25"
  },
  {
    "name": "Brand Marketing Dual-Timeline Workflow",
    "type": "process_framework",
    "confidence": 0.88,
    "description": "A framework for managing brand marketing work across two parallel time horizons: current operations and future planning",
    "components": [
      "Working in the here and now (understanding current brand performance, existing programs, promotions, products)",
      "Building for the future (developing new programs, plans, products for 1-18 months ahead)"
    ],
    "evidence_quote": "most of our day to day is focused on a combination of working in the here and now, like understanding what's going on with your brand and any existing programs or promotions or products that you may have launched to then. We're seemingly almost always like building something for the future, you know, whether that's a new program, a plan, a product, like for a year or even 18 months down the road.",
    "source_transcript": "transcripts_normalized/Matt Foley - AI Interview - with Section AI 2025-07-16 07_32 transcript.json",
    "source_date": "2025-07-16"
  },
  {
    "name": "Audience-Based Presentation Adaptation Framework",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "A methodology for tailoring brand plans and presentations to different stakeholder groups by creating audience-specific variations",
    "components": [
      "Create base brand plan/presentation",
      "Develop variation for internal leadership (CMO)",
      "Adapt for global team perspective",
      "Customize for sales team or distributor team",
      "Tailor for specific customer groups (e.g., Target)"
    ],
    "evidence_quote": "we tend to have, say we have a. Plan for the upcoming year. Then we'll end up with three or four variations of how that even needs to be shared or show up based on the audience that we're talking to. So you know, whether it's like you're kind of selling internally to our CMO or you're talking to a global team sometimes which is a little bit different, their perspective versus a sales team or distributor team or even a specific customer group",
    "source_transcript": "transcripts_normalized/Matt Foley - AI Interview - with Section AI 2025-07-16 07_32 transcript.json",
    "source_date": "2025-07-16"
  },
  {
    "name": "Cross-Functional Brand Leadership Model",
    "type": "model_framework",
    "confidence": 0.85,
    "description": "A conceptual model defining the brand marketer's role as the center of cross-functional coordination, combining vision-setting with project management",
    "components": [
      "Vision and tone setting",
      "Strategic direction guidance",
      "Cross-functional leadership (not just project management)",
      "Formal communications and project tracking",
      "Informal ad hoc collaboration and ideation"
    ],
    "evidence_quote": "you're the one who should be setting like the vision, the tone, the direction, like kind of not just being a project manager but also being, you know, that cross functional leader that's kind of guiding things through the system. So that takes up a lot of their work and workflow. So through you know, formal communications, project tracking, keeping things like on, you know, so that's kind of more project management I'd say. But there's also a whole informal piece to it of you know, all that ad hoc chatting, conversations, ideation that happens in between any of those formal checkpoints.",
    "source_transcript": "transcripts_normalized/Matt Foley - AI Interview - with Section AI 2025-07-16 07_32 transcript.json",
    "source_date": "2025-07-16"
  },
  {
    "name": "Enterprise AI Use Case Discovery & Prioritization",
    "type": "process_framework",
    "confidence": 0.98,
    "description": "A three-step methodology for identifying, evaluating, and implementing AI use cases across an enterprise",
    "components": [
      "Step 1: Collect and document all AI use cases across functions (create master list)",
      "Step 2: Review use cases for shared understanding, evaluate AI impact, identify blockers, and prioritize",
      "Step 3: Identify suitable tools/processes for prioritized use cases, test, and pilot"
    ],
    "evidence_quote": "step one. Get all these use cases kind of documented somewhere. That's the Excel I sent around... And now today's goal is kind of one, go through all these use cases, make sure we kind of all have the same understanding so that we can two, prioritize them all... our next step then is like hey once we have these use cases... for the ones that aren't, like identify suitable tools, new processes and then kind of test those out, pilot those going forward.",
    "source_transcript": "transcripts_normalized/Customer Solutions - AI Discovery & Prioritization 2025-08-07 14_02 transcript.json",
    "source_date": "2025-08-07"
  },
  {
    "name": "AI Impact Evaluation Framework",
    "type": "measurement_framework",
    "confidence": 0.92,
    "description": "A multi-dimensional framework for assessing the impact of AI use cases based on efficiency, quality, and implementation factors",
    "components": [
      "Evaluate efficiency gains from AI implementation",
      "Assess quality improvement of outputs",
      "Identify implementation blockers or barriers",
      "Determine adoption requirements and change management needs"
    ],
    "evidence_quote": "evaluating that on the AI impact and really trying to understand the reasoning for that kind of what the lift is. Are we gaining a lot of efficiency? Is it improving the quality of the output? Is it both? And then kind of understand for the ones that aren't rolled out, are there blockers that have kind of been preventing that? Is it just that we haven't gotten around to it? And then when we do kind of start addressing those use cases, what do we really need to do to drive adoption",
    "source_transcript": "transcripts_normalized/Customer Solutions - AI Discovery & Prioritization 2025-08-07 14_02 transcript.json",
    "source_date": "2025-08-07"
  },
  {
    "name": "AI Prioritization Framework",
    "type": "decision_framework",
    "confidence": 0.85,
    "description": "A framework for prioritizing AI use cases based on impact levels while allowing parallel execution of non-conflicting initiatives",
    "components": [
      "Categorize use cases by impact level (high, medium, low)",
      "Identify top 5 priority use cases for resource constraints",
      "Allow parallel execution of lower-priority items if resources available and work already underway"
    ],
    "evidence_quote": "hey, where do we think the biggest impacts are? And we can get in... where are the, you know, the high impact ones? Whereas maybe more of a medium... let's like right click our top five just in case, you know, resource wise, there's not an ability to go and do the laundry list, but to the extent these can be done in parallel. Great. Like we don't want to hold anything up just because it's not on 1 through 5 if you already have work underway",
    "source_transcript": "transcripts_normalized/Customer Solutions - AI Discovery & Prioritization 2025-08-07 14_02 transcript.json",
    "source_date": "2025-08-07"
  },
  {
    "name": "AI Scope Boundary Framework",
    "type": "decision_framework",
    "confidence": 0.88,
    "description": "A framework for defining scope boundaries by separating customer-facing AI applications from internal operational AI use cases",
    "components": [
      "Exclude customer-facing AI solutions already in active development (conversational IVR, AI chat agents, expert assist)",
      "Focus on internal/back-office functions for transformation initiative"
    ],
    "evidence_quote": "using AI and Saluto and claims to either serve customers with like things like conversational IVR or AI chat agents or AI expert assist for solving and selling. We've kind of kept those out of scope for now just because there's so much work already underway in those. So focus of this conversation is more on... back office type functions.",
    "source_transcript": "transcripts_normalized/Customer Solutions - AI Discovery & Prioritization 2025-08-07 14_02 transcript.json",
    "source_date": "2025-08-07"
  },
  {
    "name": "AI Adoption Journey",
    "type": "process_framework",
    "confidence": 0.9,
    "description": "A staged approach to AI implementation that emphasizes building foundational blocks before advancing to complex applications like agentic AI",
    "components": [
      "Foundational building blocks",
      "Intermediate capabilities",
      "Advanced implementation (agentic AI)"
    ],
    "evidence_quote": "I like the slide that you put together and I'll have you talk through that of like, we obviously want to get people all the way there, but like these are the building blocks that we find are important to put into place in order to bring everyone along and make sure that everyone has the tool set to be able to do this effectively.",
    "source_transcript": "transcripts_normalized/Refining Workshop Strategy for AI Adoption and Client Customization 2025-11-19 12_33 transcript.json",
    "source_date": "2025-11-19"
  },
  {
    "name": "Dual-Track Learning Framework",
    "type": "model_framework",
    "confidence": 0.92,
    "description": "A two-component learning model separating foundational AI education from customized workshop applications",
    "components": [
      "Prof. AI: AI 101 fluency, responsible use, prompting fundamentals",
      "Workshops: Leadership essentials with outside-in/inside-out blended learning, customized to organizational themes and initiatives"
    ],
    "evidence_quote": "in my mind the workshop is more of that like outside in, inside out, like blended learning experience where we're taking like their themes and like customizing the content to like help drive towards their initiatives. Whereas our Prof. AI content is very much like AI 101 fluency, responsible use, prompting, fundamentals, etc. And then I think like the workshops is more of the leadership essentials.",
    "source_transcript": "transcripts_normalized/Refining Workshop Strategy for AI Adoption and Client Customization 2025-11-19 12_33 transcript.json",
    "source_date": "2025-11-19"
  },
  {
    "name": "Four-Pillar Strategic AI Initiative",
    "type": "model_framework",
    "confidence": 0.88,
    "description": "A top-down strategic framework defining four focus areas for systemic AI use case implementation",
    "components": [
      "Customer service",
      "Personalization",
      "Content creation",
      "Insights generation"
    ],
    "evidence_quote": "they have this strategic initiative where they've defined these four, four pillars and areas where they're going to focus from like a systemic use case standpoint. So just to give you some background, they've prioritized four main areas around customer service, personalization, content creation and insights generation.",
    "source_transcript": "transcripts_normalized/Refining Workshop Strategy for AI Adoption and Client Customization 2025-11-19 12_33 transcript.json",
    "source_date": "2025-11-19"
  },
  {
    "name": "Dual-Objective AI Enablement Strategy",
    "type": "model_framework",
    "confidence": 0.85,
    "description": "A two-tiered approach addressing both individual leader productivity and organizational workflow transformation",
    "components": [
      "Short-term: Upskilling leaders with toolsets for personal productivity",
      "Long-term: Enabling leaders to identify workflow opportunities and understand good use cases across teams"
    ],
    "evidence_quote": "part of this entire initiative is like one upskilling leaders, giving them the tool sets, helping them find their own personal productivity. But then there's like a longer tail objective of them wanting to also make sure that the leaders can like talk the talk and at least understand like what is a good opportunity for a workflow or how should they be thinking about it across their different teams.",
    "source_transcript": "transcripts_normalized/Refining Workshop Strategy for AI Adoption and Client Customization 2025-11-19 12_33 transcript.json",
    "source_date": "2025-11-19"
  },
  {
    "name": "Contextualized Tool Training Framework",
    "type": "engagement_framework",
    "confidence": 0.87,
    "description": "An approach to customize all training content to the specific toolset (Copilot) being deployed in the organization",
    "components": [
      "Customize workshop content for specific tools (Copilot)",
      "Provide tool-specific skills courses",
      "Frame all teaching within the context of available toolset",
      "Demonstrate tool applications at every step"
    ],
    "evidence_quote": "everything that we're teaching the partners about in these like custom sessions is in the context of the toolset that they have. And so we will make sure that like at every step we're teaching them in that framework and like giving them a sense of like the different things that they can leverage within COPILOT in order to do these activities.",
    "source_transcript": "transcripts_normalized/Refining Workshop Strategy for AI Adoption and Client Customization 2025-11-19 12_33 transcript.json",
    "source_date": "2025-11-19"
  },
  {
    "name": "Session Duration Constraint Framework",
    "type": "decision_framework",
    "confidence": 0.8,
    "description": "A decision rule for designing training sessions based on attention span limitations",
    "components": [
      "Maximum 90 minutes for virtual sessions",
      "Recommended structure: 75 minutes core + adjustments for additional modules"
    ],
    "evidence_quote": "their, their concern was that they were like, they. What did they say? 90 minutes was kind of the max. Yeah, my 90 minutes should be the max for the virtual sessions. They won't be able to keep people's attention longer than that.",
    "source_transcript": "transcripts_normalized/Refining Workshop Strategy for AI Adoption and Client Customization 2025-11-19 12_33 transcript.json",
    "source_date": "2025-11-19"
  },
  {
    "name": "Product Education Information Package",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "A structured approach to onboarding stakeholders with product knowledge through a sequenced delivery of educational materials",
    "components": [
      "Recorded demo of Blue in context of broader presentation",
      "Data Foundations 101 course in video library format",
      "Compiled slides from discovery conversations",
      "Packaged information delivery"
    ],
    "evidence_quote": "We will also send you Our Data Foundations 101 course which Susie and team are going to put into like a video library because that goes through data sources in glue, how we think about first party versus third party data match methodology, how we think about data provenance... And then we also want to send over just slides... we'll definitely compile all of that and basically just package all this information up for you so you have it.",
    "source_transcript": "transcripts_normalized/[PRODUCT MARKETING] Martech 101 Discovery Session  2025-06-25 13_00 transcript.json",
    "source_date": "2025-06-25"
  },
  {
    "name": "Data Foundations 101 Curriculum",
    "type": "model_framework",
    "confidence": 0.88,
    "description": "A comprehensive educational framework covering core data concepts and methodologies",
    "components": [
      "Data sources in glue",
      "First party versus third party data",
      "Match methodology",
      "Data provenance"
    ],
    "evidence_quote": "We will also send you Our Data Foundations 101 course which Susie and team are going to put into like a video library because that goes through data sources in glue, how we think about first party versus third party data match methodology, how we think about data provenance.",
    "source_transcript": "transcripts_normalized/[PRODUCT MARKETING] Martech 101 Discovery Session  2025-06-25 13_00 transcript.json",
    "source_date": "2025-06-25"
  },
  {
    "name": "Product Introduction Meeting Structure",
    "type": "process_framework",
    "confidence": 0.85,
    "description": "A flexible meeting structure that adapts based on access issues, starting broad then addressing specific questions",
    "components": [
      "Take a step back and walk through Blue holistically",
      "Provide Horizon background context",
      "Explain what's being built with Blue",
      "Address specific questions in a pointed way"
    ],
    "evidence_quote": "Is take a bit of a step back and walk you through kind of Blue holistically... take a step back, walk through some Horizon background, some background around what we're building with Blue and just give you all that broader context. And then Kyra, I want to go through some of your questions that you would send and just address those in a pointed way.",
    "source_transcript": "transcripts_normalized/[PRODUCT MARKETING] Martech 101 Discovery Session  2025-06-25 13_00 transcript.json",
    "source_date": "2025-06-25"
  },
  {
    "name": "AI-Native Product Development Approach",
    "type": "model_framework",
    "confidence": 0.8,
    "description": "A strategic approach to building technology that leverages independence and avoids tech debt while adapting to AI paradigm shifts",
    "components": [
      "Build proprietary technology without acquisitions",
      "Avoid tech debt from legacy systems",
      "Build AI native from ground up",
      "Rely on strategic partnerships",
      "Enable rapid adaptation to rate of change"
    ],
    "evidence_quote": "We haven't made these big multimillion dollar acquisitions over the last many years, as many of our competitors have done. So we're really not saddled with that type of tech debt the way they are. So we've been building everything from a proprietary standpoint, but also really reliant on strategic partnerships... we're building Blue in a way that is AI native, that is enabling us to move more quickly and really adapt to the rate of change.",
    "source_transcript": "transcripts_normalized/[PRODUCT MARKETING] Martech 101 Discovery Session  2025-06-25 13_00 transcript.json",
    "source_date": "2025-06-25"
  },
  {
    "name": "Workshop Development Framework",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "Step-by-step process for preparing client workshops: finish outline, share for feedback, prepare slides, customize demo prompts",
    "components": [
      "Finish outline by deadline",
      "Share with client for feedback",
      "Select pre-prepared demos",
      "Contextualize content for client",
      "Customize demo prompts"
    ],
    "evidence_quote": "So my objective is to just finish that outline by today and like we can share it with them if they want to give us feedback on that... we don't really need to do anything other than just like assess which demos of the like pre prepared demos we want to do and just how we want to contextualize it for them",
    "source_transcript": "transcripts_normalized/Kyra & Alli 1x1 2025-11-04 13_03 transcript.json",
    "source_date": "2025-11-04"
  },
  {
    "name": "Workshop Structure Model",
    "type": "model_framework",
    "confidence": 0.95,
    "description": "Standard workshop content model with five core components: why/introduction, getting started, prompting basics, demos, and hands-on activity",
    "components": [
      "Why of AI (introduction)",
      "Getting started with tool (co-pilot)",
      "Prompting fundamentals",
      "Three use case demos",
      "Hands-on activity"
    ],
    "evidence_quote": "we would teach, you know like three use cases, demo activity and Prof... it starts with the why of AI as an introduction and then getting started with co pilot... Super quick prompting three demos and then the activity",
    "source_transcript": "transcripts_normalized/Kyra & Alli 1x1 2025-11-04 13_03 transcript.json",
    "source_date": "2025-11-04"
  },
  {
    "name": "Activity Design Framework",
    "type": "process_framework",
    "confidence": 0.88,
    "description": "Interactive workshop activity structure using prompt template to guide participants through self-discovery of AI use cases",
    "components": [
      "Participant introduces themselves to AI",
      "Specify available tools",
      "AI asks clarifying questions",
      "Generate personalized use cases (15 ideas)",
      "Frame AI as strategic thought partner"
    ],
    "evidence_quote": "the activity is basically taking from oat and optimize prompt of just being like here's who I am, here's the tool I have access to help me think of... ask me a few questions and help me think of 15 use cases to use AI as a strategic thought partner",
    "source_transcript": "transcripts_normalized/Kyra & Alli 1x1 2025-11-04 13_03 transcript.json",
    "source_date": "2025-11-04"
  },
  {
    "name": "Skill-to-Workflow Transformation Model",
    "type": "model_framework",
    "confidence": 0.9,
    "description": "Two-layer approach separating individual skill-building from organizational workflow optimization, positioning training as foundation for future transformation",
    "components": [
      "Building individual skills for experimentation",
      "Workflow optimization for transformation (future state)",
      "Three core workflow optimizations (persistent)",
      "Integration readiness"
    ],
    "evidence_quote": "there's building the skill so that people can experiment... Going to get into the workflow for this, like future state of transformation... these optimizations of the three workflows stay the same",
    "source_transcript": "transcripts_normalized/Kyra & Alli 1x1 2025-11-04 13_03 transcript.json",
    "source_date": "2025-11-04"
  },
  {
    "name": "Prof.AI Positioning Framework",
    "type": "engagement_framework",
    "confidence": 0.85,
    "description": "Strategy for positioning internal learning platform to create excitement and explain value proposition to teams before access",
    "components": [
      "Preview access announcement",
      "Explain proficiency unlocking",
      "Explain use case discovery",
      "Generate excitement",
      "Position as ongoing resource"
    ],
    "evidence_quote": "one thing could just be around in terms of how to position prop AI. Like you and your teams are going to get access to this thing. This is how it's going to unlock both proficiency and use cases for you all and just sort of like get them excited about that",
    "source_transcript": "transcripts_normalized/Kyra & Alli 1x1 2025-11-04 13_03 transcript.json",
    "source_date": "2025-11-04"
  },
  {
    "name": "Functional Workshop Research Framework",
    "type": "process_framework",
    "confidence": 0.87,
    "description": "Data collection methodology combining survey data with structured interviews per function to inform workshop customization",
    "components": [
      "Use existing survey data",
      "Conduct three interviews per function",
      "Two employee-level interviews",
      "One leadership interview",
      "Record all interviews",
      "Synthesize for workshop design"
    ],
    "evidence_quote": "we can use the survey data and then do like three interviews per function... we could have like Taylor Powers do the two employee ones and like I could do the leadership one... obviously record and all that",
    "source_transcript": "transcripts_normalized/Kyra & Alli 1x1 2025-11-04 13_03 transcript.json",
    "source_date": "2025-11-04"
  },
  {
    "name": "Workload Management Framework",
    "type": "decision_framework",
    "confidence": 0.83,
    "description": "Priority-based task delegation approach: focus on critical deliverables while transitioning other work to maintain momentum",
    "components": [
      "Identify critical deadlines (Havas, DTE crash course)",
      "Transition non-critical work to others",
      "Focus on building key deliverables",
      "Maintain client momentum"
    ],
    "evidence_quote": "everything other than Havas and the DTE crash course to people so that I can focus on building those two things and also making sure we don't lose any momentum with assuring",
    "source_transcript": "transcripts_normalized/Kyra & Alli 1x1 2025-11-04 13_03 transcript.json",
    "source_date": "2025-11-04"
  },
  {
    "name": "Custom Workshop Development Timeline",
    "type": "process_framework",
    "confidence": 0.95,
    "description": "A 5-week phased approach to developing customized AI workflow training, moving from research through content development to delivery",
    "components": [
      "Week 1-2: Stakeholder interviews and research (employee interviews to understand current work and AI opportunities)",
      "Week 2-5: Content development (create outline, develop skeleton deck, prep facilitators)",
      "Week 5: Final workshop delivery (third week of November)"
    ],
    "evidence_quote": "So we have about five weeks, counting this week, to when the actual summit is. And so we'll start with this week, ideally starting this week, and then finishing up next week with stakeholder interviews and research... and then spend the next three weeks and content development... And then finish up the skeleton deck, start prepping the facilitators and get them ready for the final workshop delivery that week, the third week of November.",
    "source_transcript": "transcripts_normalized/HP x Section_ AI workflows workshop discussion 2025-10-21 17_01 transcript.json",
    "source_date": "2025-10-21"
  },
  {
    "name": "Employee Interview Research Methodology",
    "type": "engagement_framework",
    "confidence": 0.92,
    "description": "A structured approach to gathering insights from different organizational levels through 3-5 sessions combining manager and individual contributor perspectives",
    "components": [
      "Conduct 3-5 sessions based on team size and scope",
      "Manager focus groups (strategic perspective, team goals, bird's eye view of opportunities)",
      "Individual contributor sessions (deep dive into actual work, current AI usage, unmet needs)",
      "Session format options: individual interviews OR small focus groups (2-3 employees with similar roles/workflows)"
    ],
    "evidence_quote": "So we usually do anywhere from three to five sessions, depending on the size of the team and the scope of a workshop. And we can do a combination of manager focus groups and individual contributor sessions... the idea of what we get from managers is they offer a strategic perspective, they talk about team goals... versus what we get from the individual contributor sessions are the more valuable insights where they'll deep dive into. Here's what I'm doing at work, here are the ways I'm actively using AI.",
    "source_transcript": "transcripts_normalized/HP x Section_ AI workflows workshop discussion 2025-10-21 17_01 transcript.json",
    "source_date": "2025-10-21"
  },
  {
    "name": "Content Customization Discovery Process",
    "type": "process_framework",
    "confidence": 0.88,
    "description": "A methodology for identifying relevant workflow use cases through employee interviews to ensure training content feels new and valuable",
    "components": [
      "Conduct employee interviews to understand current work activities",
      "Identify opportunities for AI integration in workflows",
      "Assess existing AI knowledge to avoid repetition",
      "Identify 2-3 additional workflows beyond presentations to cover in workshop"
    ],
    "evidence_quote": "So we want to do employee interviews so we can deeply understand what is the kind of work that they're engaged in, what are the opportunities for them to use AI. I know you all mentioned that you have had quite a few AI workshops already. So we want to make sure that what we're showing them feels like new content, feels like new new opportunities, and use cases for them to incorporate AI into their workflow... this will be our other opportunity to identify what are the other two potential workflows that we'll cover during this session that would be most valuable to the team.",
    "source_transcript": "transcripts_normalized/HP x Section_ AI workflows workshop discussion 2025-10-21 17_01 transcript.json",
    "source_date": "2025-10-21"
  },
  {
    "name": "Workshop Content Development Sequence",
    "type": "process_framework",
    "confidence": 0.9,
    "description": "A sequential process for developing custom workshop materials from research insights through to delivery readiness",
    "components": [
      "Complete stakeholder interviews",
      "Create content outline based on interview insights",
      "Share outline with client for review",
      "Develop skeleton deck",
      "Prepare facilitators for delivery"
    ],
    "evidence_quote": "So for this custom workshop, we'll create an outline, once we've completed the interviews, of our thoughts on the structure of the content and what will be included in it, and then share that with you all for your review. And then finish up the skeleton deck, start prepping the facilitators and get them ready for the final workshop delivery",
    "source_transcript": "transcripts_normalized/HP x Section_ AI workflows workshop discussion 2025-10-21 17_01 transcript.json",
    "source_date": "2025-10-21"
  },
  {
    "name": "Earnings Report Compilation Process",
    "type": "process_framework",
    "confidence": 0.98,
    "description": "A systematic weekly process for tracking, compiling, and distributing earnings reports to investment teams",
    "components": [
      "Track earnings call dates via RSS feeds and IR distribution lists",
      "Update spreadsheet with earnings call dates",
      "Add earnings calls to executive calendar",
      "Download press releases and investor letters from company websites",
      "Download presentation materials",
      "Pull transcripts from Cap IQ software",
      "Pull analyst research from Goldman Sachs (day after)",
      "Combine 3-5 files into single PDF using Adobe",
      "Distribute via Slack channel (fintech) or email (direct to manager)"
    ],
    "evidence_quote": "every like basically weekly I have a spreadsheet that I update the, the earnings called dates on...And then when, at the end of each week when earnings call season is occurring, I go to the website for each of the companies. I pull the press release or like an investor letter and then the presentation...And I download that and then from a software that we have here called Cap Iq, I pull a transcript of the earnings call and then from Goldman Sachs research I pull the analyst research...And then in Adobe I combine you know, the four, three to four files or you know, three to five files into one. Then I put that into Slack",
    "source_transcript": "transcripts_normalized/Lisa Read and Kyra Atekwana 2025-09-24 11_01 transcript.json",
    "source_date": "2025-09-24"
  },
  {
    "name": "EA Needs Assessment Framework",
    "type": "engagement_framework",
    "confidence": 0.92,
    "description": "A structured approach to understanding EA roles before designing AI training interventions",
    "components": [
      "Understand the specific EA role and responsibilities",
      "Identify typical weekly activities and tasks",
      "Deep dive into specific processes",
      "Identify automation opportunities",
      "Design targeted AI workshops based on findings"
    ],
    "evidence_quote": "So the purpose of the interview is really to just understand more about your role and the kind of work that you're engaged in, so I can start thinking about ways to help to help you all use AI more frequently and also more strategically",
    "source_transcript": "transcripts_normalized/Lisa Read and Kyra Atekwana 2025-09-24 11_01 transcript.json",
    "source_date": "2025-09-24"
  },
  {
    "name": "Distribution Segmentation Framework",
    "type": "decision_framework",
    "confidence": 0.88,
    "description": "Logic for routing earnings reports to appropriate recipients based on content category",
    "components": [
      "IF fintech-related (~10 companies) THEN distribute to fintech team Slack channel",
      "IF non-fintech but manager-relevant (~3 companies) THEN send directly via email to manager"
    ],
    "evidence_quote": "There's I pull like a, I don't know, maybe 10 or so that are fintech related. Those go into the Slack channel for the fintech team...And then the other ones that are non fintech related are more for like my manager...those ones I just send directly to him via email",
    "source_transcript": "transcripts_normalized/Lisa Read and Kyra Atekwana 2025-09-24 11_01 transcript.json",
    "source_date": "2025-09-24"
  },
  {
    "name": "AI Use Case Identification Workshop Framework",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "A structured approach for teams to identify AI automation opportunities within their existing workflows through presentation, breakout sessions, and guided exercises",
    "components": [
      "Educational session on finding AI use cases (~60 minutes)",
      "Pre-mapped workflow audit across all team processes",
      "Breakout sessions by functional team",
      "Guided exercise to identify automation opportunities in specific workflow steps",
      "Moderated discussions with facilitators per breakout group",
      "Output: Documented use cases and prompts by team"
    ],
    "evidence_quote": "The first hour or so is going to be about finding your AI use case... then there's going to be breakouts where the purpose of the breakouts is for them to basically identify like their own use cases... they want people to think about the different steps in each of these different processes and think about where AI can automate some of these steps",
    "source_transcript": "transcripts_normalized/Sync on Doordash presentation 2025-09-09 23_01 transcript.json",
    "source_date": "2025-09-09"
  },
  {
    "name": "Workflow Audit to AI Implementation Framework",
    "type": "process_framework",
    "confidence": 0.88,
    "description": "A systematic approach to mapping existing workflows, identifying automation opportunities, and enabling teams to implement AI solutions",
    "components": [
      "Map organizational ecosystem and work streams",
      "Audit all workflows and processes by team",
      "Break teams into functional groups",
      "Analyze specific workflow steps for AI automation potential",
      "Identify and document use cases per workflow",
      "Provide guidance on implementation approach"
    ],
    "evidence_quote": "They've been going through the process of mapping out their ecosystem and like all of the different work streams that folks have... they want people to think about the different steps in each of these different processes and think about where AI can automate some of these steps",
    "source_transcript": "transcripts_normalized/Sync on Doordash presentation 2025-09-09 23_01 transcript.json",
    "source_date": "2025-09-09"
  },
  {
    "name": "Workshop Delivery Engagement Framework",
    "type": "engagement_framework",
    "confidence": 0.85,
    "description": "A stakeholder engagement model for delivering AI enablement workshops with distributed facilitation and clear role definitions",
    "components": [
      "Single expert speaker delivers core content",
      "Client-side moderators facilitate breakout groups",
      "Pre-workshop alignment call with client stakeholders",
      "Clear guidance documentation for moderators",
      "Structured breakout format with defined objectives",
      "Team-specific outputs and deliverables"
    ],
    "evidence_quote": "We were very explicit that there is only one person who is joining and that is Tawny. There is no facilitator, etc. So on their side they're going to have people who are helping to moderate the different breakouts... we'll probably need to give Tani some guidance and then we'll need to work with them on like, okay, what is the structure for that and how do you, what are we asking for people to do and how did the moderators help?",
    "source_transcript": "transcripts_normalized/Sync on Doordash presentation 2025-09-09 23_01 transcript.json",
    "source_date": "2025-09-09"
  },
  {
    "name": "Workshop Content Development Process",
    "type": "process_framework",
    "confidence": 0.8,
    "description": "Internal process for developing and delivering customized workshop content under tight timelines",
    "components": [
      "Gather all context materials (recordings, docs, order forms)",
      "Review client call recordings and transcripts",
      "Use AI tools (GPT) to analyze context",
      "Schedule alignment meeting with client stakeholders",
      "Build customized content deck",
      "Coordinate logistics and speaker travel",
      "Define expected outputs and deliverables"
    ],
    "evidence_quote": "if you could send me. Anything and everything. Context, random docs that I can look through. Any. If there's any, like, recordings or transcripts that may be useful... I can chat through those with GPT to get some context and then build that out... Let me get you the recordings of the last couple of calls as well as the screenshots",
    "source_transcript": "transcripts_normalized/Sync on Doordash presentation 2025-09-09 23_01 transcript.json",
    "source_date": "2025-09-09"
  },
  {
    "name": "Workshop Success Measurement Framework",
    "type": "measurement_framework",
    "confidence": 0.75,
    "description": "Expected outputs to measure workshop effectiveness and team enablement",
    "components": [
      "Prompt use cases documented by team",
      "Clear guidance on identifying AI use cases",
      "Team-specific workflow optimization recommendations"
    ],
    "evidence_quote": "the expected output we talked about was prompt use cases by team. So we'll just need her to clarify, like, what are the exact teams they want us to focus on and then clear guidance on how to identify AI use cases, which should be the output of the actual workshop",
    "source_transcript": "transcripts_normalized/Sync on Doordash presentation 2025-09-09 23_01 transcript.json",
    "source_date": "2025-09-09"
  },
  {
    "name": "Product Team Organizational Model",
    "type": "model_framework",
    "confidence": 0.92,
    "description": "A three-layer organizational model for product teams based on customer interface and technical complexity",
    "components": [
      "Expert/Frontline Tools Teams - focus on internal employee-facing products",
      "Customer Experience Teams - focus on end customer-facing products with high UI requirements",
      "Domain/Platform Teams - focus on backend systems with less UI requirements"
    ],
    "evidence_quote": "there's going to be people that really focus on like all of our expert tools and technology, which means all of the, all of the stuff that our internal like Frontline employees will use and then some teams that will focus a lot on what like the end customers experience will be... And then there's probably, you know, call it the other half of product that are more. We'll call like domain and platform teams that are, that are less UI heavy",
    "source_transcript": "transcripts_normalized/Connect - PRD Kickoff 2025-11-10 11_30 transcript.json",
    "source_date": "2025-11-10"
  },
  {
    "name": "Product Team Differentiation Model",
    "type": "model_framework",
    "confidence": 0.88,
    "description": "A model for categorizing product teams by their operational characteristics and constraints",
    "components": [
      "Fast-moving teams with dedicated engineers and minimal client dependencies (internal tools)",
      "Cross-functional teams with interdependencies across multiple teams",
      "Client-facing teams requiring higher rigor and slower pace due to external stakeholder management"
    ],
    "evidence_quote": "it's in teams where they already have like dedicated engineers to them. They already have like they're working less client dependencies, more like internal tools. Like Frank's team can move very fast, whereas. Um, you know, Josh's team has more like interdependencies across and then mine tend to like work with the clients which are much slower and we have to be much more rigorous on things.",
    "source_transcript": "transcripts_normalized/Connect - PRD Kickoff 2025-11-10 11_30 transcript.json",
    "source_date": "2025-11-10"
  },
  {
    "name": "Automation Pilot Discovery Process",
    "type": "process_framework",
    "confidence": 0.85,
    "description": "A phased approach to implementing automation tools starting with current state mapping before solution design",
    "components": [
      "Map current state processes in detail across different teams",
      "Identify variations in workflows and stakeholder requirements",
      "Design customized automation solutions based on team needs",
      "Consider tool capabilities (e.g., V0) for specific use cases"
    ],
    "evidence_quote": "I think the first step and Kyra will get to it in a second but will be just really mapping out the current state in a lot of detail because the solution might change moving forward... I also think once we map it out it might be that the solutions are more accustomed to each team",
    "source_transcript": "transcripts_normalized/Connect - PRD Kickoff 2025-11-10 11_30 transcript.json",
    "source_date": "2025-11-10"
  },
  {
    "name": "Tool Adoption Decision Framework",
    "type": "decision_framework",
    "confidence": 0.87,
    "description": "Logic for determining which product teams should adopt vibe coding tools based on UI intensity",
    "components": [
      "High UI teams (customer/expert-facing) - use tools in day-to-day work for prototyping",
      "Low UI teams (domain/platform) - train on tools but less frequent day-to-day usage",
      "Universal baseline - all PMs should have the skill set regardless of current need"
    ],
    "evidence_quote": "I think a lot of those teams could be, could benefit a lot from these vibe coding tools and be part of their day to day because there's going to be a lot of things that they want to prototype and show off. And then there's probably, you know, call it the other half of product that are more... less UI heavy, that may not need as much in their day to day, but they should probably be trained up on it",
    "source_transcript": "transcripts_normalized/Connect - PRD Kickoff 2025-11-10 11_30 transcript.json",
    "source_date": "2025-11-10"
  },
  {
    "name": "Change Management Risk Framework",
    "type": "decision_framework",
    "confidence": 0.83,
    "description": "Framework for evaluating effort investment during organizational transition periods",
    "components": [
      "Assess stability of current processes vs. likelihood of change",
      "Flag organizational transition risks (new leadership, reorgs)",
      "Balance discovery value against potential wasted effort",
      "Prioritize work that survives organizational changes"
    ],
    "evidence_quote": "I think this is very valuable but I also am, I'm a bit worried about any sort of wasted effort here with like trying to understand things that are going to change anyways... I do want to flag that as a caution just because I, I can't, can't guarantee you on what's going to happen in the next couple months here.",
    "source_transcript": "transcripts_normalized/Connect - PRD Kickoff 2025-11-10 11_30 transcript.json",
    "source_date": "2025-11-10"
  },
  {
    "name": "AI-Assisted Prompt Development Workflow",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "Multi-step process for creating comprehensive AI analysis using sequential AI tools and structured prompts",
    "components": [
      "Gather all source materials (chats, polls, transcripts)",
      "Send to GPT-4 to generate 15 prompts including system prompt and kickoff prompt",
      "Transfer prompts to Claude project for better attachment and memory management",
      "Run initial comprehensive analysis (25 minutes)",
      "Execute follow-up sub-prompts for deeper analysis",
      "Generate outputs (big document, one-pager, spreadsheet analysis)"
    ],
    "evidence_quote": "I went through and got all of the chats and the polls and the transcripts of everything from January to October, sent it to GPT5Pro, told it to come up with a series of 15 prompts, including a system prompt and a kickoff prompt. So I could put that into a cloud project which manages attachments and memory for these types of documents much better, and then sort of sent that out.",
    "source_transcript": "transcripts_normalized/Tom _ Kyra_ Working Session 2025-10-23 14_03 transcript (2).json",
    "source_date": "2025-10-23"
  },
  {
    "name": "Prompt Practice Exercise Framework",
    "type": "engagement_framework",
    "confidence": 0.88,
    "description": "Interactive workshop methodology for teaching participants to improve prompts using AI assistance",
    "components": [
      "Present basic prompt to participants",
      "Give 2 minutes to turn basic prompt into comprehensive prompt using AI",
      "Have participants screenshot framework for AI reference",
      "Participants share prompts and insights in chat",
      "Compare differences and discuss outcomes"
    ],
    "evidence_quote": "I did both of these things with General Catalyst is like here's a basic prompt, now make a comprehend. I just skipped straight to like make a comprehensive one based on this. And then people can share and then it's like. And then do that and pay are the differences. Share your prompt and your insights in the chat",
    "source_transcript": "transcripts_normalized/Tom _ Kyra_ Working Session 2025-10-23 14_03 transcript (2).json",
    "source_date": "2025-10-23"
  },
  {
    "name": "AI-Guided Interview Prompting Method",
    "type": "process_framework",
    "confidence": 0.85,
    "description": "Step-by-step approach where AI interviews the user through prompt building blocks to create comprehensive prompts",
    "components": [
      "Share framework slides with AI",
      "Ask AI to interview user through each building block",
      "AI guides user through structured questions",
      "AI creates final comprehensive prompt based on responses"
    ],
    "evidence_quote": "I gave the slides to her and then basically asked her to be like ask ChatGPT to take you through each building block to interview you so you can create and then it will create the prompt for you at the end.",
    "source_transcript": "transcripts_normalized/Tom _ Kyra_ Working Session 2025-10-23 14_03 transcript (2).json",
    "source_date": "2025-10-23"
  },
  {
    "name": "Use Case Translation Framework",
    "type": "decision_framework",
    "confidence": 0.82,
    "description": "Framework for helping learners identify how to apply demonstrated examples to their own work contexts",
    "components": [
      "Recognize demonstration is not industry-specific",
      "Identify core function in demo (e.g., creating a brief)",
      "Map to analogous task in own work (e.g., creating a memo)",
      "Apply one-to-one translation"
    ],
    "evidence_quote": "I think part of it is that people don't understand how to find use cases for themselves for work. And so I want you to tell me how I should be using it for work as opposed to like, oh, I just saw you do it for. To create like a brief. I could probably do that to create my next like memo.",
    "source_transcript": "transcripts_normalized/Tom _ Kyra_ Working Session 2025-10-23 14_03 transcript (2).json",
    "source_date": "2025-10-23"
  },
  {
    "name": "Workshop Content Validation Process",
    "type": "measurement_framework",
    "confidence": 0.78,
    "description": "Methodology for ensuring workshop content matches participant expectations by tracking demonstration alignment",
    "components": [
      "Review what demos are in prompt pack",
      "Compare to what's being delivered in live workshops",
      "Analyze participant feedback for specific requests (e.g., data analysis)",
      "Determine if requested content is missing or misaligned",
      "Adjust content accordingly"
    ],
    "evidence_quote": "So I actually don't even know if she's doing the workshop feedback data analysis demo anymore. Because I'm like, given how many, you know, like pretty much all the analyses call out. People want to see data analysis. That makes it like, are they not seeing it? Is the data analysis that we're doing not the right kind of data analysis?",
    "source_transcript": "transcripts_normalized/Tom _ Kyra_ Working Session 2025-10-23 14_03 transcript (2).json",
    "source_date": "2025-10-23"
  },
  {
    "name": "AI Technology Maturity Spectrum",
    "type": "model_framework",
    "confidence": 0.88,
    "description": "A conceptual model for organizing and categorizing different AI technologies to help audiences understand the landscape of automation, agentic workflows, and agents",
    "components": [
      "Automation",
      "Agentic Workflows",
      "Agents"
    ],
    "evidence_quote": "we talked about doing a little bit of dedicated time in your session to talk about like the difference in automation, agentic workflows and agents. And then Kyra sent over that graphic this weekend that I thought looked really interesting.",
    "source_transcript": "transcripts_normalized/Content Check-in_ Building Agentic Workflows + Keynote 2025-10-21 15_01 transcript.json",
    "source_date": "2025-10-21"
  },
  {
    "name": "AI Audience Understanding Framework",
    "type": "engagement_framework",
    "confidence": 0.92,
    "description": "A framework for tailoring AI education based on audience knowledge level, focusing on addressing confusion and providing concrete demonstrations",
    "components": [
      "Assess audience awareness level",
      "Organize the chaos into buckets/categories",
      "Show concrete examples (not just theory)",
      "Demonstrate tools in action",
      "Address business value and realistic expectations"
    ],
    "evidence_quote": "I think we forget, right? Like we sort of forget how little other people know about this world...some kind of, like, framing of, like, okay, let's organize the mess of the world a little bit into some buckets or something. And then the other thing I think is really interesting that I'm seeing is that even if someone has some awareness, they don't...they've never seen it in action.",
    "source_transcript": "transcripts_normalized/Content Check-in_ Building Agentic Workflows + Keynote 2025-10-21 15_01 transcript.json",
    "source_date": "2025-10-21"
  },
  {
    "name": "Executive AI Demonstration Process",
    "type": "process_framework",
    "confidence": 0.85,
    "description": "A step-by-step methodology for demonstrating AI agents to executives to create understanding and buy-in",
    "components": [
      "Pull up a tool (e.g., N8N)",
      "Show the prompt structure",
      "Explain the agent's decision-making capability",
      "Demonstrate tool usage in real-time",
      "Observe impact on audience understanding"
    ],
    "evidence_quote": "I'll pull up, you know, N8N or something. And I'm like. And so what's going on is. And I show them like the, the, like the prompt. And so I'm like, all that's happening here is this prompt is telling this agent to have some, you know, to make decisions on its own, to do its own thinking and use these tools appropriately.",
    "source_transcript": "transcripts_normalized/Content Check-in_ Building Agentic Workflows + Keynote 2025-10-21 15_01 transcript.json",
    "source_date": "2025-10-21"
  },
  {
    "name": "Builder Democratization Model",
    "type": "model_framework",
    "confidence": 0.9,
    "description": "A conceptual model showing the evolution from limited technical capability to widespread builder capability enabled by AI",
    "components": [
      "Traditional separation: business people vs developers",
      "Limited capability layer: business users with basic automation (Zapier)",
      "AI-enabled cognitive capabilities",
      "Expanded builder capability: more people can now build",
      "Cambrian explosion of possibilities"
    ],
    "evidence_quote": "so many people can be builders now. Whereas before you had business people and you had developers and the most a business person could do is maybe do some zapier shit. Right. And so now, you know, we've got this explosion of capabilities powered by AI, because AI can do this, cognitive, has cognitive abilities. And so that has unleashed this...Cambrian explosion",
    "source_transcript": "transcripts_normalized/Content Check-in_ Building Agentic Workflows + Keynote 2025-10-21 15_01 transcript.json",
    "source_date": "2025-10-21"
  },
  {
    "name": "AI Implementation Reality Check Framework",
    "type": "decision_framework",
    "confidence": 0.82,
    "description": "A decision framework for evaluating AI adoption considering market immaturity, vendor promises, and realistic implementation expectations",
    "components": [
      "Assess vendor maturity vs promises",
      "Evaluate enterprise solution risks",
      "Understand management awareness gaps",
      "Consider realistic first steps",
      "Navigate between marketing hype and actual capability"
    ],
    "evidence_quote": "there's a lot of immaturity in this space as well. Like where everyone's saying they have a product, everyone's making these big promises, people are implementing, you know, enterprise level glean and shit and failing...Microsoft has a very sophisticated sales team...But it's also high level that the, that the purposely, I think where the management team is then like, okay, so we're buying that. I guess, like they have no idea what they're buying",
    "source_transcript": "transcripts_normalized/Content Check-in_ Building Agentic Workflows + Keynote 2025-10-21 15_01 transcript.json",
    "source_date": "2025-10-21"
  },
  {
    "name": "AI Use Case Discovery and Prioritization Framework",
    "type": "process_framework",
    "confidence": 0.98,
    "description": "A three-step methodology for identifying, evaluating, and prioritizing AI use cases for organizational implementation",
    "components": [
      "Clear understanding and capture of all potential AI use cases (existing solutions, new shared cases, and uncaptured ideas)",
      "Evaluation and prioritization using quality and efficiency metrics (high/medium/low impact assessment)",
      "Alignment on top use cases for pilot testing and tool identification"
    ],
    "evidence_quote": "First is to make sure we have a clear understanding of all the potential use cases for AI... Next we'll jump to all use, like begin the evaluation and prioritization process... And then we just want to align on what are the top new use cases that are surfacing after the evaluation",
    "source_transcript": "transcripts_normalized/FW_ AI use-case Discovery and Prioritization Session - E&C New Partner Growth 2025-08-05 11_31 transcript.json",
    "source_date": "2025-08-05"
  },
  {
    "name": "Two-Metric Impact Evaluation Framework",
    "type": "measurement_framework",
    "confidence": 0.95,
    "description": "A dual-metric system for evaluating AI use cases based on quality enhancement and efficiency improvement",
    "components": [
      "Ability to enhance quality (primary vs. secondary impact)",
      "Ability to improve efficiency (high/medium/low rating)",
      "Determination of primary benefit category"
    ],
    "evidence_quote": "So we'll want to evaluate two main metrics. First is its ability to enhance quality. And the second is its ability to improve efficiency... it's like deciding which one of the two it does most. Is it primarily enhancing efficiency or primarily enhancing quality?",
    "source_transcript": "transcripts_normalized/FW_ AI use-case Discovery and Prioritization Session - E&C New Partner Growth 2025-08-05 11_31 transcript.json",
    "source_date": "2025-08-05"
  },
  {
    "name": "AI Pilot Scaling Framework",
    "type": "scaling_framework",
    "confidence": 0.9,
    "description": "A framework for scaling AI tool implementation from individual use to organizational deployment",
    "components": [
      "Identify optimal AI tool for each use case",
      "Craft testing/piloting process",
      "Scale from individual/team level to broader organizational function",
      "Choose between third-party vendor or in-house build"
    ],
    "evidence_quote": "After this, the team will start. Identifying what would be the best, most optimal AI tool for each of the use cases and we'll start crafting what a testing or piloting process should look like... in your case it wouldn't just be for the three of you and your team, it would be for the broader new partner strategy team",
    "source_transcript": "transcripts_normalized/FW_ AI use-case Discovery and Prioritization Session - E&C New Partner Growth 2025-08-05 11_31 transcript.json",
    "source_date": "2025-08-05"
  },
  {
    "name": "Organizational Impact Assessment Framework",
    "type": "measurement_framework",
    "confidence": 0.88,
    "description": "A framework for measuring impact at scale rather than individual level",
    "components": [
      "Evaluate team-wide application rather than individual use",
      "Consider organizational scaling implications",
      "Assess function-level impact"
    ],
    "evidence_quote": "if this is applied to the organization as a whole or to the team as a whole, what would be the impact for that function? So less about maybe your team or like let's say one individual applying this tool, more so about like if we scale this to multiple people, what would be the impact for the organization?",
    "source_transcript": "transcripts_normalized/FW_ AI use-case Discovery and Prioritization Session - E&C New Partner Growth 2025-08-05 11_31 transcript.json",
    "source_date": "2025-08-05"
  },
  {
    "name": "Three-Objective Session Structure Framework",
    "type": "engagement_framework",
    "confidence": 0.92,
    "description": "A structured approach for conducting AI use case discovery sessions with stakeholders",
    "components": [
      "Capture existing and in-progress use cases",
      "Review and validate new shared use cases",
      "Discover and add any missing use cases through brief discovery"
    ],
    "evidence_quote": "So three main objectives for this session. The first is to make sure we have a clear understanding of all the potential use cases for AI... First is just capturing the use cases with solutions already in progress. The second is go through any new use cases that you guys have already shared with us. And then the third is seeing if there's any ideas that we haven't captured in the list",
    "source_transcript": "transcripts_normalized/FW_ AI use-case Discovery and Prioritization Session - E&C New Partner Growth 2025-08-05 11_31 transcript.json",
    "source_date": "2025-08-05"
  },
  {
    "name": "Three-Perspective AI ROI Analysis Framework",
    "type": "model_framework",
    "confidence": 0.92,
    "description": "A structured approach to understanding AI ROI from multiple organizational viewpoints: buyer perspective (how to measure ROI of purchased tools), builder perspective (how to provide ROI insights to customers), and foundational context (current state of AI ROI)",
    "components": [
      "Level set on the state of AI ROI (where we are today)",
      "Buyer perspective: How to measure ROI of AI tools deployed internally",
      "Builder perspective: How to help companies get realtime access to ROI insights"
    ],
    "evidence_quote": "we're going to quickly kind of level set on the state of AI Roi kind of where we are uh today and why we're talking about it then we're going to share uh how grammar as as a buyer of a bunch of tools that run our uh our company uh you know how we measure the ROI uh of AI tools that we've deployed uh and then lastly uh we're going to give you a look at how we as a as a builder of AI productivity tools um you know how we at grammarly are helping companies uh really get realtime access uh to insights that matter",
    "source_transcript": "transcripts_normalized/tactiq-free-transcript-z9N1cUGxqgE.json",
    "source_date": "unknown"
  },
  {
    "name": "AI ROI Measurement Gap Framework",
    "type": "measurement_framework",
    "confidence": 0.88,
    "description": "A framework identifying the disconnect between belief in AI value and ability to measure that value, highlighting that only 22% of organizations can measure AI ROI despite widespread belief in its potential",
    "components": [
      "High organizational belief in AI transformation potential",
      "Low ability to measure actual value (22% success rate)",
      "Gap between intrinsic belief and quantifiable proof"
    ],
    "evidence_quote": "most of us as as leaders in organizations uh are pretty bullish on AP on AI uh we believe AI is really going to change how our organizations work for the better...but in a recent survey um from IBM we actually uh see that only 22% are actually feeling like they've been able to measure that value uh that they kind of intrinsically believe is there um but have been really struggling to of pinned down",
    "source_transcript": "transcripts_normalized/tactiq-free-transcript-z9N1cUGxqgE.json",
    "source_date": "unknown"
  },
  {
    "name": "Reactive AI Deployment Process Framework",
    "type": "process_framework",
    "confidence": 0.85,
    "description": "A diagnostic framework explaining why organizations struggle with AI ROI measurement, describing the sequence: AI emergence \u2192 reactive damage control \u2192 deployment without measurement planning",
    "components": [
      "Sudden emergence of generative AI technology",
      "Reactive focus on risk management and damage control",
      "Deployment before establishing measurement frameworks",
      "Result: deployed tools without ROI measurement capabilities"
    ],
    "evidence_quote": "when you think about how the generative AI um came to be uh today uh is it really happened to us like as it leaders and cesos and cios um you know suddenly it was a are and um we kind of reacted to it oh my God what am I going to do all these risks and these these privacy issues and these these security issues we really focused on like damage control and risk management...and we did didn't have even an opportunity to stay ahead of it...that's why we deployed it but we don't really know how to measure the ROI of it",
    "source_transcript": "transcripts_normalized/tactiq-free-transcript-z9N1cUGxqgE.json",
    "source_date": "unknown"
  },
  {
    "name": "EA Needs Assessment Framework",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "Kyra's structured approach to understanding EA needs and designing targeted AI training workshops",
    "components": [
      "Understand specific role and responsibilities",
      "Map typical week tasks and deliverables",
      "Identify time constraints and reactive vs proactive work",
      "Determine desired future state and time allocation",
      "Identify current process pain points",
      "Recommend appropriate AI tools and workflows"
    ],
    "evidence_quote": "So first to get us started, I would love to know just a little bit more about you and your like what your specific EA role is... I would love if you could walk through in your typical week, like, what does your week look like? What are your tasks? What are your deliverables?... And when it comes to freeing up your time to be more proactive, like, what are those things that you wish you had more time to do?",
    "source_transcript": "transcripts_normalized/Ana Portugal and Kyra Atekwana 2025-09-23 18_33 transcript.json",
    "source_date": "2025-09-23"
  },
  {
    "name": "Daily Brief Preparation Process",
    "type": "process_framework",
    "confidence": 0.88,
    "description": "Ana's current manual process for preparing executive daily briefs",
    "components": [
      "Search emails for relevant context and details",
      "Contact people directly to gather missing information",
      "Compile logistics details (timing, transportation, locations)",
      "Gather meeting context and background information",
      "Populate information into Google Doc template",
      "Add relevant links and supporting documents",
      "Transfer content to email format",
      "Send to executive"
    ],
    "evidence_quote": "one of my biggest tasks for her mom to sending him a brief, a daily brief ahead of his schedules... where do we pull that context? Right now I pull that context from emails asking people... I'll populate in the Google Doc and then transport that over into an email and send that to him",
    "source_transcript": "transcripts_normalized/Ana Portugal and Kyra Atekwana 2025-09-23 18_33 transcript.json",
    "source_date": "2025-09-23"
  },
  {
    "name": "CRM Data Integration Vision",
    "type": "model_framework",
    "confidence": 0.85,
    "description": "Future-state model for automating brief preparation through CRM system integration",
    "components": [
      "Team members update Affinity (CRM) after meetings",
      "Meeting notes and context stored in centralized system",
      "Automated feeding of CRM data into executive briefs",
      "Reduced manual chasing for information",
      "EA time freed from information gathering to strategic work"
    ],
    "evidence_quote": "it would be great if we could somehow get affinity to feedback and turn, you know, like feed into these briefs so that, like, again, I wouldn't. I wasn't spending like hours chasing people for context",
    "source_transcript": "transcripts_normalized/Ana Portugal and Kyra Atekwana 2025-09-23 18_33 transcript.json",
    "source_date": "2025-09-23"
  },
  {
    "name": "Reactive to Proactive Work Transition Model",
    "type": "model_framework",
    "confidence": 0.9,
    "description": "Ana's conceptual model distinguishing between current reactive state and desired proactive state",
    "components": [
      "Current state: Firefighting, reactive task completion, minute-by-minute scheduling",
      "Barrier: Volume of requests and lack of bandwidth",
      "Desired state: Strategic planning, holistic thinking, mindful scheduling",
      "Enabler: AI tools to automate routine tasks",
      "Outcome: Time freed for business-aligned decision making"
    ],
    "evidence_quote": "We don't really have the time right now to be proactive about things... right now it's just reactive and we're just getting through the tasks... being able to plan ahead right now... step back, look at things holistically and say, does this make sense for the business?",
    "source_transcript": "transcripts_normalized/Ana Portugal and Kyra Atekwana 2025-09-23 18_33 transcript.json",
    "source_date": "2025-09-23"
  },
  {
    "name": "AI Agent Workflow Framework",
    "type": "process_framework",
    "confidence": 0.87,
    "description": "Kyra's proposed agentic workflow using Make for automating information gathering and brief preparation",
    "components": [
      "Connect multiple systems together (email, Slack, Google Sheets, etc.)",
      "Set scheduled triggers (e.g., check emails at 8am)",
      "Define specific search parameters and prompts",
      "Automate information extraction",
      "Automatically populate output destination (Google Sheet/Doc)"
    ],
    "evidence_quote": "you can connect a bunch of different systems together. So it could be like, you know, check emails every 8am to look for the specific thing. You can prompt it to do that, and then it can take that information and put it into a Google Sheet",
    "source_transcript": "transcripts_normalized/Ana Portugal and Kyra Atekwana 2025-09-23 18_33 transcript.json",
    "source_date": "2025-09-23"
  },
  {
    "name": "Data Quality Prerequisites Framework",
    "type": "decision_framework",
    "confidence": 0.83,
    "description": "Identified barriers to automation: data availability and organizational habits must be addressed before technical solutions can be effective",
    "components": [
      "Identify automation opportunity",
      "Assess data availability in systems",
      "Evaluate team habits and adoption",
      "If data missing: address data issue first",
      "If habits missing: build organizational practices",
      "Then implement technical automation"
    ],
    "evidence_quote": "the barrier to that is that the information is not actually an affinity... it's a data. Data issue... And I think also a habit issue. You know, people aren't in the habit yet of putting those details, putting those notes in affinity",
    "source_transcript": "transcripts_normalized/Ana Portugal and Kyra Atekwana 2025-09-23 18_33 transcript.json",
    "source_date": "2025-09-23"
  },
  {
    "name": "Workshop Product Tiering Strategy",
    "type": "model_framework",
    "confidence": 0.88,
    "description": "A conceptual model for pricing workshops based on specificity and customization level - general/scalable workshops priced lower (~$15k), specialized/customized workshops priced higher (~$25-30k)",
    "components": [
      "General builder/champion workshops (lower price, ~$15k)",
      "Specialized builder workshops with customization (higher price, ~$25-30k)",
      "Pre-work/discovery calls for specialized workshops",
      "Volume discounts for multiple workshop purchases"
    ],
    "evidence_quote": "these are like for a smaller population they're like that builder champion workshop we probably should being like 15 because they're more general and like the kickoff and then some of the more and Kyra has to do like a call or someone on her team has to do a call to make sure we kind of understand roughly what they work on... just which workshops need to be built for scale and therefore should be stay at the lower price and frankly which workshops do we want to bring to a higher price",
    "source_transcript": "transcripts_normalized/Weekly Proposal Review 2025-11-13 15_02 transcript.json",
    "source_date": "2025-11-13"
  },
  {
    "name": "Workshop Development and Delivery Process",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "A standardized process for delivering customized workshops that includes discovery, development, and delivery phases with flexibility built in",
    "components": [
      "Discovery phase (interviews, kickoff calls as needed)",
      "Development phase with workshop team engagement",
      "Delivery phase (workshop execution)",
      "Flexible scoping language to avoid over-commitment"
    ],
    "evidence_quote": "development includes discovery. Such as. Yeah, development, interviews, kickoff calls, et cetera. As needed... I would just urge more for Lauren and Kyra. One of the things that I think we have gotten tripped up a little bit on is like putting that in there and then we get into the process and we realize we don't actually need interviews and then the client feels like they bought them",
    "source_transcript": "transcripts_normalized/Weekly Proposal Review 2025-11-13 15_02 transcript.json",
    "source_date": "2025-11-13"
  },
  {
    "name": "Client Progression Model",
    "type": "model_framework",
    "confidence": 0.85,
    "description": "A conceptual model showing how clients progress from foundational AI education to advanced workflow building capabilities",
    "components": [
      "Foundation: Prof. AI for everyone (general education)",
      "Problem: Teams need to generate advanced workflows",
      "Solution consideration: Forward deployed consultant (rejected)",
      "Actual solution: Builder workshops for identifying pilots and building LLM automations"
    ],
    "evidence_quote": "They have Prof. AI for everyone. And then the issue that they have is they want their teams to be starting to generate more advanced work. Workflows and so we were originally talking to them about like they saw the idea of a forward deployed consultant and they basically were like will you go do this for us? And we were like no. So we reoriented them towards the two builder workshops",
    "source_transcript": "transcripts_normalized/Weekly Proposal Review 2025-11-13 15_02 transcript.json",
    "source_date": "2025-11-13"
  },
  {
    "name": "Deal Sweetening Strategy",
    "type": "decision_framework",
    "confidence": 0.9,
    "description": "A decision logic for bundling renewals and additional services to close larger deals",
    "components": [
      "If multi-workshop purchase: apply volume discount",
      "If early renewal opportunity exists: bundle with current deal",
      "If client has existing product: reference as credibility/differentiation for upsell"
    ],
    "evidence_quote": "after I, Kyra and I hopped off, I thought it would make sense after talking with Bobby to try to add in the renewal of their Prof. AI which they don't renew until May, but wanted to kind of do that to sweeten the deal... why I did this is because they had, they have bought an AI crash course before. So I wanted to make it clear like why these are more expensive",
    "source_transcript": "transcripts_normalized/Weekly Proposal Review 2025-11-13 15_02 transcript.json",
    "source_date": "2025-11-13"
  },
  {
    "name": "Sell-Then-Build Product Development",
    "type": "process_framework",
    "confidence": 0.87,
    "description": "A methodology for validating new products by selling them before fully completing development",
    "components": [
      "Develop product to ~60% completion",
      "Create product menu/offering",
      "Sell to validate market demand",
      "Complete remaining development after sale confirmation"
    ],
    "evidence_quote": "the first one we're looking at for mid January, which I think should be fine. That workshop is still, I would say, about like, 60% of the way there in terms of the... he said once we sell it, then we would... So I think so now you have one. Now you have one... we haven't totally finished the new menu but we were like let's sell it to make sure before we started. So now we sold one",
    "source_transcript": "transcripts_normalized/Weekly Proposal Review 2025-11-13 15_02 transcript.json",
    "source_date": "2025-11-13"
  },
  {
    "name": "AI Tool Migration Strategy",
    "type": "process_framework",
    "confidence": 0.85,
    "description": "A systematic approach to transitioning users from unsecured external AI tools to enterprise-approved platforms with data protection",
    "components": [
      "Identify existing usage of external tools (ChatGPT)",
      "Provide secure alternative with data protection (Microsoft Copilot/PRGPT)",
      "Educate users on data security risks",
      "Move users to approved tools",
      "Monitor adoption and usage"
    ],
    "evidence_quote": "people are already using things like ChatGPT, right. Our idea was to try to move people off that to the tool that is, you know, under the data protection of Microsoft. So any work related information wasn't going to be able to be leaked.",
    "source_transcript": "transcripts_normalized/Tech - AI Discovery Interview - with Section AI 2025-07-14 11_31 transcript.json",
    "source_date": "2025-07-14"
  },
  {
    "name": "AI Use Case Validation Process",
    "type": "process_framework",
    "confidence": 0.88,
    "description": "A systematic process for evaluating and approving AI use cases within the organization",
    "components": [
      "Understand AI use cases",
      "Assess value generation for organization",
      "Navigate organizational AI approval processes",
      "Get blessing/recommendation",
      "Execute approved use cases"
    ],
    "evidence_quote": "me and my team are involved in like understanding AI use cases and what value they could generate for the organization and helping. Helping to kind of navigate the AI processes at Pernod Ricard to get them in a position where you know, they either get a blessing, you know a recommendation of some sort or not and then seeing that through into execution.",
    "source_transcript": "transcripts_normalized/Tech - AI Discovery Interview - with Section AI 2025-07-14 11_31 transcript.json",
    "source_date": "2025-07-14"
  },
  {
    "name": "AI Upskilling Interview Framework",
    "type": "engagement_framework",
    "confidence": 0.92,
    "description": "A structured discovery approach for developing custom AI training by understanding current state, use cases, and organizational needs",
    "components": [
      "Introduce facilitator and purpose",
      "Gather participant introductions and roles",
      "Assess current AI use cases in organization",
      "Understand proficiency levels",
      "Identify valuable use cases",
      "Build on existing practices for custom training"
    ],
    "evidence_quote": "just love to hear from you all. Yeah, how especially with regards to Copilot, we can start there, you know, I guess like the level of proficiency you're seeing across the organization and some of the more valuable use cases that have come up.",
    "source_transcript": "transcripts_normalized/Tech - AI Discovery Interview - with Section AI 2025-07-14 11_31 transcript.json",
    "source_date": "2025-07-14"
  },
  {
    "name": "Dual-Tool AI Access Model",
    "type": "model_framework",
    "confidence": 0.83,
    "description": "A complementary tool architecture providing users with two AI platforms that balance accessibility, security, and capability limitations",
    "components": [
      "Primary tool: Free Microsoft Copilot (limited features, integrated in Edge browser)",
      "Secondary tool: PRGPT (custom ChatGPT version, expanded capabilities)",
      "Balanced usage based on task requirements and limitations",
      "Both tools maintain data security"
    ],
    "evidence_quote": "it's a healthy balance to use both. If you are trying to explore AI inside of Preneur card because of our license limistration limitation with Copilot right now.",
    "source_transcript": "transcripts_normalized/Tech - AI Discovery Interview - with Section AI 2025-07-14 11_31 transcript.json",
    "source_date": "2025-07-14"
  },
  {
    "name": "Progressive AI Adoption Maturity Model",
    "type": "scaling_framework",
    "confidence": 0.78,
    "description": "An implicit maturity model showing progression from basic to advanced AI usage within the organization",
    "components": [
      "Basic level: Text structuring, email assistance, document reformatting",
      "Intermediate level: Browser-integrated usage, departmental applications",
      "Advanced level: File restructuring, specialized use cases (1% of users)",
      "Future state: Copilot standalone licenses with expanded capabilities"
    ],
    "evidence_quote": "most use cases are still kind of very basic fundamental understanding... We're moving now I guess into more or less a lot of text structuring, help with emails... Not as much file like restructuring because once again we're only using the free version... I feel the maybe 1% of Prenata card population that is really heavily using AI",
    "source_transcript": "transcripts_normalized/Tech - AI Discovery Interview - with Section AI 2025-07-14 11_31 transcript.json",
    "source_date": "2025-07-14"
  },
  {
    "name": "Field-Specific AI Coaching Approach",
    "type": "engagement_framework",
    "confidence": 0.8,
    "description": "A personalized training methodology that tailors AI education to specific departments and roles rather than generic training",
    "components": [
      "Assess user's field/department",
      "Identify role-specific productivity opportunities",
      "Provide contextualized use case education",
      "Coach on available tool capabilities",
      "Focus on practical application in their domain"
    ],
    "evidence_quote": "we're trying to honestly educate more people on how we can use this around your field, around your department to be a little bit more productive with what we have access to",
    "source_transcript": "transcripts_normalized/Tech - AI Discovery Interview - with Section AI 2025-07-14 11_31 transcript.json",
    "source_date": "2025-07-14"
  },
  {
    "name": "Amazon-Style Document Review Process",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "A meeting methodology where participants silently read a prepared document before discussion, inspired by Amazon's meeting practices",
    "components": [
      "Pre-written document shared in meeting",
      "Silent reading period (5 minutes)",
      "Group discussion after reading"
    ],
    "evidence_quote": "Okay, this is what I want to do actually is we're going to go Amazon style and I'm going to put this link in the chat... Take five minutes. We'll come back at 1:11, 1:11 for me and then discuss.",
    "source_transcript": "transcripts_normalized/Company Lunch & Learn 2025-10-24 14_01 transcript.json",
    "source_date": "2025-10-24"
  },
  {
    "name": "Use Case Desert Concept",
    "type": "model_framework",
    "confidence": 0.88,
    "description": "A conceptual model describing the gap between AI tool awareness/basic usage and advanced, meaningful use cases in organizations",
    "components": [
      "High AI proficiency scores (85%+)",
      "Low actual use case adoption (less than 50%)",
      "Predominance of beginner use cases (90%)",
      "Illusion of advanced usage vs. reality"
    ],
    "evidence_quote": "I feel like I'm seeing more and more companies where we're doing their AI maturity report and like people know how to use AI. Like they know the basics of it. They'll score like 85% proficiency. And then when I go into the data, like less than half of them actually have a use case. And then those that do, it's like 90% beginner use cases.",
    "source_transcript": "transcripts_normalized/Company Lunch & Learn 2025-10-24 14_01 transcript.json",
    "source_date": "2025-10-24"
  },
  {
    "name": "Product Presentation Structure",
    "type": "process_framework",
    "confidence": 0.85,
    "description": "A structured approach to presenting a new product feature or release to stakeholders",
    "components": [
      "Problem overview",
      "Product demo",
      "FAQ/Anticipated questions",
      "Roadmap and release timeline"
    ],
    "evidence_quote": "So I'm going to talk a little bit about the problem we're going to solve. Then I'm going to show you the demo. So that'll be most of it. I've got some answers to what I think are likely going to be the FAQs and then some upcoming roadmap and release timeline stuff.",
    "source_transcript": "transcripts_normalized/Company Lunch & Learn 2025-10-24 14_01 transcript.json",
    "source_date": "2025-10-24"
  },
  {
    "name": "AI Adoption Barrier Model",
    "type": "model_framework",
    "confidence": 0.8,
    "description": "A conceptual model identifying barriers that prevent users from advancing beyond basic AI use cases",
    "components": [
      "Basic usage level (email summarization, simple tasks)",
      "Policy constraints (data sharing restrictions)",
      "Readiness without means to advance",
      "Self-reinforcing cycle of perceived expertise"
    ],
    "evidence_quote": "You have a lot of people who are doing the more basic use cases, but also feel like, I'm totally using AI... But then you also have teams that they feel very ready and they seem like they're kind of really eager to use it in a more advanced way, but then they are stuck by the policies and not able to do it.",
    "source_transcript": "transcripts_normalized/Company Lunch & Learn 2025-10-24 14_01 transcript.json",
    "source_date": "2025-10-24"
  },
  {
    "name": "Self-Deception Cycle in AI Adoption",
    "type": "model_framework",
    "confidence": 0.78,
    "description": "A cyclical pattern where users overestimate their AI expertise, creating a barrier to actual learning and advancement",
    "components": [
      "Overestimation of expertise",
      "Basic use cases perceived as advanced",
      "No recognition of knowledge gap",
      "Prevention of learning progression"
    ],
    "evidence_quote": "There's a sort of like cycle that's self fulfilling of like I tell myself that I'm an expert here and I have a bunch of great use cases, but in reality I don't. And so that it sort of creates like a black hole effect of like never going to learn anything if you keep telling yourself that you're amazing.",
    "source_transcript": "transcripts_normalized/Company Lunch & Learn 2025-10-24 14_01 transcript.json",
    "source_date": "2025-10-24"
  },
  {
    "name": "AI Training Session Structure",
    "type": "process_framework",
    "confidence": 0.9,
    "description": "A step-by-step structure for delivering an AI training course, starting with expectations, then context-setting, followed by capability overview and use cases",
    "components": [
      "Set expectations up front about what the course is going to be",
      "Setting the stage around opportunity for AI in marketing",
      "Introduce AI passenger versus AI driver concept",
      "Overview of tools people have access to",
      "Present AI superpowers (analyze, ideate, create, research, prototype)",
      "Give overview of each superpower",
      "Provide use cases including ones mentioned in previous sessions"
    ],
    "evidence_quote": "So we want expectations up front about what the course is going to be. None of this is just a template slide we have, but I need to complete that. And then we sort of go into just setting the stage around opportunity for AI in marketing. And then as we were talking about this concept of the AI passenger versus an AI driver... And then what I want to do is go through, give an overview of each one and then have a bunch of use cases",
    "source_transcript": "transcripts_normalized/Marketing Offsite AI Workshop - Creative summary 2025-09-25 16_04 transcript.json",
    "source_date": "2025-09-25"
  },
  {
    "name": "AI Superpowers Model",
    "type": "model_framework",
    "confidence": 0.95,
    "description": "A conceptual model categorizing AI capabilities into five core superpowers that users can leverage",
    "components": [
      "Analyze",
      "Ideate",
      "Create",
      "Research",
      "Prototype"
    ],
    "evidence_quote": "And then these are the superpowers that we want people to leverage, analyze, ideate, create, research, and prototype. Those are things that you can do with AI.",
    "source_transcript": "transcripts_normalized/Marketing Offsite AI Workshop - Creative summary 2025-09-25 16_04 transcript.json",
    "source_date": "2025-09-25"
  },
  {
    "name": "Two-Track Workshop Design",
    "type": "decision_framework",
    "confidence": 0.92,
    "description": "A decision framework that routes participants to different workshop tracks based on their AI proficiency level and goals",
    "components": [
      "Track 1: Prompt building for exploration/entry level users",
      "Track 2: Advanced agent building (GPT/Gem/Glean agent) for daily users",
      "Decision criteria: User experience level and whether they have ideas for custom tools"
    ],
    "evidence_quote": "So there'll be like an activity packet. One of them is like prompt building, which I think for like more of an exploration entry level type of user, that's something to just like get them started... And then the other option is like let's say you're already, like, a daily user, and maybe you've had a thought about making a GPT or a gem or a Glean agent. We also have an activity workbook that could help you build one of those live right there.",
    "source_transcript": "transcripts_normalized/Marketing Offsite AI Workshop - Creative summary 2025-09-25 16_04 transcript.json",
    "source_date": "2025-09-25"
  },
  {
    "name": "Audience Segmentation Strategy",
    "type": "engagement_framework",
    "confidence": 0.88,
    "description": "A framework for segmenting different organizational teams into appropriate training sessions based on their role and needs",
    "components": [
      "Creative team: Separate session with tool vendors (Tool and Chromista)",
      "Marketing leadership: Workflow-focused session",
      "Product managers: Potentially automation-focused follow-up",
      "Decision logic: Match session type to team function and AI use case priority"
    ],
    "evidence_quote": "The creative team is going to hear from both Tool and Chromista. They both confirmed and so they're going to take like the creative team just going to go in a separate room... But I have talked to Hannah and Arielle about staying in this session because I think this is a good... I kind of feel like Alyssa should be in the creative... I would kind of like them all in creative. And then to do a separate.",
    "source_transcript": "transcripts_normalized/Marketing Offsite AI Workshop - Creative summary 2025-09-25 16_04 transcript.json",
    "source_date": "2025-09-25"
  },
  {
    "name": "AI Passenger vs AI Driver Model",
    "type": "model_framework",
    "confidence": 0.85,
    "description": "A conceptual model distinguishing between passive AI usage (passenger) and active AI direction (driver)",
    "components": [
      "AI Passenger: Passive usage mode",
      "AI Driver: Active direction mode"
    ],
    "evidence_quote": "And then as we were talking about this concept of the AI passenger versus an AI driver.",
    "source_transcript": "transcripts_normalized/Marketing Offsite AI Workshop - Creative summary 2025-09-25 16_04 transcript.json",
    "source_date": "2025-09-25"
  },
  {
    "name": "VIP Relationship Tiering and Touch Cadence System",
    "type": "model_framework",
    "confidence": 0.98,
    "description": "A three-tier relationship classification system that determines contact frequency requirements based on relationship priority level",
    "components": [
      "Tier 1: Monthly contact required",
      "Tier 2: Quarterly contact required",
      "Tier 3: Annual contact required",
      "Contact identification and labeling",
      "Automated stale relationship alerts"
    ],
    "evidence_quote": "We label them Tier 1, 2 or 3 Tier 1 contacts. We want to ensure that Paul has talked to them every month, tier 2 contacts every quarter and tier 3 contacts once a year. And so every month I surface the updates from that month, send him using touchpoint data from Affinity, send him the information on those people who are starting to become stale.",
    "source_transcript": "transcripts_normalized/Amanda Lennon and Kyra Atekwana 2025-09-22 14_00 transcript (2).json",
    "source_date": "2025-09-22"
  },
  {
    "name": "Rolodex Data Management Process",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "A multi-step process for capturing, storing, and surfacing relationship intelligence data using multiple tools in combination",
    "components": [
      "Capture personal details (dietary restrictions, family, interests)",
      "Port Affinity contacts into Coda for enrichment",
      "Add specific relationship intelligence manually",
      "Surface relevant data before meetings"
    ],
    "evidence_quote": "I have a combination of just an affinity list of Paul's contacts which I also port into Coda where I can add more specific information like dietary restrictions, spouse's name is Karen, loves the Bruins, that kind of information.",
    "source_transcript": "transcripts_normalized/Amanda Lennon and Kyra Atekwana 2025-09-22 14_00 transcript (2).json",
    "source_date": "2025-09-22"
  },
  {
    "name": "Information Capture and Data Preservation System",
    "type": "model_framework",
    "confidence": 0.9,
    "description": "A dual-function system architecture combining knowledge capture/preservation with relationship and ecosystem tracking",
    "components": [
      "Knowledge sharing/information hub (using Coda)",
      "Pipeline management (using Affinity)",
      "Data preservation protocols",
      "Ecosystem tracking capability",
      "Government relationship monitoring"
    ],
    "evidence_quote": "I administer the sort of knowledge sharing knowledge information hub for our global resilience team, which is the catch all phrase for all of those investing arms and then primarily for that use a combination of coda and affinity to capture data among our team. I spend a lot of time thinking about both information capture and data preservation as well as tracking.",
    "source_transcript": "transcripts_normalized/Amanda Lennon and Kyra Atekwana 2025-09-22 14_00 transcript (2).json",
    "source_date": "2025-09-22"
  },
  {
    "name": "High-Value Relationship Identification Criteria",
    "type": "decision_framework",
    "confidence": 0.87,
    "description": "A pattern-recognition framework for identifying valuable but under-cultivated relationships based on interaction characteristics rather than frequency",
    "components": [
      "Exclude high-frequency contacts (board members, regular touchpoints)",
      "Identify low-frequency, high-potential contacts",
      "Look for single meaningful introductions",
      "Track relationships that provided mutual value",
      "Flag relationships that 'fell off' after initial engagement"
    ],
    "evidence_quote": "These are going to be the people that a government official that he met once at a party, has exchanged a handful of emails with and maybe did a one on one call but then dropped off the face of the earth and we didn't foster that relationship. So looking for patterns in where to find those relationships, it's not going to be someone he's sitting on a board with. It's going to be someone that he, someone else introduced him to that was valuable that we helped a little bit.",
    "source_transcript": "transcripts_normalized/Amanda Lennon and Kyra Atekwana 2025-09-22 14_00 transcript (2).json",
    "source_date": "2025-09-22"
  },
  {
    "name": "AI Tool Governance Review Framework",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "A mandatory review process for AI tools requiring evaluation by three departments before implementation",
    "components": [
      "Privacy review",
      "Security review",
      "Legal review"
    ],
    "evidence_quote": "What we want to do is make sure that this is fully reviewed by privacy, Security and legal. Any AI features that are. Add ons or just standalone tools that assuring is using do need to be fully evaluated and we do need to have a record of that and make sure we understand what data is being kind of like provided to that.",
    "source_transcript": "transcripts_normalized/FW_ AI Job Description Project 2025-09-17 14_00 transcript.json",
    "source_date": "2025-09-17"
  },
  {
    "name": "Job Description Cleanup Automation Workflow",
    "type": "process_framework",
    "confidence": 0.95,
    "description": "A multi-step automated workflow for cleaning up missing job descriptions using AI and routing through HR business partners",
    "components": [
      "Load HR business partners into Workday by sew Orgs",
      "Create reporting to align HR business partners with job profiles missing descriptions",
      "Provide Excel file that feeds into AI tool",
      "AI tool creates job description",
      "Job description feeds to HR business partner for review/edit/approval",
      "Approved descriptions feed back into Excel sheet as EIB",
      "EIB upload into Workday"
    ],
    "evidence_quote": "I would provide you an Excel file that feeds into an AI tool that is going to create the job description. That job description is going to feed over to an HR business partner for them to be able to go in and edit, review, approve, and then that would feed back into another Excel sheet of an EI that would be the EIB upload to be. Be able to go into workday.",
    "source_transcript": "transcripts_normalized/FW_ AI Job Description Project 2025-09-17 14_00 transcript.json",
    "source_date": "2025-09-17"
  },
  {
    "name": "New Job Description Process Workflow",
    "type": "process_framework",
    "confidence": 0.88,
    "description": "A separate workflow for new job descriptions that routes through compensation team rather than direct Workday integration",
    "components": [
      "Generate new job description",
      "Route to compensation team",
      "Compensation team manually uploads to Workday"
    ],
    "evidence_quote": "The new job description process will not have to feed directly into workday because that goes to the compensation team, and then the compensation team will upload that manually.",
    "source_transcript": "transcripts_normalized/FW_ AI Job Description Project 2025-09-17 14_00 transcript.json",
    "source_date": "2025-09-17"
  },
  {
    "name": "HR Business Partner Assignment Framework",
    "type": "model_framework",
    "confidence": 0.85,
    "description": "An organizational model for assigning HR business partners based on sew Orgs structure",
    "components": [
      "Identify HR business partners by sew Orgs",
      "Load assignments into Workday",
      "Create reporting alignment with job profiles"
    ],
    "evidence_quote": "So the HR business partners have been identified according to sew Orgs. So what we're waiting on right now is for those to get loaded into workday. Once they're loaded into workday, then we'll be doing some fancy dancing reporting to align with those with the job profiles that are missing job descriptions.",
    "source_transcript": "transcripts_normalized/FW_ AI Job Description Project 2025-09-17 14_00 transcript.json",
    "source_date": "2025-09-17"
  },
  {
    "name": "Technical Build Decision Framework",
    "type": "decision_framework",
    "confidence": 0.9,
    "description": "A decision logic for determining whether to build temporary or permanent technical solutions based on process longevity",
    "components": [
      "If process is temporary (cleanup), use simple EIB Excel upload",
      "If process requires extensive development time, avoid for temporary solutions",
      "Prioritize speed over sophistication for one-time workflows"
    ],
    "evidence_quote": "I don't want you all to have to do a lot of technology build out for a temporary solution because once we do the cleanup, that process is kind of gone... I think just the EIB file upload on Excel is probably fine, as opposed to spending time doing development work.",
    "source_transcript": "transcripts_normalized/FW_ AI Job Description Project 2025-09-17 14_00 transcript.json",
    "source_date": "2025-09-17"
  },
  {
    "name": "Project Timeline Estimation Framework",
    "type": "measurement_framework",
    "confidence": 0.82,
    "description": "A framework for estimating project timelines with dependencies and milestones",
    "components": [
      "Governance review timeline: couple of weeks",
      "Job description generation development: 1-2 weeks",
      "HR business partner data loading: target October 1st",
      "Account for dependencies and variable factors"
    ],
    "evidence_quote": "I'd say a couple weeks. Right. If everyone's sort of like available and aligned, I think things can, can happen in a couple weeks... I think that would take me, like, maybe a week or two of development time.",
    "source_transcript": "transcripts_normalized/FW_ AI Job Description Project 2025-09-17 14_00 transcript.json",
    "source_date": "2025-09-17"
  },
  {
    "name": "Translation Policy Risk Assessment Framework",
    "type": "decision_framework",
    "confidence": 0.88,
    "description": "Decision logic for determining who should provide translated AI policies based on risk factors and technical constraints",
    "components": [
      "Assess technical capability (auto-translation availability)",
      "Evaluate risk factors (translation accuracy, data security)",
      "Determine responsibility (client vs. internal team)",
      "Consider roadmap timing (short-term vs. long-term solution)"
    ],
    "evidence_quote": "to me, ideally we would say for Japanese, whatever the other two are for the languages that are launching now, like, you give us a translated AI policy, but it's on our roadmap. So when you launch your long tail of like 20 other languages, you won't have to give us 20 policies.",
    "source_transcript": "transcripts_normalized/Asurion Standup 2025-11-10 12_46 transcript.json",
    "source_date": "2025-11-10"
  },
  {
    "name": "Feature Release Gating Process",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "Step-by-step process for releasing new features with client validation before full rollout",
    "components": [
      "Identify stakeholders for early access testing",
      "Provide select users early access",
      "Gather feedback and validate changes",
      "Confirm no blocking issues",
      "Schedule full rollout (turn on for everyone)",
      "Set clear deadline unless client objects"
    ],
    "evidence_quote": "we need to know who he wants to give access. I'm imagining he wants to give a select number of people early access and hopefully we can just turn it on with everyone else... I think we need to be clear, like this is going to be turned on unless, you know, barring anything you have to say around wanting to hold for a moment.",
    "source_transcript": "transcripts_normalized/Asurion Standup 2025-11-10 12_46 transcript.json",
    "source_date": "2025-11-10"
  },
  {
    "name": "Client Escalation Decision Framework",
    "type": "decision_framework",
    "confidence": 0.85,
    "description": "Logic for determining whether to escalate issues to client contacts versus resolving internally first",
    "components": [
      "Assess if issue understanding is complete",
      "Develop internal POV/recommendation",
      "Determine if client input is required",
      "Present recommendation to client with clear options"
    ],
    "evidence_quote": "where we left it off with Sam, it's like, let us go find out what's going on. So we haven't said anything as far as, like, we'll translate it, you'll translate it. We just need to go in with a POV of like, what do we recommend?",
    "source_transcript": "transcripts_normalized/Asurion Standup 2025-11-10 12_46 transcript.json",
    "source_date": "2025-11-10"
  },
  {
    "name": "Multi-Language Scaling Framework",
    "type": "scaling_framework",
    "confidence": 0.9,
    "description": "Approach for scaling from initial language launches to long-tail language support",
    "components": [
      "Phase 1: Handle immediate languages manually (client-provided translations)",
      "Phase 2: Add automation to roadmap for future scale",
      "Phase 3: Enable self-service for long-tail languages (20+ languages)"
    ],
    "evidence_quote": "ideally we would say for Japanese, whatever the other two are for the languages that are launching now, like, you give us a translated AI policy, but it's on our roadmap. So when you launch your long tail of like 20 other languages, you won't have to give us 20 policies.",
    "source_transcript": "transcripts_normalized/Asurion Standup 2025-11-10 12_46 transcript.json",
    "source_date": "2025-11-10"
  },
  {
    "name": "Stakeholder Alignment Process",
    "type": "engagement_framework",
    "confidence": 0.82,
    "description": "Process challenge identified around getting all stakeholders aligned before proceeding with project changes",
    "components": [
      "Identify all required stakeholders",
      "Schedule meeting with all stakeholders present",
      "Present new project proposal collectively (avoid one-at-a-time)",
      "Address workflow redesign blockers"
    ],
    "evidence_quote": "we're like very stalled right now, basically. Unfortunately, we didn't have all of the stakeholders on. We haven't had all of the stakeholders on a call yet. And when we pitched the new project, we have have only been able to talk to them one at a time.",
    "source_transcript": "transcripts_normalized/Asurion Standup 2025-11-10 12_46 transcript.json",
    "source_date": "2025-11-10"
  },
  {
    "name": "Prototype Development Sequence Framework",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "A sequential approach to building product prototypes, starting with brand fundamentals before moving to functional development",
    "components": [
      "Establish brand identity (colors, logo, visual elements)",
      "Create comprehensive user journey mapping",
      "Design phase execution",
      "Command center process review and optimization"
    ],
    "evidence_quote": "to get to a prototype, obviously you need colors, you need a brand, you need all those things, right? Logo, blah, blah, blah. So I think that's where it's probably critical. So I think we start there, and then we look at the command center and see if there's anything else we need to do to get that process moving.",
    "source_transcript": "transcripts_normalized/DeckSense 2025-09-18 09_05 transcript.json",
    "source_date": "2025-09-18"
  },
  {
    "name": "Research-Based Brand Development Framework",
    "type": "process_framework",
    "confidence": 0.88,
    "description": "A methodology for developing brand identity by studying existing frameworks and successful examples rather than arbitrary choices",
    "components": [
      "Research established brand design frameworks",
      "Identify industry patterns and standards (AI space specific)",
      "Study organizations with strong brand presence",
      "Apply design principles used by professional brand agencies"
    ],
    "evidence_quote": "I would like to, you know, use some sort of a framework. Like, I don't just want to pick colors and all of that stuff at random... I think there are standards for companies in the AI space. There are, like, patterns around how they design their branding",
    "source_transcript": "transcripts_normalized/DeckSense 2025-09-18 09_05 transcript.json",
    "source_date": "2025-09-18"
  },
  {
    "name": "Trust-Based Color Selection Framework",
    "type": "decision_framework",
    "confidence": 0.85,
    "description": "A decision logic for selecting brand colors based on the trust factor required for the product being built",
    "components": [
      "Identify core product value (trust in this case)",
      "Research color psychology aligned with that value",
      "Validate recommendations across multiple sources/LLMs",
      "Select colors that empirically convey the desired attribute"
    ],
    "evidence_quote": "it still boils down to choosing a color that gives trust based on what we're trying to build. And I know I was doing a lot of questioning on okay what we currently demoed or created using ChatGPT if it worked. And the recommendations that I got from the different LLMs was that the blue works, gray works and that seal also works.",
    "source_transcript": "transcripts_normalized/DeckSense 2025-09-18 09_05 transcript.json",
    "source_date": "2025-09-18"
  },
  {
    "name": "Competitive Landscape Assessment Framework",
    "type": "process_framework",
    "confidence": 0.93,
    "description": "A systematic approach to analyzing market competition by categorizing competitors and identifying white spaces",
    "components": [
      "Compile comprehensive list of competitors (100+ tools)",
      "Categorize by market segment (enterprise, consumer, education, etc.)",
      "Identify direct competitors in target segment",
      "Assess feature completeness of each competitor",
      "Map white spaces and opportunity gaps"
    ],
    "evidence_quote": "So using that table I sort of did like the AI presentation landscape using the... So there are just 12 when it comes to enterprise focus. 25 for consumer general use, 10 for education and academia, 15 for templates, marketplaces for startup and pitch decks.",
    "source_transcript": "transcripts_normalized/DeckSense 2025-09-18 09_05 transcript.json",
    "source_date": "2025-09-18"
  },
  {
    "name": "Feature Completeness Measurement Framework",
    "type": "measurement_framework",
    "confidence": 0.9,
    "description": "A methodology for measuring competitive advantage by assessing percentage completion of critical features against competitors",
    "components": [
      "Identify critical enterprise features (brand compliance, data security, system integration, analytics)",
      "Assess competitor completion levels (percentage-based)",
      "Set target completion thresholds (90-100%)",
      "Prioritize features where competitors are incomplete",
      "Measure own progress against these benchmarks"
    ],
    "evidence_quote": "So every tool that says they give brand compliance, they do brand compliance up until like 70% but not 100%. So if able to maybe, or maybe work towards achieving 100% then it will really be great for us... we need to like win on all these fronts on a hundred percent or maybe because 100 is like maybe utopia. Maybe you can aim for 90",
    "source_transcript": "transcripts_normalized/DeckSense 2025-09-18 09_05 transcript.json",
    "source_date": "2025-09-18"
  },
  {
    "name": "White Space Opportunity Framework",
    "type": "model_framework",
    "confidence": 0.91,
    "description": "A conceptual model for identifying and exploiting market gaps by comparing competitor capabilities across key enterprise dimensions",
    "components": [
      "Brand compliance (targeted 100% vs competitor 70%)",
      "Data security",
      "System integration",
      "Analytics and reporting",
      "Enterprise-specific needs vs. individual user focus"
    ],
    "evidence_quote": "we could be the most complete enterprise solution if we're able to execute flawlessly on those different white spaces that we have identified... we're really big on brand compliance... for data security... system integration... presents, present shows, analytics",
    "source_transcript": "transcripts_normalized/DeckSense 2025-09-18 09_05 transcript.json",
    "source_date": "2025-09-18"
  },
  {
    "name": "Big Player Risk Assessment Framework",
    "type": "decision_framework",
    "confidence": 0.87,
    "description": "A decision logic for validating market opportunity by assessing whether dominant players intend to address the same space",
    "components": [
      "Identify dominant market player (Microsoft in this case)",
      "Assess their current investment in the problem space",
      "Leverage insider intelligence to understand strategic intent",
      "Make go/no-go decision based on likelihood of direct competition",
      "Avoid investing if big player plans to compete directly"
    ],
    "evidence_quote": "one of the things that this is built on is that Microsoft is not investing a lot in solving some of these things... If they decide to go at it, you know, we're pretty much done for... is this smart? I have a few friends that work at Microsoft to ask... so that we don't start invest a lot of money and then we now have to quit halfway",
    "source_transcript": "transcripts_normalized/DeckSense 2025-09-18 09_05 transcript.json",
    "source_date": "2025-09-18"
  },
  {
    "name": "Three-Step AI Use Case Discovery Session",
    "type": "process_framework",
    "confidence": 0.98,
    "description": "A structured three-step process for evaluating and prioritizing AI use cases across an organization",
    "components": [
      "Step 1: High-level review of compiled use cases to identify gaps",
      "Step 2: Evaluate use cases based on potential impact (high/medium/low) considering efficiency and quality improvement",
      "Step 3: Align on top 3-5 needle movers for execution"
    ],
    "evidence_quote": "So in terms of objectives and next steps, there's three main steps to this session. First, we're going to take a high level view of the list of use cases that we shared... The second step, which is what we asked you guys to take a pass at before, is to evaluate all the use cases based on their potential impact... And then at the end we'll just wrap up and make sure we're all aligned on what are the big needle movers across this whole list? What are those top three to five things that we want to go ahead and execute on",
    "source_transcript": "transcripts_normalized/FW_ Core Connect AI Discovery & Prioritization Session 2025-08-08 11_00 transcript.json",
    "source_date": "2025-08-08"
  },
  {
    "name": "Dual-Criteria Impact Assessment Framework",
    "type": "measurement_framework",
    "confidence": 0.92,
    "description": "A framework for evaluating AI use cases using two primary impact dimensions: efficiency gains and quality improvements",
    "components": [
      "Efficiency potential: reduction in workload and time",
      "Quality potential: improvements not possible without AI",
      "Impact categorization: high, medium, or low",
      "Roadblock identification: adoption barriers and systematic changes needed"
    ],
    "evidence_quote": "So do we think this use case has a high efficiency potential, like it'll reduce the workload and the time it takes to do things today, or do we think that this use case has the potential to improve the quality in a way that is kind of not possible if we didn't have an AI tool, We'd also want to know if there's any roadblocks, like do we think there's key enablers to drive adoption for some of these use cases or key systematic things that need to change",
    "source_transcript": "transcripts_normalized/FW_ Core Connect AI Discovery & Prioritization Session 2025-08-08 11_00 transcript.json",
    "source_date": "2025-08-08"
  },
  {
    "name": "AI Pilot-to-Production Framework",
    "type": "scaling_framework",
    "confidence": 0.9,
    "description": "A structured approach for moving from AI tool selection through testing, piloting, and tracking success metrics",
    "components": [
      "Research suitable AI tools (focusing on top 3-5 use cases)",
      "Create testing and piloting plan",
      "Track KPIs",
      "Ensure tools enhance existing workflows"
    ],
    "evidence_quote": "we're going to start researching like suitable AI tools, obviously focusing on these top three to five use cases and then coming up with a plan for testing, piloting, tracking KPIs and making sure that the tools are serving the needs and enhancing the workflows as we know them today",
    "source_transcript": "transcripts_normalized/FW_ Core Connect AI Discovery & Prioritization Session 2025-08-08 11_00 transcript.json",
    "source_date": "2025-08-08"
  },
  {
    "name": "Functional Group Engagement Structure",
    "type": "engagement_framework",
    "confidence": 0.88,
    "description": "An organizational approach to conducting AI discovery sessions by grouping functions logically while enabling cross-functional tool sharing",
    "components": [
      "Conduct sessions by high-level function (HR, legal, supply chain, product, etc.)",
      "Group related sub-functions within sessions",
      "Enable cross-functional use case and tool sharing",
      "Assign AI champions for each function",
      "Create periodic connection points between champions with similar responsibilities"
    ],
    "evidence_quote": "we've tried to group these sessions in as logical as possible. So we think about it as like high level function sessions, one for hr, for legal, for supply chain... our goal is to also enable like cross functional use cases and tool sharing because I think that's going to be really beneficial to drive adoption at a greater scale... we do have AI champions identified for each function... there's a benefit to having for example, the AI champions from the people who are AI champions in different functions that have production. Management responsibilities, it's probably beneficial for those people to periodically conn",
    "source_transcript": "transcripts_normalized/FW_ Core Connect AI Discovery & Prioritization Session 2025-08-08 11_00 transcript.json",
    "source_date": "2025-08-08"
  },
  {
    "name": "New Hire Onboarding Process",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "Step-by-step methodology for onboarding new employees from notification to successful onboarding",
    "components": [
      "Receive notification from Bamboo HR with hire details (name, team, location, manager)",
      "Add to company-wide new hire tracker with start dates and details",
      "Create personal tracker in Google Sheets with task checklist",
      "Add start date to executive's calendar",
      "Send email to hiring manager",
      "Schedule required meetings (TNE compliance, day one, week one, month one)",
      "Send pre-start email to new hire (10 days before start)",
      "Monitor tracker daily and check off completed tasks"
    ],
    "evidence_quote": "Basically we get a notification from Bamboo HR saying, you know, that this is the new hire. This is the team they're on, is the location they're in. And then from there I then put it into. We have like so many different trackers. We have one tracker that has all of our new hires in one place and the dates they start... Then I have my own personal tracker... Basically I'm like all the steps I need to take before, before this person starts. So adding it, adding the hire to my executive's calendar, their start date, sending an email to the hiring manager, scheduling. And then I have each meeting that needs to be scheduled.",
    "source_transcript": "transcripts_normalized/Valentina Pannullo and Kyra Atekwana 2025-09-22 15_31 transcript (1).json",
    "source_date": "2025-09-22"
  },
  {
    "name": "Needs Assessment Discovery Framework",
    "type": "engagement_framework",
    "confidence": 0.88,
    "description": "Structured approach to understanding client organizational needs for custom AI training",
    "components": [
      "Learn about the individual and their background",
      "Understand scope of role and responsibilities",
      "Review typical week structure and recurring tasks",
      "Deep dive into specific processes and pain points",
      "Identify automation and improvement opportunities"
    ],
    "evidence_quote": "So I work with all of our clients to basically do what I'm doing right now, understand what the needs are within the organization and then build some custom learning content based on that... First question, would just love to learn a little bit more about you and if you could sort of give me a little insight on the scope of your role... if we had to take a week at a glance, like what does your week typically look like... I would actually love to dig into that a little bit deeper.",
    "source_transcript": "transcripts_normalized/Valentina Pannullo and Kyra Atekwana 2025-09-22 15_31 transcript (1).json",
    "source_date": "2025-09-22"
  },
  {
    "name": "Time-Based Task Trigger System",
    "type": "decision_framework",
    "confidence": 0.85,
    "description": "Manual decision logic for determining when onboarding tasks need to be completed based on time thresholds",
    "components": [
      "Monitor tracker daily for upcoming start dates",
      "If less than 10 days before start date and new hire email not sent, send email",
      "Check off tasks as completed",
      "Execute tasks based on proximity to start date"
    ],
    "evidence_quote": "I just live in this sheet and I know like for example, like I just said on the 30th we're getting closer. So now I just go into the sheet every day. I just kind of check off the things that I need to do, and I just know when. Like if I haven't sent the new hire that email yet and it's now less than 10 days before, I just know that, that I need to do that.",
    "source_transcript": "transcripts_normalized/Valentina Pannullo and Kyra Atekwana 2025-09-22 15_31 transcript (1).json",
    "source_date": "2025-09-22"
  },
  {
    "name": "AI Solution Assessment Framework",
    "type": "decision_framework",
    "confidence": 0.79,
    "description": "Logic for determining appropriate technical solution based on process characteristics",
    "components": [
      "Assess if tasks are trigger-based (one step triggers next) or time-based",
      "If trigger-based, consider agent automation (e.g., Make)",
      "If time-based with dependencies, consider Google Apps Script",
      "Evaluate if AI is appropriate or if traditional automation is better",
      "Determine level of personalization required"
    ],
    "evidence_quote": "I was asking about the triggers, because I was just curious to know, is it like, okay, once this get thing gets done, then this thing should automatically be done. In which case, you know, you can use make to create an agent that just gets triggered every time the next step happens versus it sounds like it's dependent on some factors and so they're not necessarily related to one another. So maybe actually a Google Apps script automation might be more relevant there. I think AI is a great solution, but not always necessarily the right solution",
    "source_transcript": "transcripts_normalized/Valentina Pannullo and Kyra Atekwana 2025-09-22 15_31 transcript (1).json",
    "source_date": "2025-09-22"
  },
  {
    "name": "Media Team Workflow Framework",
    "type": "process_framework",
    "confidence": 0.98,
    "description": "Three-stage sequential workflow for media planning and execution: Planning, Activation, and Optimization",
    "components": [
      "Planning - Develop media plans responsive to business problems, competitive/cultural/consumer context, and select right media touchpoints",
      "Activation - Steward implementation working with internal/external stakeholders, including budget management, finance, asset delivery",
      "Optimization - Assess in-market performance and identify optimization levers to drive stronger outcomes"
    ],
    "evidence_quote": "So from a planning perspective, the team is working to develop media plans that are responsive to the brand's business problem, to solve competitive context, cultural and consumer context... From an activation standpoint, then they are stewarding the implementation and activation of those plans... And then from an optimization standpoint that's assessing actual in market performance, identifying optimization levers to drive stronger outcomes.",
    "source_transcript": "transcripts_normalized/Pernod Ricard Interview - Jenny + Kathryn 2025-07-14 07_31 transcript.json",
    "source_date": "2025-07-14"
  },
  {
    "name": "Dual-Purpose AI Implementation Framework",
    "type": "model_framework",
    "confidence": 0.92,
    "description": "Two-layered approach to AI adoption covering both individual usage and organizational use cases within functional pillars",
    "components": [
      "Personal usage layer - Individual team member AI tool adoption and learning",
      "Pillar-specific use cases layer - Functional area applications (e.g., media practice, content excellence, creative production)"
    ],
    "evidence_quote": "I want them to talk about that but then also for the use cases of what we're talking about... it's almost dual purpose it's personal usage. And use cases within their pillars.",
    "source_transcript": "transcripts_normalized/Pernod Ricard Interview - Jenny + Kathryn 2025-07-14 07_31 transcript.json",
    "source_date": "2025-07-14"
  },
  {
    "name": "Content AI Deployment Timeline Framework",
    "type": "scaling_framework",
    "confidence": 0.85,
    "description": "Phased approach to scaling AI in content operations from current nascent state to full deployment over 3-6 month timeline",
    "components": [
      "Current state - Limited AI usage, primarily LLM tools for ideation and wordsmithing",
      "Near-term (3-6 months) - Deployment of specific internal and external AI products pending HQ approval",
      "Scale requirement - Rapid deployment needed to reach market-ready state"
    ],
    "evidence_quote": "my day to day team currently is not using AI in the way that it will need to be deployed over the course of the next three to six months... I would say my team, as far as how it plans to be is going forward, is very much still nascent in some of those areas that we need to rapidly, rapidly get to market.",
    "source_transcript": "transcripts_normalized/Pernod Ricard Interview - Jenny + Kathryn 2025-07-14 07_31 transcript.json",
    "source_date": "2025-07-14"
  },
  {
    "name": "Content Workflow Gating Framework",
    "type": "decision_framework",
    "confidence": 0.88,
    "description": "Decision hierarchy where HQ serves as decision-maker and gatekeeper for key AI tool deployment in content workflows",
    "components": [
      "HQ decision gate - Headquarters approval required for key AI tool deployment",
      "Dual workstream structure - Current limited operations running parallel to planned future state",
      "Tool-specific paths - Separate approval tracks for internal vs external products"
    ],
    "evidence_quote": "we have our HQ currently the decision maker around some of the key tools that we could deploy from a content standpoint. And so there's kind of two work streams going on in that area... There are two specific paths right now for two specific products. One is an internal and one is an external.",
    "source_transcript": "transcripts_normalized/Pernod Ricard Interview - Jenny + Kathryn 2025-07-14 07_31 transcript.json",
    "source_date": "2025-07-14"
  },
  {
    "name": "Meeting Structure and Reporting Framework",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "A structured approach to meeting management where each committee chair provides status updates sequentially, followed by Q&A",
    "components": [
      "Get updates from every subcommittee or committee chair",
      "Each chair/representative reports planning progress",
      "Budget committee reports included",
      "Open floor for questions"
    ],
    "evidence_quote": "The agenda was to get updates from every subcommittee or every committee chair on planning so far. So basically every chair or representative will tell us how far you are with planning and what to do. And then that includes budget committee as well, by the way... And then we ask, then the last item will be ask questions.",
    "source_transcript": "transcripts_normalized/Pa Nkwate Funeral Planning 2025-11-23 13_33 transcript.json",
    "source_date": "2025-11-23"
  },
  {
    "name": "Committee-Based Planning Structure",
    "type": "model_framework",
    "confidence": 0.88,
    "description": "An organizational model utilizing multiple subcommittees with designated chairs responsible for specific planning domains",
    "components": [
      "Multiple subcommittees with chairs",
      "Planning groups (US-based and Cameroon-based)",
      "Specialized subcommittees (e.g., audio subcommittee)",
      "Budget committee oversight"
    ],
    "evidence_quote": "Is he in the planning group for America?... he's in the subcommittee for audio... that includes budget committee as well",
    "source_transcript": "transcripts_normalized/Pa Nkwate Funeral Planning 2025-11-23 13_33 transcript.json",
    "source_date": "2025-11-23"
  },
  {
    "name": "Access Control Decision Framework",
    "type": "decision_framework",
    "confidence": 0.85,
    "description": "Logic for determining committee membership based on geographic relevance and role requirements",
    "components": [
      "Assess geographic relevance (US vs general planning)",
      "Determine role-specific needs",
      "Administrator approval for access",
      "Specialized subcommittee assignments"
    ],
    "evidence_quote": "This is not the U. S. Planning group. This is the general thought... He's in the US One... Is he in the planning group for America?... he's in the subcommittee for audio",
    "source_transcript": "transcripts_normalized/Pa Nkwate Funeral Planning 2025-11-23 13_33 transcript.json",
    "source_date": "2025-11-23"
  },
  {
    "name": "Train-the-Trainer Delivery Model",
    "type": "model_framework",
    "confidence": 0.92,
    "description": "A three-layer approach to upskilling internal champions: (1) Deliver semi-customized content to champions, (2) Champions customize further for their teams, (3) Champions train their teams",
    "components": [
      "Semi-customized baseline content from vendor",
      "Champion-level customization for team context",
      "Champion-led training delivery to end users"
    ],
    "evidence_quote": "So I think the way we would do it is like kind of like semi custom and then we would like want them to custom even further for their team because like that's the role of a champion... We are upskilling the champion so they can turn and teach.",
    "source_transcript": "transcripts_normalized/Talk Autodesk Train the Trainer 2025-10-23 14_46 transcript.json",
    "source_date": "2025-10-23"
  },
  {
    "name": "Workshop Content Customization Process",
    "type": "process_framework",
    "confidence": 0.88,
    "description": "A process for customizing training workshops: (1) Use interview transcripts and existing research to identify relevant use cases, (2) Semi-customize workshop content with those use cases, (3) Enable client to further customize for their specific teams",
    "components": [
      "Extract use cases from transcripts/interviews",
      "Identify most valuable use cases for client context",
      "Semi-customize workshop content",
      "Client performs final team-specific customization"
    ],
    "evidence_quote": "I think what we could do in terms of customizations is like, I'll probably just use the transcripts and stuff that you guys have from your interviews... Basically identify what are the use cases that are going to be most valuable to them... And then it's like, obviously you guys know your team's best. You know the work that they do best. You can see how to build on this and then deliver it.",
    "source_transcript": "transcripts_normalized/Talk Autodesk Train the Trainer 2025-10-23 14_46 transcript.json",
    "source_date": "2025-10-23"
  },
  {
    "name": "90-Minute Train-the-Trainer Session Structure",
    "type": "process_framework",
    "confidence": 0.85,
    "description": "A time-boxed session format: 45 minutes covering workflow workshop content, 45 minutes on teaching methodology",
    "components": [
      "45 minutes on workflow workshop content (strategic decision makers and marketing workflows)",
      "45 minutes on how to teach and unpack a workflow workshop"
    ],
    "evidence_quote": "That. Actually, I think that's fine because the flow for strategic decision makers and, and marketing is the same. So we could be like 45 minutes... Five minutes on like how to teach and unpack a workflow workshop.",
    "source_transcript": "transcripts_normalized/Talk Autodesk Train the Trainer 2025-10-23 14_46 transcript.json",
    "source_date": "2025-10-23"
  },
  {
    "name": "Scope Control Decision Framework",
    "type": "decision_framework",
    "confidence": 0.8,
    "description": "Decision logic for managing scope in fixed-price engagements: If client wants multiple deep-dive workshops, that requires custom workshop pricing; if budget is limited, consolidate into single train-the-trainer session covering multiple topics at overview level",
    "components": [
      "Assess if request is for deep customization (3 custom workshops)",
      "Check if budget supports deep customization",
      "If budget insufficient, offer consolidated train-the-trainer alternative",
      "Limit to knowledge base content only"
    ],
    "evidence_quote": "So what Taylor said is we will do one like one 90 minute. Because we, like if they, we had talked to them, like, if we, if they wanted us to go deep on each topic. If we'd like three, essentially three workshops. Like that's three custom workshops. And they paid all in like not enough money to have something like that.",
    "source_transcript": "transcripts_normalized/Talk Autodesk Train the Trainer 2025-10-23 14_46 transcript.json",
    "source_date": "2025-10-23"
  },
  {
    "name": "Product Development Workflow Framework",
    "type": "process_framework",
    "confidence": 0.98,
    "description": "A six-step methodology for moving from initial discovery through to user story creation in Jira, including capture, drafting, review, prioritization, scoping, and transition to engineering.",
    "components": [
      "Capture discovery inputs",
      "Draft brief in Notion",
      "Brief review and triage/prioritize",
      "Assign ownership to PM and scope",
      "Draft PRD with engineering review",
      "Transpose to Jira user stories"
    ],
    "evidence_quote": "The first thing that happens is there's some sort of capturing of discovery inputs...then there is a draft brief that gets created in Notion and then that brief is triaged and prioritized...that brief is an assigned ownership to a PM who will scope it out and then draft the prd...then that draft PRD is then transposed into jira, into user stories in jira.",
    "source_transcript": "transcripts_normalized/PRD Process Deep Dive & KPI Mapping 2025-10-20 16_30 transcript.json",
    "source_date": "2025-10-20"
  },
  {
    "name": "Brief Triage Decision Framework",
    "type": "decision_framework",
    "confidence": 0.92,
    "description": "A decision gate framework where briefs are reviewed with business owner/leader to determine if the problem is worth solving and prioritizing for the team's time.",
    "components": [
      "Review brief with business owner/leader",
      "Evaluate: Is this the right problem?",
      "Evaluate: Is this worth the team's time?",
      "Decision: Proceed to PRD or deprioritize"
    ],
    "evidence_quote": "There's usually some review of the brief done, whether that's live or asynchronously with either business owner leader kind of to get input to say, yeah, is this the right problem we're solving for and is this worth. Worth the team's time? I think that's a key decision point is there's plenty of briefs out there that never make it to a prd.",
    "source_transcript": "transcripts_normalized/PRD Process Deep Dive & KPI Mapping 2025-10-20 16_30 transcript.json",
    "source_date": "2025-10-20"
  },
  {
    "name": "AI Workflow Design Framework",
    "type": "process_framework",
    "confidence": 0.95,
    "description": "A methodology for redesigning workflows with AI by documenting workflow steps, ownership, inputs/outputs, and metrics to bridge the gap between AI training data and team-specific context.",
    "components": [
      "Map and align on workflow steps",
      "Define step ownership",
      "Document inputs and outputs for each step",
      "Identify metrics for each step",
      "Fill context gap between AI training and team specifics"
    ],
    "evidence_quote": "Who owns these steps, what goes into and comes out of them, and then what metrics do we have for those steps?...when we're redesigning workflows with AI, there really is no detail that's too small because what we want to do is fill the gap between AI's training data and your team's specific context.",
    "source_transcript": "transcripts_normalized/PRD Process Deep Dive & KPI Mapping 2025-10-20 16_30 transcript.json",
    "source_date": "2025-10-20"
  },
  {
    "name": "Engineering PRD Review Framework",
    "type": "decision_framework",
    "confidence": 0.88,
    "description": "A validation framework where engineering reviews draft PRDs to assess whether there is sufficient detail and understanding before proceeding to development.",
    "components": [
      "Engineering reviews draft PRD",
      "Assess: Is there enough detail?",
      "Assess: Do we understand the problem?",
      "Assess: Do we understand the requirements?",
      "Provide feedback for iteration or approval"
    ],
    "evidence_quote": "Usually what I'll see from our teams is engineering will review that at some point...And essentially give input to say, this is enough detail. It's not enough detail. I understand the problem. I don't. You know, I understand the requirements. I don't.",
    "source_transcript": "transcripts_normalized/PRD Process Deep Dive & KPI Mapping 2025-10-20 16_30 transcript.json",
    "source_date": "2025-10-20"
  },
  {
    "name": "AI Prototyping Integration Model",
    "type": "model_framework",
    "confidence": 0.85,
    "description": "A conceptual model showing how AI-generated prototypes (V0) supplement or replace traditional PRD processes over time, with the balance shifting based on team maturity and problem complexity.",
    "components": [
      "Traditional PRD (baseline documentation)",
      "V0 prototype generation (supplemental/replacement)",
      "Context factors: engineer tenure, problem space familiarity, detail comfort level",
      "Evolution trajectory: supplemental \u2192 partial replacement \u2192 full replacement"
    ],
    "evidence_quote": "I would say definitely supplements step five. I don't think we're at the point of completely getting rid of PRDs, but it may depend on the level of tenure of the engineers, on the problem space, and if they're comfortable enough with less detail to go straight into dev...If PRDs and PRDs are up here and V0 is here, in terms of the level of contribution to an overall product requirement at V0 goes up over time. The traditional PRD goes down over time.",
    "source_transcript": "transcripts_normalized/PRD Process Deep Dive & KPI Mapping 2025-10-20 16_30 transcript.json",
    "source_date": "2025-10-20"
  },
  {
    "name": "Workshop Content Development Process",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "A sequential process for creating workshop content from initial concept to completed template, with custom GPTs supporting each step",
    "components": [
      "Create a brief",
      "Do research",
      "Develop workflows",
      "Find AI use cases",
      "Generate completed workshop template content"
    ],
    "evidence_quote": "the first step is to create a brief and then the second step is to do research. Then the third step is to develop workflows and then the fourth step is to find AI use cases. And then those, you know, those intermediary three steps are what creates the content.",
    "source_transcript": "transcripts_normalized/\u2728 Kyra Atekwana and Hannah Tsumoto 2025-09-24 10_02 transcript.json",
    "source_date": "2025-09-24"
  },
  {
    "name": "Use Case Identification and Solution Building Framework",
    "type": "process_framework",
    "confidence": 0.88,
    "description": "A three-step methodology for moving from prioritized workflows to AI solutions, involving goal identification, workflow mapping, and solution design",
    "components": [
      "Prioritize your workflow (identify top use cases)",
      "Identify goals for the workflow",
      "Map out the workflow with specific tasks and steps",
      "Build solution (custom GPT or prompts) aligned to workflow steps"
    ],
    "evidence_quote": "we already know what the top two are for everybody, so we can skip the prioritization and just start talking about, okay, you have your workflow that you've prioritized. Now how do you think about what your goals are around that? And then... It would be helpful to actually map out that workflow for those top two that have been identified",
    "source_transcript": "transcripts_normalized/\u2728 Kyra Atekwana and Hannah Tsumoto 2025-09-24 10_02 transcript.json",
    "source_date": "2025-09-24"
  },
  {
    "name": "Goal-Driven Solution Design Framework",
    "type": "decision_framework",
    "confidence": 0.85,
    "description": "A decision framework where the type of goal (efficiency vs quality) influences the nature of the AI solution designed",
    "components": [
      "Identify workflow goal (efficiency vs quality)",
      "Goal determines solution approach",
      "Solution design varies based on goal type"
    ],
    "evidence_quote": "What your goal is when you're thinking about to go to Slide 6, efficiency versus quality, I think will influence the kind of solution that you ultimately come up with.",
    "source_transcript": "transcripts_normalized/\u2728 Kyra Atekwana and Hannah Tsumoto 2025-09-24 10_02 transcript.json",
    "source_date": "2025-09-24"
  },
  {
    "name": "Single-Purpose GPT Design Principle",
    "type": "model_framework",
    "confidence": 0.87,
    "description": "A design principle advocating for creating separate custom GPTs for each step in a process rather than one complex GPT, to maintain focus and effectiveness",
    "components": [
      "One custom GPT per workflow step",
      "Each GPT has single, focused goal",
      "Avoid multi-goal 'monster prompts'",
      "Chain GPTs together for complete workflow"
    ],
    "evidence_quote": "I have a custom GPT for every step in that process. And the reason why is because if you have more than one goal for a GPT, it can be kind of challenging to get it to do all of the things. The right things, because, you know, it's like a monster prompt.",
    "source_transcript": "transcripts_normalized/\u2728 Kyra Atekwana and Hannah Tsumoto 2025-09-24 10_02 transcript.json",
    "source_date": "2025-09-24"
  },
  {
    "name": "Workflow vs Use Case Distinction Framework",
    "type": "model_framework",
    "confidence": 0.83,
    "description": "A conceptual framework distinguishing between a complete workflow (multiple steps) and a use case (single step within that workflow)",
    "components": [
      "Workflow: Complete end-to-end process with multiple steps",
      "Use case: Individual step or task within the workflow",
      "Example: QA is one step within campaign building workflow"
    ],
    "evidence_quote": "when I look at this, this is the workflow, in my opinion, this whole thing and the one step literally that the team is talking about here, this QA step, Is here in campaign building and development... That's not a workflow. That's one step in the process.",
    "source_transcript": "transcripts_normalized/\u2728 Kyra Atekwana and Hannah Tsumoto 2025-09-24 10_02 transcript.json",
    "source_date": "2025-09-24"
  },
  {
    "name": "Team Alignment and Validation Framework",
    "type": "engagement_framework",
    "confidence": 0.79,
    "description": "A collaborative approach to ensure team agreement on workflow steps and corresponding prompts before building AI solutions",
    "components": [
      "Map out workflow together",
      "Ensure team agreement on tasks to include",
      "Validate steps for custom GPT/prompts",
      "Align on prompts for each workflow step"
    ],
    "evidence_quote": "It would be helpful to actually map out that workflow for those top two that have been identified, just to make sure that everybody is in agreement, you know, about. These are the right tasks to include... And we agree as a team that these are the steps that we want the GPT to go through.",
    "source_transcript": "transcripts_normalized/\u2728 Kyra Atekwana and Hannah Tsumoto 2025-09-24 10_02 transcript.json",
    "source_date": "2025-09-24"
  },
  {
    "name": "Enterprise AI Use Case Prioritization Framework",
    "type": "process_framework",
    "confidence": 0.98,
    "description": "A four-step methodology for identifying, documenting, evaluating, and prioritizing AI applications across an organization",
    "components": [
      "Step 1: Document all use cases - gather what AI is being applied to today and what could be applied in the future across all functions",
      "Step 2: Align understanding - review use cases with stakeholders to ensure common understanding and capture missing items",
      "Step 3: Evaluate and prioritize - assess AI impact, understand efficiency/quality gains, identify blockers, and plan for adoption",
      "Step 4: Implement - identify suitable tools/processes for prioritized use cases, test and pilot them"
    ],
    "evidence_quote": "step one. Get all these use cases kind of documented somewhere...now today's goal is kind of one, go through all these use cases, make sure we kind of all have the same understanding so that we can...two, prioritize them all...And then with any time remaining we can kind of prioritize among the highs maybe. And then I guess for your guys context our next step then is like hey once we have these use cases...for the ones that aren't, like identify suitable tools, new processes and then kind of test those out, pilot those going forward.",
    "source_transcript": "transcripts_normalized/Customer Solutions - AI Discovery & Prioritization 2025-08-07 11_02 transcript.json",
    "source_date": "2025-08-07"
  },
  {
    "name": "AI Impact Assessment Framework",
    "type": "measurement_framework",
    "confidence": 0.92,
    "description": "A framework for evaluating AI initiatives based on multiple impact dimensions including efficiency, quality, implementation readiness, and adoption requirements",
    "components": [
      "Impact magnitude assessment - classify as high/medium/low impact",
      "Efficiency gains - measure time or resource savings",
      "Quality improvement - assess output quality enhancement",
      "Blocker identification - understand what prevents rollout",
      "Adoption planning - determine requirements to drive usage"
    ],
    "evidence_quote": "evaluating that on the AI impact and really trying to understand the reasoning for that kind of what the lift is. Are we gaining a lot of efficiency? Is it improving the quality of the output? Is it both? And then kind of understand for the ones that aren't rolled out, are there blockers that have kind of been preventing that? Is it just that we haven't gotten around to it? And then when we do kind of start addressing those use cases, what do we really need to do to drive adoption",
    "source_transcript": "transcripts_normalized/Customer Solutions - AI Discovery & Prioritization 2025-08-07 11_02 transcript.json",
    "source_date": "2025-08-07"
  },
  {
    "name": "Parallel Execution Prioritization Framework",
    "type": "scaling_framework",
    "confidence": 0.85,
    "description": "An approach that allows for flexible prioritization while enabling parallel work streams to continue without being blocked by rank ordering",
    "components": [
      "Create prioritized list of top use cases",
      "Allow parallel execution of lower-priority items if resources available",
      "Avoid blocking work already underway or in pipeline regardless of priority rank"
    ],
    "evidence_quote": "let's like right click our top five just in case, you know, resource wise, there's not an ability to go and do the laundry list, but to the extent these can be done in parallel. Great. Like we don't want to hold anything up just because it's not on 1 through 5 if you already have work underway or work coming down on those.",
    "source_transcript": "transcripts_normalized/Customer Solutions - AI Discovery & Prioritization 2025-08-07 11_02 transcript.json",
    "source_date": "2025-08-07"
  },
  {
    "name": "AI Scope Boundary Framework",
    "type": "decision_framework",
    "confidence": 0.88,
    "description": "A framework for determining which AI initiatives to include in transformation work based on customer-facing vs. internal operations distinction",
    "components": [
      "Exclude customer-facing AI applications already in progress (conversational IVR, AI chat agents, expert assist)",
      "Include internal/back-office functions",
      "Separate scope based on existing work streams to avoid duplication"
    ],
    "evidence_quote": "using AI and Saluto and claims to either serve customers with like things like conversational IVR or AI chat agents or AI expert assist for solving and selling. We've kind of kept those out of scope for now just because there's so much work already underway in those. So focus of this conversation is more on. Yeah, like for again, maybe not the right exact term, but back office type functions.",
    "source_transcript": "transcripts_normalized/Customer Solutions - AI Discovery & Prioritization 2025-08-07 11_02 transcript.json",
    "source_date": "2025-08-07"
  },
  {
    "name": "Phased Workshop Delivery Framework",
    "type": "process_framework",
    "confidence": 0.85,
    "description": "A multi-phase delivery approach where workshops are sequenced with the 'Why of AI' workshop as first priority, followed by workforce deep dives, with insights delivery timed to client milestones",
    "components": [
      "Phase 1: Why of AI workshop delivery",
      "Phase 2: Workforce deep dive research",
      "Phase 3: Initial insights presentation at leadership event",
      "Phase 4: Full deliverable readouts post-event"
    ],
    "evidence_quote": "The way we framed is is insights and I think that's appropriate given that they're already going. They're definitely to be launching their vision or manifesto, whatever they decide to call it. So like that's the big focus and then we can share some initial insights about the workforce... not assuming that we even necessarily have to do those deliverable readouts until January",
    "source_transcript": "transcripts_normalized/AIT Consulting Weekly  2025-10-30 11_01 transcript.json",
    "source_date": "2025-10-30"
  },
  {
    "name": "Adaptive Engagement Framework",
    "type": "engagement_framework",
    "confidence": 0.78,
    "description": "A flexible engagement approach that adapts deliverables based on client context and existing programs, scaling scope up or down as appropriate",
    "components": [
      "Assess client's broader program context",
      "Determine appropriate deliverable scope",
      "Adapt standard methodology to fit needs",
      "Focus on most relevant insights/recommendations"
    ],
    "evidence_quote": "Well, because they don't want to. Like, this is like a smaller part of an overall program. So, like the whole transformation roadmap doesn't make sense. So, like, we surfaced some insights from their first readout of just, like, main things that, like, they're struggling with. And so we were going to give them, like, recommendations to deal with that. And it is. It'll be like a roadmap, but it won't be as, like, comprehensive because this is just a part of a much bigger plan that they're doing.",
    "source_transcript": "transcripts_normalized/AIT Consulting Weekly  2025-10-30 11_01 transcript.json",
    "source_date": "2025-10-30"
  },
  {
    "name": "Priority-Based Resource Allocation Framework",
    "type": "decision_framework",
    "confidence": 0.72,
    "description": "A decision logic for prioritizing client work based on confirmation status and strategic importance, with lower-priority engagements receiving reduced attention",
    "components": [
      "Assess client confirmation and commitment level",
      "Rank engagements by strategic importance",
      "Allocate resources accordingly",
      "Deprioritize unconfirmed work"
    ],
    "evidence_quote": "And quite frankly, we haven't done as much on this one because as you and I said, like, it went to the bottom because they just, you know, didn't confirm.",
    "source_transcript": "transcripts_normalized/AIT Consulting Weekly  2025-10-30 11_01 transcript.json",
    "source_date": "2025-10-30"
  },
  {
    "name": "Milestone-Driven Deliverable Framework",
    "type": "process_framework",
    "confidence": 0.8,
    "description": "A delivery approach that aligns engagement outputs and milestones with client's key events and decision points",
    "components": [
      "Identify client's critical dates/events",
      "Sequence deliverables to support those milestones",
      "Deliver insights appropriate to timing",
      "Schedule full readouts post-milestone"
    ],
    "evidence_quote": "the challenging part of HAVAS is they have a leadership off site on January 13th that they want to have both the output of the Y of AI for and initial insights from their deep dive for... So we have to also like define the why of AI. We have some of that but kind of pulling some things together from existing workshops, building new.",
    "source_transcript": "transcripts_normalized/AIT Consulting Weekly  2025-10-30 11_01 transcript.json",
    "source_date": "2025-10-30"
  },
  {
    "name": "AI Transformation Upskilling Framework",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "A methodology for AI transformation that combines use case identification, workflow redesign, and educational programming",
    "components": [
      "Identify generative AI use cases",
      "Redesign workflows using AI",
      "Create courses, workshops and boot camps"
    ],
    "evidence_quote": "my expertise is in generative AI and coming up with use cases and helping redesign workflows using AI and then creating courses and workshops and boot camps around that",
    "source_transcript": "transcripts_normalized/[PARTNERSHIPS + TECH] Martech 101 Discovery Session  2025-06-23 14_00 transcript.json",
    "source_date": "2025-06-23"
  },
  {
    "name": "Technology Ecosystem Architecture Framework",
    "type": "model_framework",
    "confidence": 0.88,
    "description": "A model for realizing product vision through strategic technology partnerships and integrations",
    "components": [
      "Technology partnership formulation",
      "Technology integration",
      "Connection to product team"
    ],
    "evidence_quote": "the full vision of Blue is largely going to be realized through technology partnership and technology integration. And so helping formulate that ecosystem and connect it to the product team is where I focused my time now",
    "source_transcript": "transcripts_normalized/[PARTNERSHIPS + TECH] Martech 101 Discovery Session  2025-06-23 14_00 transcript.json",
    "source_date": "2025-06-23"
  },
  {
    "name": "MarTech Training Two-Goal Framework",
    "type": "measurement_framework",
    "confidence": 0.95,
    "description": "A dual-objective framework for measuring success of MarTech training program",
    "components": [
      "Raise baseline understanding of Martech and client tech stacks",
      "Increase conversational literacy, fluency and confidence in asking clients the right questions"
    ],
    "evidence_quote": "the goal of this training is twofold. I think, number one, it's just to raise the overall baseline of understanding around Martech and what client tech stacks might look like and how to have some of those conversations. The second goal is related to that in that we really want to increase conversational literacy fluency as well as confidence in terms of people asking their clients the right questions",
    "source_transcript": "transcripts_normalized/[PARTNERSHIPS + TECH] Martech 101 Discovery Session  2025-06-23 14_00 transcript.json",
    "source_date": "2025-06-23"
  },
  {
    "name": "Stakeholder Interview Progression Framework",
    "type": "engagement_framework",
    "confidence": 0.9,
    "description": "A structured approach to gathering requirements through sequential stakeholder group interviews",
    "components": [
      "New business team (Julia and Caroline)",
      "Client architect team (Megan and Brina)",
      "Partnership and technical integration team"
    ],
    "evidence_quote": "We have spoken to Julia and Caroline on the new business team. That was our first conversation that we had last week. And then we spoke to Megan and Brina from a client architect standpoint this morning. So this conversation will round us out in terms of getting into more of the partnership side of things, technical integrations",
    "source_transcript": "transcripts_normalized/[PARTNERSHIPS + TECH] Martech 101 Discovery Session  2025-06-23 14_00 transcript.json",
    "source_date": "2025-06-23"
  },
  {
    "name": "Blue Platform Integration Options Model",
    "type": "model_framework",
    "confidence": 0.85,
    "description": "A three-option technical integration model for the Blue platform",
    "components": [
      "Open API",
      "Snowflake",
      "Data Share"
    ],
    "evidence_quote": "we talked about, you know, how Glue has an open API and there are the three options of like Snowflake, Data Share, A",
    "source_transcript": "transcripts_normalized/[PARTNERSHIPS + TECH] Martech 101 Discovery Session  2025-06-23 14_00 transcript.json",
    "source_date": "2025-06-23"
  },
  {
    "name": "AI Pilot Prioritization Framework",
    "type": "decision_framework",
    "confidence": 0.92,
    "description": "Decision logic for determining which AI use cases to engage external consultants on, based on organizational maturity and solution clarity",
    "components": [
      "High impact + solution identified = internal execution with KPI tracking support",
      "Medium impact + ambiguous/no solution = external consultant engagement",
      "Assessment factors: impact level, solution clarity, team AI experience"
    ],
    "evidence_quote": "does it make sense to engage and pull you guys into the use cases and the pilots that are the highest impact? But we feel like we already have a tool or solution identified... Or should we bring you into the more ambiguous, nebulous use cases that might be more of like the medium impact, but we have no idea where to go next",
    "source_transcript": "transcripts_normalized/Asurion x Section 2025-09-11 12_33 transcript.json",
    "source_date": "2025-09-11"
  },
  {
    "name": "Budget-Based Work Allocation Framework",
    "type": "decision_framework",
    "confidence": 0.88,
    "description": "Method for dividing work between internal teams and external consultants based on budget constraints",
    "components": [
      "Identify total scope of work",
      "Assess available budget",
      "Prioritize what to do internally vs. externally",
      "Engage external support strategically"
    ],
    "evidence_quote": "we may have to prioritize just based on the budget we have, like what we try to do internally and then what we bring you guys in for",
    "source_transcript": "transcripts_normalized/Asurion x Section 2025-09-11 12_33 transcript.json",
    "source_date": "2025-09-11"
  },
  {
    "name": "Launch Day Monitoring Framework",
    "type": "measurement_framework",
    "confidence": 0.85,
    "description": "Process for monitoring system launches through multi-channel issue detection and user activity tracking",
    "components": [
      "Monitor communication delivery",
      "Track system flows for issues",
      "Monitor user logins",
      "Flag technical issues in real-time",
      "Team on standby for support"
    ],
    "evidence_quote": "Our team is obviously on standby too, so we're monitoring the flows and nothing's been flagged on our end... I can check in with the team and see, you know, how many we've seen come through, but I can at least report there's been no issues reported",
    "source_transcript": "transcripts_normalized/Asurion x Section 2025-09-11 12_33 transcript.json",
    "source_date": "2025-09-11"
  },
  {
    "name": "Consultant Engagement Selection Criteria",
    "type": "decision_framework",
    "confidence": 0.9,
    "description": "Criteria for selecting which projects warrant external consultant involvement based on team readiness and problem definition",
    "components": [
      "Assess team's AI experience level",
      "Evaluate clarity of problem definition",
      "Determine if solutions have been identified",
      "Prioritize teams with least AI experience",
      "Focus on ground-zero starting points"
    ],
    "evidence_quote": "those are also not just the projects and pilots that we're starting from ground zero, but the teams that have the least experience with AI and its possibilities and haven't already started thinking about it",
    "source_transcript": "transcripts_normalized/Asurion x Section 2025-09-11 12_33 transcript.json",
    "source_date": "2025-09-11"
  },
  {
    "name": "Pilot Governance Structure",
    "type": "engagement_framework",
    "confidence": 0.87,
    "description": "Stakeholder structure for managing functional AI pilots with clear ownership and management roles",
    "components": [
      "Functional AI Champions (ownership layer)",
      "Pilot managers (Seth and Claudia - execution layer)",
      "External consultants (support layer)",
      "Benefactor/purse string holders (approval layer)"
    ],
    "evidence_quote": "they're the two that are really owning the functional pilots or owning the management of them. I think there's a desire to call the functional AI champions the owners",
    "source_transcript": "transcripts_normalized/Asurion x Section 2025-09-11 12_33 transcript.json",
    "source_date": "2025-09-11"
  },
  {
    "name": "AI-Assisted Content Analysis Framework",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "A multi-step methodology for analyzing large volumes of content using AI tools, involving data collection, prompt engineering across platforms, and iterative analysis",
    "components": [
      "Collect all source materials (chats, polls, transcripts)",
      "Use GPT to generate 15 prompts including system prompt and kickoff prompt",
      "Transfer prompts to Claude project for better attachment/memory management",
      "Execute primary analysis (lengthy processing time)",
      "Run follow-up sub-prompts for deeper analysis",
      "Generate multiple output formats (big document, one-pager, spreadsheet)"
    ],
    "evidence_quote": "I went through and got all of the chats and the polls and the transcripts of everything from January to October, sent it to GPT5Pro, told it to come up with a series of 15 prompts, including a system prompt and a kickoff prompt. So I could put that into a cloud project which manages attachments and memory for these types of documents much better, and then sort of sent that out.",
    "source_transcript": "transcripts_normalized/Tom _ Kyra_ Working Session 2025-10-23 14_03 transcript (1).json",
    "source_date": "2025-10-23"
  },
  {
    "name": "Workshop Prompt Practice Exercise Framework",
    "type": "engagement_framework",
    "confidence": 0.88,
    "description": "A structured approach to teaching participants prompt engineering through hands-on exercises with multiple implementation options",
    "components": [
      "Option 1: Basic to comprehensive prompt transformation (participants manually improve prompts)",
      "Option 2: Screenshot framework and use AI to help create comprehensive prompt",
      "Option 3: AI-guided interview approach where AI asks questions through each building block",
      "Participants share prompts and insights in chat",
      "Compare differences and discuss outcomes"
    ],
    "evidence_quote": "This was. Let me look back at what exactly I share people to do was basically like, okay... I had them take two minutes to turn this basic prompt into a comprehensive prompt using AI I think. So it was like, okay, take a screenshot of the framework and have AI help you turn it into a comprehensive prompt.",
    "source_transcript": "transcripts_normalized/Tom _ Kyra_ Working Session 2025-10-23 14_03 transcript (1).json",
    "source_date": "2025-10-23"
  },
  {
    "name": "Workshop Content Relevance Diagnostic Framework",
    "type": "decision_framework",
    "confidence": 0.85,
    "description": "A diagnostic approach to determine whether content issues stem from missing demonstrations, wrong type of demonstrations, or participant understanding gaps",
    "components": [
      "Verify which demos are actually being presented vs. planned",
      "Check if requested content type (e.g., data analysis) is being shown",
      "Determine if shown content matches what participants need",
      "Assess if participants understand how to apply learnings to their context",
      "Identify if issue is content selection or participant application skills"
    ],
    "evidence_quote": "So I actually don't even know if she's doing the workshop feedback data analysis demo anymore. Because I'm like, given how many, you know, like pretty much all the analyses call out. People want to see data analysis. That makes it like, are they not seeing it? Is the data analysis that we're doing not the right kind of data analysis? Like what are people looking for that they're not getting from that?",
    "source_transcript": "transcripts_normalized/Tom _ Kyra_ Working Session 2025-10-23 14_03 transcript (1).json",
    "source_date": "2025-10-23"
  },
  {
    "name": "Industry-Specific Content Adaptation Framework",
    "type": "process_framework",
    "confidence": 0.79,
    "description": "An approach to address the recurring challenge of participants wanting industry-specific examples by improving transfer learning and use case identification",
    "components": [
      "Acknowledge perpetual nature of industry-specificity requests (B2B vs B2C)",
      "Make application process more obvious to participants",
      "Help participants learn to find use cases for themselves",
      "Teach one-to-one transfer (e.g., demo creating brief \u2192 apply to creating memo)",
      "Potentially improve through demo explanations"
    ],
    "evidence_quote": "Like even when I was working for section as a contractor and we would do like brand strategy sprints, people would always be like there are too many B2B I need B2C or there are too many B2C I need B2B... I think we need to make it more obvious to people how they should understand to apply this to their learnings. And I think part of it is that people don't understand how to find use cases for themselves for work.",
    "source_transcript": "transcripts_normalized/Tom _ Kyra_ Working Session 2025-10-23 14_03 transcript (1).json",
    "source_date": "2025-10-23"
  },
  {
    "name": "AI Use Case Prioritization Framework",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "A step-by-step methodology for identifying and prioritizing AI deployment opportunities across organizational functions",
    "components": [
      "Step 1: Identify where deployment can be most valuable holistically",
      "Step 2: Brainstorm specific use cases to prioritize and tackle",
      "Step 3: Review high-impact use cases flagged by functional groups",
      "Step 4: Validate completeness - check for missing use cases",
      "Step 5: Assess maturity and determine appropriate support level"
    ],
    "evidence_quote": "the question for us is, you know, on your all's end, based on how you're looking at this holistically, where can deploying us be most valuable? And then I think to your email, Claudia, like, then can we brainstorm a little bit on the specific use cases that we should prioritize and tackle?",
    "source_transcript": "transcripts_normalized/Section Workflow Redesign 2025-09-15 14_34 transcript.json",
    "source_date": "2025-09-15"
  },
  {
    "name": "AI Workflow Integration Decision Framework",
    "type": "decision_framework",
    "confidence": 0.88,
    "description": "Logic for determining whether to redesign workflows or plug AI into existing processes",
    "components": [
      "Option 1: Redesign workflow if fundamental changes needed",
      "Option 2: Plug AI into existing workflow if structure is sound",
      "Decision criteria: What makes most sense for the given use case"
    ],
    "evidence_quote": "to have you kind of help either redesign a workflow if it's actually a redesign, or plug AI into an existing workflow. Right. Whatever makes most sense for a given use case.",
    "source_transcript": "transcripts_normalized/Section Workflow Redesign 2025-09-15 14_34 transcript.json",
    "source_date": "2025-09-15"
  },
  {
    "name": "AI Content Creation Maturity Model",
    "type": "model_framework",
    "confidence": 0.9,
    "description": "A three-stage progression model for AI-powered compliance and content creation",
    "components": [
      "Stage 1: Legal team uses internal GPT to review materials reactively",
      "Stage 2: Legal exposes GPT to marketing for self-service compliance checking before submission",
      "Stage 3: AI integrated into content creation tools with built-in compliance requirements"
    ],
    "evidence_quote": "the use case is really specific and narrow of. Hey, like when we're, when we get something from marketing, we're going to review those materials using like this GPT... Then you could kind of see a next step where the legal team exposes that GPT to marketing so they can just interact with it directly... the full like end product should really be in this image and video content creation, whatever materials you're making, you should then be making those with AI as a first pass. And that AI should already know all of the communications requirements.",
    "source_transcript": "transcripts_normalized/Section Workflow Redesign 2025-09-15 14_34 transcript.json",
    "source_date": "2025-09-15"
  },
  {
    "name": "Use Case Intent Differentiation Framework",
    "type": "decision_framework",
    "confidence": 0.85,
    "description": "Decision logic for determining appropriate AI tools based on content purpose and compliance requirements",
    "components": [
      "Internal use cases: Can use broader range of AI tools for inspiration and agency briefings",
      "External use cases: Require tools without copyrighted content training (e.g., Adobe Firefly)",
      "Key decision factor: Intent and destination of created assets"
    ],
    "evidence_quote": "are they using these for internal purposes versus are these assets that are created externally? I think that is one big question I have because I think the goal matters as far as what tools you're using. So obviously Adobe Firefly, there's not training on copyrighted content and things like that. So it's more appropriate for external use versus are these things where you're using them as inspiration to share with agencies",
    "source_transcript": "transcripts_normalized/Section Workflow Redesign 2025-09-15 14_34 transcript.json",
    "source_date": "2025-09-15"
  },
  {
    "name": "Function Maturity Assessment Framework",
    "type": "measurement_framework",
    "confidence": 0.87,
    "description": "Framework for assessing organizational readiness and determining level of support needed",
    "components": [
      "Advanced maturity indicators: Roadmaps completed, proof of concepts built, vendors identified",
      "Support for advanced functions: Selective vendor validation and impact monitoring",
      "Lower maturity indicators: Early testing phase, limited tool adoption",
      "Support for developing functions: Full roadmap and playbook development"
    ],
    "evidence_quote": "marketing is one function that is really ahead in like their roadmaps. They've, they've looked at all their use cases. They've built proof of concepts... I don't know that they need like a full roadmap built or a playbook... HR will need more help. I think the one they're testing now is job description generation.",
    "source_transcript": "transcripts_normalized/Section Workflow Redesign 2025-09-15 14_34 transcript.json",
    "source_date": "2025-09-15"
  },
  {
    "name": "Use Case Scope Validation Framework",
    "type": "process_framework",
    "confidence": 0.83,
    "description": "Process for validating completeness and appropriate scope of identified use cases",
    "components": [
      "Review current list of high-impact use cases by function",
      "Check for commonly missed use cases based on industry patterns",
      "Assess whether use cases are too narrow (single task vs. full process)",
      "Expand scope where full process redesign would add more value"
    ],
    "evidence_quote": "are we missing anything that you guys see usually, or that, you know, is generally a big use case that we might want to add to the list? Or, you know, it could be like maybe expanding one of these use cases. Like, hey, you've got a subset, but usually we see like a full process redesign where you've got one piece of it. And maybe we're not thinking broad enough.",
    "source_transcript": "transcripts_normalized/Section Workflow Redesign 2025-09-15 14_34 transcript.json",
    "source_date": "2025-09-15"
  },
  {
    "name": "AI Tool Selection Framework",
    "type": "decision_framework",
    "confidence": 0.92,
    "description": "Framework for selecting AI tools based on employee access and existing licensing rather than one-off solutions",
    "components": [
      "Identify tools employees already have access to",
      "Prioritize commonly available tools (ChatGPT, Microsoft Copilot, Workday)",
      "Avoid arbitrary tools requiring separate licensing",
      "Consider global accessibility across all HRBPs"
    ],
    "evidence_quote": "I think part of the thought process is it's got to be a tool that our employees have the access to. Like, I can't go pick some tool that nobody has access to because it's really the eight. In the most cases, it's going to be the HRBP that's probably going to drive the process... So if it could be one of these three, then I know, hey, assuming everyone gets access to ChatGPT, it's a tool that's common out there.",
    "source_transcript": "transcripts_normalized/HR Pilot - AI Job Description Generation 2025-09-16 10_02 transcript.json",
    "source_date": "2025-09-16"
  },
  {
    "name": "AI Tool Comparative Testing Process",
    "type": "process_framework",
    "confidence": 0.95,
    "description": "Step-by-step methodology for testing multiple AI tools to generate job descriptions and selecting the best performer",
    "components": [
      "Outline required fields for job descriptions",
      "Pull relevant data from Workday (job title, discipline, level)",
      "Input data into each tool (Workday AI, ChatGPT, Microsoft Copilot) with requirements",
      "Generate job descriptions from each tool",
      "Engage HRBPs to evaluate outputs",
      "Select tool that produces best job descriptions based on HRBP feedback"
    ],
    "evidence_quote": "So what we want to do is test to say which, which one comes closer to driving the best job description... we've engaged with the technology team to start the work to, to develop this, this initial tool and test... we're hoping that you know, the majority will find one tool better. And then that's kind of the process we'll, we'll go with.",
    "source_transcript": "transcripts_normalized/HR Pilot - AI Job Description Generation 2025-09-16 10_02 transcript.json",
    "source_date": "2025-09-16"
  },
  {
    "name": "Dual-Path Job Description Generation Model",
    "type": "model_framework",
    "confidence": 0.88,
    "description": "Two-pronged approach to address both backlog of missing job descriptions and ongoing new job description creation",
    "components": [
      "Path 1: Bulk generation for 2,000 existing jobs without descriptions",
      "Path 2: Process for managers/HRBPs to generate new job descriptions going forward",
      "Same AI tool can be used for both paths"
    ],
    "evidence_quote": "one thing we're trying to do is we have 2,000 jobs that don't have job descriptions. In workday. So one is to get a job description and then the other is what's our, what's our process going forward when a manager or an HRBP has to generate a new job description. So kind of two different processes but we can use the same tool to, to do that.",
    "source_transcript": "transcripts_normalized/HR Pilot - AI Job Description Generation 2025-09-16 10_02 transcript.json",
    "source_date": "2025-09-16"
  },
  {
    "name": "Central AI Support Framework",
    "type": "engagement_framework",
    "confidence": 0.85,
    "description": "Framework for how central team can support departmental AI initiatives across multiple touchpoints",
    "components": [
      "Accelerating tools through approval process",
      "Helping with pilot execution",
      "Finding solutions for use cases",
      "Providing structure to pilots",
      "Identifying and prioritizing use cases"
    ],
    "evidence_quote": "See what areas would be best for the central team to support. Maybe it's like accelerating a tool through the approval process. Maybe it's like helping with a pilot, finding a solution, helping with a use case... Kira is with Section AI, which is a company that is helping us identify use cases, find potential solutions and kind of like give some structure to pilots.",
    "source_transcript": "transcripts_normalized/HR Pilot - AI Job Description Generation 2025-09-16 10_02 transcript.json",
    "source_date": "2025-09-16"
  },
  {
    "name": "Job Description Quality Measurement Framework",
    "type": "measurement_framework",
    "confidence": 0.78,
    "description": "Approach to measuring which AI tool produces the best job descriptions through stakeholder evaluation",
    "components": [
      "Acknowledge that no job description will be perfect without tweaking",
      "Measure which tool gets closest to desired output",
      "Use HRBP evaluation as success metric",
      "Determine winner by majority HRBP preference"
    ],
    "evidence_quote": "No job description will probably go without a tweak, you know, know from an hrbp, but which one gets us the closest... engage the HRVPs then to do an evaluation on the job descriptions and let us know basically which, which tool produce the better job description. And we're hoping that you know, the majority will find one tool better.",
    "source_transcript": "transcripts_normalized/HR Pilot - AI Job Description Generation 2025-09-16 10_02 transcript.json",
    "source_date": "2025-09-16"
  },
  {
    "name": "Extended Discovery to Solution Selection Framework",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "A phased approach moving from extended discovery through solution evaluation to implementation, with specific focus on understanding team processes before selecting solution type",
    "components": [
      "Extended Discovery Phase (through end of year)",
      "Solution Evaluation Phase (early January)",
      "Solution Development/Implementation (4 weeks post-evaluation)",
      "Separate V0 Coding Discovery and Development (New Year)"
    ],
    "evidence_quote": "we decided to move forward, basically with an extended discovery phase... gives us, you know, from December 1st through the 15th to really dig in here... focus on that solution evaluation effectively when we come back in January... actually work through that solution, whether that is this four week pilot or four weeks to develop the content",
    "source_transcript": "transcripts_normalized/Section x Asurion_ Workflow Redesign Weekly Sync 2025-11-18 11_02 transcript.json",
    "source_date": "2025-11-18"
  },
  {
    "name": "Three-Option Solution Decision Framework",
    "type": "decision_framework",
    "confidence": 0.95,
    "description": "A decision framework that evaluates three distinct solution paths based on discovery findings: pure automation, training-based redesign, or hybrid approach",
    "components": [
      "Option 1: Pure automation/augmentation solution (custom GPTs or LLM automations)",
      "Option 2: Redesign training (teaching PMs to be AI-powered PMs)",
      "Option 3: Hybrid solution (combination of automation and training)"
    ],
    "evidence_quote": "whether that is a pure sort of automation augmentation solution, like what we had initially hypothesized of building these, you know, custom GPTs or other LLM automations to help with the process, or potentially a redesign training where we're teaching the PMs how to be AI powered, PMs specifically focusing on a product process... there's a third option in which we have some sort of a hybrid solution",
    "source_transcript": "transcripts_normalized/Section x Asurion_ Workflow Redesign Weekly Sync 2025-11-18 11_02 transcript.json",
    "source_date": "2025-11-18"
  },
  {
    "name": "Discovery Assessment Framework",
    "type": "process_framework",
    "confidence": 0.88,
    "description": "A structured discovery methodology focusing on three key assessment areas to inform solution selection",
    "components": [
      "Explore PRD process and understand how processes differ across teams",
      "Identify what's working well and assess where standardization matters",
      "Assess team capabilities and skill gaps"
    ],
    "evidence_quote": "we do want to continue exploring the PRD process and deeply understanding how those processes differ across teams... thinking about what is working well, as I mentioned, in those ways of working across the teams and use as an opportunity to assess where standardization matters... seeing and assessing as well what the team's capabilities and skill gaps are",
    "source_transcript": "transcripts_normalized/Section x Asurion_ Workflow Redesign Weekly Sync 2025-11-18 11_02 transcript.json",
    "source_date": "2025-11-18"
  },
  {
    "name": "Standardization-First AI Augmentation Model",
    "type": "model_framework",
    "confidence": 0.85,
    "description": "A conceptual model that positions process standardization as the prerequisite for AI augmentation opportunities",
    "components": [
      "Identify inconsistent processes across teams",
      "Determine where standardization matters",
      "Apply AI augmentation to standardized processes"
    ],
    "evidence_quote": "where standardization matters, that's where especially the AI augmentation opportunity exists... sort of seeing what makes sense to scale across the team and to make an optimized process there before we start to think about how to augment that with AI",
    "source_transcript": "transcripts_normalized/Section x Asurion_ Workflow Redesign Weekly Sync 2025-11-18 11_02 transcript.json",
    "source_date": "2025-11-18"
  },
  {
    "name": "Problem Reframing Framework",
    "type": "model_framework",
    "confidence": 0.9,
    "description": "A strategic reframing approach that repositions a redesign opportunity as a training/upskilling opportunity based on root cause analysis",
    "components": [
      "Identify lack of consensus among stakeholders",
      "Diagnose root cause (inconsistency in capabilities)",
      "Reframe solution from redesign to training/upskilling",
      "Link to organizational context (reorg)"
    ],
    "evidence_quote": "we do see some consensus and an opportunity for us to reframe the redesign opportunity as a training opportunity. Basically, the insight that they shared is that there is inconsistency in the capabilities across the product team, which is probably what's contributing to some of the inconsistencies in terms of the outputs",
    "source_transcript": "transcripts_normalized/Section x Asurion_ Workflow Redesign Weekly Sync 2025-11-18 11_02 transcript.json",
    "source_date": "2025-11-18"
  },
  {
    "name": "Stakeholder Engagement Maintenance Framework",
    "type": "engagement_framework",
    "confidence": 0.82,
    "description": "A risk mitigation approach for maintaining stakeholder engagement during extended discovery phases through leader and champion engagement",
    "components": [
      "Maintain engagement with product leaders",
      "Maintain engagement with champions",
      "Leverage sponsor support for engagement",
      "Embed in organizational changes to maintain relevance"
    ],
    "evidence_quote": "I do recognize, obviously, we want to maintain momentum. We're now extending discovery through the holidays... really want to lean on your support, Claudia and Seth, in helping to maintain engagement with both the leaders and the champions... we have an opportunity here, as these organizational changes are happening in the product team, to be potentially embedded in that",
    "source_transcript": "transcripts_normalized/Section x Asurion_ Workflow Redesign Weekly Sync 2025-11-18 11_02 transcript.json",
    "source_date": "2025-11-18"
  },
  {
    "name": "VIP Relationship Tiering and Touch Point Management System",
    "type": "model_framework",
    "confidence": 0.98,
    "description": "A three-tier classification system for prioritizing high-value relationships with corresponding engagement frequency requirements",
    "components": [
      "Tier 1 contacts: Monthly engagement required",
      "Tier 2 contacts: Quarterly engagement required",
      "Tier 3 contacts: Annual engagement required",
      "Monthly staleness monitoring and surfacing",
      "Touch point data tracking from Affinity"
    ],
    "evidence_quote": "We label them Tier 1, 2 or 3 Tier 1 contacts. We want to ensure that Paul has talked to them every month, tier 2 contacts every quarter and tier 3 contacts once a year. And so every month I surface the updates from that month, send him using touchpoint data from Affinity, send him the information on those people who are starting to become stale.",
    "source_transcript": "transcripts_normalized/Amanda Lennon and Kyra Atekwana 2025-09-22 14_00 transcript (1).json",
    "source_date": "2025-09-22"
  },
  {
    "name": "Rolodex Data Capture and Enrichment Process",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "Multi-system approach to capturing, storing, and enriching relationship intelligence data",
    "components": [
      "Capture contact information in Affinity",
      "Port contacts into Coda for enrichment",
      "Add personal details (dietary restrictions, family, interests)",
      "Auto-populate global fields via Affinity",
      "Manual supplementation of personal context",
      "Surface relevant data before meetings"
    ],
    "evidence_quote": "I have a combination of just an affinity list of Paul's contacts which I also port into Coda where I can add more specific information like dietary restrictions, spouse's name is Karen, loves the Bruins, that kind of information... in my wildest dreams AI would have the ability to... allow me to say, I just found out that Theresa Carlson's favorite drink is a whiskey sour and just have that entered into a profile somewhere and then anytime Paul had a meeting with that person, it would spit out what we know about them.",
    "source_transcript": "transcripts_normalized/Amanda Lennon and Kyra Atekwana 2025-09-22 14_00 transcript (1).json",
    "source_date": "2025-09-22"
  },
  {
    "name": "High-Value Relationship Identification Criteria",
    "type": "decision_framework",
    "confidence": 0.89,
    "description": "Logic for identifying valuable but under-cultivated relationships based on engagement patterns",
    "components": [
      "Low touch point frequency (not 50+ touchpoints per year)",
      "Strategic introduction from third party",
      "Initial one-on-one engagement occurred",
      "Value exchange demonstrated",
      "Relationship went dormant without follow-up",
      "Pattern: met once, exchanged emails, one call, then dropped off"
    ],
    "evidence_quote": "These are going to be the people that a government official that he met once at a party, has exchanged a handful of emails with and maybe did a one on one call but then dropped off the face of the earth and we didn't foster that relationship... It's going to be someone that he, someone else introduced him to that was valuable that we helped a little bit. He had maybe one, one on one meeting with, made some intros and then they sort of fell off the face of the earth",
    "source_transcript": "transcripts_normalized/Amanda Lennon and Kyra Atekwana 2025-09-22 14_00 transcript (1).json",
    "source_date": "2025-09-22"
  },
  {
    "name": "Multi-Source Data Integration System",
    "type": "model_framework",
    "confidence": 0.87,
    "description": "Layered approach combining multiple tools for comprehensive data capture and knowledge management",
    "components": [
      "Affinity: Primary contact and pipeline management",
      "Coda: Enhanced data fields and team knowledge hub",
      "Airtable: Historical custom data capture",
      "Vimcal: Calendar and meeting data",
      "Manual enrichment layer for context"
    ],
    "evidence_quote": "I administer the sort of knowledge sharing knowledge information hub for our global resilience team... primarily for that use a combination of coda and affinity to capture data among our team... I have a combination of just an affinity list of Paul's contacts which I also port into Coda... I've also used data from Vimcal, which is a calendar software",
    "source_transcript": "transcripts_normalized/Amanda Lennon and Kyra Atekwana 2025-09-22 14_00 transcript (1).json",
    "source_date": "2025-09-22"
  },
  {
    "name": "Ecosystem Intelligence Tracking Approach",
    "type": "process_framework",
    "confidence": 0.85,
    "description": "Methodology for monitoring and tracking government ecosystem players and influencers for portfolio company support",
    "components": [
      "Identify major government players and influencers",
      "Monitor social media platforms (especially Twitter)",
      "Track relationships relevant to DOD/government contracts",
      "Support portfolio companies in government market entry",
      "Maintain awareness of stakeholder perspectives"
    ],
    "evidence_quote": "I spend a lot of time thinking about both information capture and data preservation as well as tracking... ecosystem tracking. Particularly because we focus very heavily on government... it would be helpful to have a better tracker on kind of what major players or influencers related to the government are thinking. Twitter is a particularly useful location",
    "source_transcript": "transcripts_normalized/Amanda Lennon and Kyra Atekwana 2025-09-22 14_00 transcript (1).json",
    "source_date": "2025-09-22"
  },
  {
    "name": "Integrated Planning Handoff Process",
    "type": "process_framework",
    "confidence": 0.85,
    "description": "A sequential handoff process for planning across organizational functions, from marketing through finance to commercial teams",
    "components": [
      "Marketing function initiates planning",
      "Finance review and approval",
      "Commercial team receives handoff",
      "Commercial team executes tactical planning for markets"
    ],
    "evidence_quote": "there are some official handoffs call it from one function to another so call it from marketing to a bit of finance... to to then our commercial team who then has to do to the tactical planning for for their for their markets",
    "source_transcript": "transcripts_normalized/Pernod Ricard Interview - Martha 2025-07-21 09_00 transcript.json",
    "source_date": "2025-07-21"
  },
  {
    "name": "Integrated Planning Stewardship Model",
    "type": "model_framework",
    "confidence": 0.8,
    "description": "A two-layer organizational model distinguishing strategic planning facilitation from tactical execution",
    "components": [
      "Strategic layer: Integrated Planning team facilitates and drives planning forward",
      "Tactical layer: Functional teams (brand, commercial) execute detailed planning",
      "Cross-functional business partnerships as enabler"
    ],
    "evidence_quote": "We're stewards of planning. So although we're not getting into the tactical pieces of planning like maybe a brand team does or a commercial planning team does we we are driving that forward",
    "source_transcript": "transcripts_normalized/Pernod Ricard Interview - Martha 2025-07-21 09_00 transcript.json",
    "source_date": "2025-07-21"
  },
  {
    "name": "Chief of Staff Dual-Role Model",
    "type": "model_framework",
    "confidence": 0.75,
    "description": "A dual-vertical operating model with distinct but complementary responsibilities",
    "components": [
      "Vertical 1: Integrated Planning - facilitation and stewardship",
      "Vertical 2: Chief of Staff - business strategy and cross-functional priorities",
      "HQ and brand company team engagement"
    ],
    "evidence_quote": "the other piece of or the other the other vertical to my job is is is the chief of staff and and working beyond planning just on on business strategy business bigger business priorities and working more cross functionally with call it our HQ team or a brand company team",
    "source_transcript": "transcripts_normalized/Pernod Ricard Interview - Martha 2025-07-21 09_00 transcript.json",
    "source_date": "2025-07-21"
  },
  {
    "name": "Business Partnership Engagement Framework",
    "type": "engagement_framework",
    "confidence": 0.7,
    "description": "An engagement approach emphasizing partnership and collaboration over communication alone",
    "components": [
      "Cross-functional team partnerships",
      "Active collaboration and engagement",
      "Partnership as primary enabler for planning facilitation"
    ],
    "evidence_quote": "the number one enabler for my team is business partnerships with cross functional teams. We not just talk a lot to them. We partner and collaborate and we need their engagement because we are facilitating planning moving forward",
    "source_transcript": "transcripts_normalized/Pernod Ricard Interview - Martha 2025-07-21 09_00 transcript.json",
    "source_date": "2025-07-21"
  },
  {
    "name": "Workflow Redesign Scoping Framework",
    "type": "decision_framework",
    "confidence": 0.92,
    "description": "A decision logic for determining depth vs. breadth when conducting workflow redesigns across an organization, choosing between lighter coverage across multiple functions or deeper analysis in a single function",
    "components": [
      "Identify champion users across functions",
      "Decision point: breadth vs. depth",
      "Option A: Lighter interviews with champions across all functions",
      "Option B: Deep dive in one function",
      "Client makes final decision"
    ],
    "evidence_quote": "Either we don't go as deep across like everything and we do like lighter interviews with the champions, or we could go really deep in just one function and that's a decision that they can make.",
    "source_transcript": "transcripts_normalized/Asurion Internal Kickoff 2025-06-17 16_33 transcript.json",
    "source_date": "2025-06-17"
  },
  {
    "name": "Champion-Led Workflow Identification Process",
    "type": "process_framework",
    "confidence": 0.88,
    "description": "A methodology for identifying and redesigning workflows using pre-identified champions who have already started mapping workflows on their teams",
    "components": [
      "Identify champions across different functions",
      "Champions identify workflows on their teams",
      "Use champions as starting point for workflow redesigns",
      "Conduct interviews with champions"
    ],
    "evidence_quote": "They have all of these champions that they've already identified who have gone through the process of starting to identify like, different workflows on their teams. So the idea is that we would start and use those champions for the workflow redesigns.",
    "source_transcript": "transcripts_normalized/Asurion Internal Kickoff 2025-06-17 16_33 transcript.json",
    "source_date": "2025-06-17"
  },
  {
    "name": "Enterprise AI Certification Rollout Framework",
    "type": "engagement_framework",
    "confidence": 0.9,
    "description": "A structured approach to certifying employees before granting enterprise GPT access, using custom proficiency certificates as gatekeepers",
    "components": [
      "Leadership commitment to certification requirement",
      "Select relevant courses for certification track",
      "Create custom proficiency certificate",
      "Employees complete certification",
      "Grant enterprise GPT access upon certification"
    ],
    "evidence_quote": "They've made this big commitment to their leadership team around how they're going to certify all of their employees to give them access to an enterprise GPT and they're going to use a custom certification, like a proficiency certificate in our platform to do that.",
    "source_transcript": "transcripts_normalized/Asurion Internal Kickoff 2025-06-17 16_33 transcript.json",
    "source_date": "2025-06-17"
  },
  {
    "name": "Contract Negotiation Trade-Off Framework",
    "type": "decision_framework",
    "confidence": 0.87,
    "description": "A negotiation logic where increased scope (user count) is exchanged for additional deliverables (case study participation)",
    "components": [
      "Client requests scope increase",
      "Identify value exchange opportunity",
      "Propose additional deliverable (case study)",
      "If accepted: increased scope",
      "If declined: maintain original scope"
    ],
    "evidence_quote": "They asked us to increase the employee scope to 6,000, which I said, okay, sure... So we said, we'll do it if you do a case study with us on the workflow redesigns... And if they don't, it'll be for the 5,000 users that they're originally contracted for.",
    "source_transcript": "transcripts_normalized/Asurion Internal Kickoff 2025-06-17 16_33 transcript.json",
    "source_date": "2025-06-17"
  },
  {
    "name": "Pathway Page Customization Process",
    "type": "process_framework",
    "confidence": 0.85,
    "description": "A step-by-step methodology for customizing client-facing platform pages with executive messaging and branded content",
    "components": [
      "Executive records welcome/vision video",
      "Customize page language and messaging",
      "Review editable component template",
      "Client works on customization elements",
      "Implement branding"
    ],
    "evidence_quote": "They're having their president record a video that they're going to include on the Pathway page, like telling people why they're so excited about this, what they can expect, et cetera, et cetera. And then they're also going to customize all of the language on that Pathway page.",
    "source_transcript": "transcripts_normalized/Asurion Internal Kickoff 2025-06-17 16_33 transcript.json",
    "source_date": "2025-06-17"
  },
  {
    "name": "Why of AI Sprint",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "A productized service methodology for helping organizations define their AI strategic vision and cascade it through the organization",
    "components": [
      "Executive interviews",
      "Leadership working session",
      "Workshop readout/summary",
      "AI manifesto draft",
      "Executive presentation preparation"
    ],
    "evidence_quote": "What we literally put in the contract just to align on this for a second is that we would do executive interviews, a work working session which is what is scheduled for December 8th... And then they also want a readout of that workshop, like a summary. And then we would also draft their AI manifesto. And then we also need to help them... Greg is attending this glm... And so we need to help both their executives present on this.",
    "source_transcript": "transcripts_normalized/Havas Why of AI Brainstorm  2025-11-13 11_33 transcript.json",
    "source_date": "2025-11-13"
  },
  {
    "name": "Two-Phase AI Transformation Structure",
    "type": "model_framework",
    "confidence": 0.88,
    "description": "A dual-approach framework combining top-down strategic alignment with bottom-up organizational assessment",
    "components": [
      "Top-down: Why of AI Sprint (strategic vision and leadership alignment)",
      "Bottom-up: AI maturity deep dive (organizational assessment)"
    ],
    "evidence_quote": "HAVAS is like phase one has two parts in some ways. I've been thinking about it as they have a top down part and they have a bottom up part. So the bottom up is more straightforward. That's just our AI maturity deep dive... Their top down part, they is this why of AI Sprint",
    "source_transcript": "transcripts_normalized/Havas Why of AI Brainstorm  2025-11-13 11_33 transcript.json",
    "source_date": "2025-11-13"
  },
  {
    "name": "Vision Cascade Framework",
    "type": "process_framework",
    "confidence": 0.9,
    "description": "A sequential approach to developing and cascading AI vision from leadership through the organization",
    "components": [
      "Define industry imperative and strategic business model imperative",
      "Articulate leadership vision",
      "Translate into employee-facing message (manifesto)",
      "Cascade down organization",
      "Execute with change management program"
    ],
    "evidence_quote": "So to me I think of that as like their industry imperative and like their strategic like business model imperative... And so they want to articulate that vision and then they want to translate that into an employee facing message. And so that's, you know, we wrote in the manifesto. But so yeah, so and then they want to cast that will cascade down the organization. We'll have done our deep dive and have a change management program and and then they will execute that.",
    "source_transcript": "transcripts_normalized/Havas Why of AI Brainstorm  2025-11-13 11_33 transcript.json",
    "source_date": "2025-11-13"
  },
  {
    "name": "Workshop Input Preparation Framework",
    "type": "process_framework",
    "confidence": 0.85,
    "description": "A pre-workshop discovery process to gather strategic context from leadership before facilitated sessions",
    "components": [
      "CEO vision interview (understand AI vision and strategy)",
      "Participant interviews (timing TBD: before or after workshop)",
      "Context gathering for workshop design"
    ],
    "evidence_quote": "Greg is going to talk to their CEO to understand his AI vision. I think that needs to be part of the grounding of the working session. Like what is this guy's. Who knows how much AI vision he has yet, but at least what is his strategy? What is he imagining Havas for the next one, three, five years, whatever... Then we also have in. In the mix interviews with the participants.",
    "source_transcript": "transcripts_normalized/Havas Why of AI Brainstorm  2025-11-13 11_33 transcript.json",
    "source_date": "2025-11-13"
  },
  {
    "name": "Stakeholder Engagement Tiering",
    "type": "engagement_framework",
    "confidence": 0.87,
    "description": "A deliberate approach to selecting workshop participants one level below executive leadership to drive ownership before executive review",
    "components": [
      "Mid-level agency leadership participates in creation/workshop",
      "Steering committee executives react to output rather than create",
      "Rationale: avoid executive conflict, build ownership at implementation level"
    ],
    "evidence_quote": "So the participants for the workshop are not the executives in the steering committee. We originally were throwing that around, but basically Dan, our client was like, they are just going to like argue with each other for three hours. And so it's one level down... These are more like agency leadership people... they need to feel. Feel ownership over this. Like, we think it's better if the steering committee is something to react to, frankly.",
    "source_transcript": "transcripts_normalized/Havas Why of AI Brainstorm  2025-11-13 11_33 transcript.json",
    "source_date": "2025-11-13"
  },
  {
    "name": "Interview Timing Decision Framework",
    "type": "decision_framework",
    "confidence": 0.75,
    "description": "A strategic decision point for optimizing when to conduct stakeholder interviews relative to workshop timing",
    "components": [
      "Option A: Before workshop - gather input to inform workshop design",
      "Option B: After workshop - gather feedback on outputs and fill gaps",
      "Decision criteria: What information is needed and when"
    ],
    "evidence_quote": "I don't have a strong POV right now on like, whether that would be better suited before the workshop or after the workshop. So, like, are there things we would want to know going into the workshop on an individual level or would we want to meet with them afterwards, like about the AI manifesto and like, get their feedback or, like fill in the gaps?",
    "source_transcript": "transcripts_normalized/Havas Why of AI Brainstorm  2025-11-13 11_33 transcript.json",
    "source_date": "2025-11-13"
  },
  {
    "name": "AI-Democratized Negotiation Framework",
    "type": "model_framework",
    "confidence": 0.88,
    "description": "A conceptual model explaining how AI transforms negotiation advantage from information asymmetry to skill in leveraging AI capabilities",
    "components": [
      "Information democratization (equal access to public insights)",
      "Asking the right questions to AI",
      "Spotting nuance in AI responses",
      "Building on insights to reach deeper understanding",
      "Using AI as a thought partner for complexity and pivoting"
    ],
    "evidence_quote": "what used to make good negotiators have an advantage over not good negotiators is like this, the information asymmetry and access information that the other party didn't have. And in a way, AI democratizes information access because now everybody has access to the same level, at least of public insight. And so you guys can both actually be at the same level now because of AI. So, like, that information asymmetry is gone, and so it instead becomes about, are you asking AI the right questions? Are you able to spot the nuance in AI's responses and build on it and run with it to get to deeper insights? And can you use it to help you pivot and think through the complexity of a negotiation and using AI really as your thought partner",
    "source_transcript": "transcripts_normalized/AI for Negotiations Content Call_ Section Intros 2025-07-28 07_02 transcript.json",
    "source_date": "2025-07-28"
  },
  {
    "name": "Enterprise Workshop Design Framework",
    "type": "decision_framework",
    "confidence": 0.85,
    "description": "Decision logic for designing enterprise workshops, focusing on business-specific use cases and avoiding features that reduce engagement",
    "components": [
      "Focus on business-specific use cases (not consumer/personal use cases)",
      "Avoid breakout rooms (leads to 50% audience loss)",
      "Align content with daily work relevance",
      "Consider enterprise buyer preferences"
    ],
    "evidence_quote": "we sell our AI academy to enterprises with the, with the idea that the use cases that we focus on are business specific use cases. And so because the salary negotiation isn't a business specific use case... And the rationale for... the biggest challenge is people use that as an opportunity to leave. Like as soon as you open the breakout room, you really percent of your audience",
    "source_transcript": "transcripts_normalized/AI for Negotiations Content Call_ Section Intros 2025-07-28 07_02 transcript.json",
    "source_date": "2025-07-28"
  },
  {
    "name": "Internal vs External Negotiation Model",
    "type": "model_framework",
    "confidence": 0.82,
    "description": "A conceptual distinction between adversarial external negotiations and collaborative internal negotiations with different objectives",
    "components": [
      "External negotiation (adversarial, opposite sides)",
      "Internal negotiation (collaborative, same side with different objectives)",
      "Recognition that internal scenarios are still negotiations"
    ],
    "evidence_quote": "I was thinking about this particular type of use case which is basically the internal negotiation where it's not necessarily adversarial, where you're on opposite sides. Like, you're both actually on the same side in a way, but with different objectives. And so that kind like that is a negotiation. You're probably not thinking about it that way because you're not, you know. It's not somebody external to you",
    "source_transcript": "transcripts_normalized/AI for Negotiations Content Call_ Section Intros 2025-07-28 07_02 transcript.json",
    "source_date": "2025-07-28"
  },
  {
    "name": "Presentation Development Process",
    "type": "process_framework",
    "confidence": 0.98,
    "description": "A step-by-step methodology for creating business presentations from initial requirement to final output, consisting of content development followed by design refinement",
    "components": [
      "Start with directive from meeting (goal, audience, time constraints)",
      "Use AI (ChatGPT/Claude) to create outline/framework",
      "Leverage existing slides as starting point",
      "Conduct working session with colleague for live edits OR present for feedback",
      "Finalize content and rough layout",
      "Beautify/design refinement phase",
      "Optional: Agency support for external slides"
    ],
    "evidence_quote": "I'll take that back and I'll be like, okay, if this is the goal of what I want to communicate, this is to whom I'm communicating to. This is how much time I have to do it. And I'll kind of start to build a framework using like ChatGPT...And then from there...I might do a working session with another colleague where we like talk about it together and make edits live. Or I might just present it to another colleague, then they give me notes and then I take it back and make edits. And I would say there's like two parts...the first part is about making sure all the content is the right content to be on there and kind of like a rough outline...And then once the content is like laid out, we're good on the content, then it's like, okay, how do I make this pretty?",
    "source_transcript": "transcripts_normalized/Presentation Interview - Sade 2025-09-26 17_07 transcript.json",
    "source_date": "2025-09-26"
  },
  {
    "name": "Two-Phase Presentation Creation Model",
    "type": "model_framework",
    "confidence": 0.96,
    "description": "A conceptual model dividing presentation creation into two distinct phases: content validation and visual design",
    "components": [
      "Phase 1: Content Development - ensuring right information with rough layout",
      "Phase 2: Design/Beautification - making the presentation visually appealing"
    ],
    "evidence_quote": "I feel like for me, when I'm making a presentation, the first part is about making sure all the content is the right content to be on there and kind of like a rough outline on how it like the like design wise, how it's supposed to be on there. And then once the content is like laid out, we're good on the content, then it's like, okay, how do I make this pretty?",
    "source_transcript": "transcripts_normalized/Presentation Interview - Sade 2025-09-26 17_07 transcript.json",
    "source_date": "2025-09-26"
  },
  {
    "name": "Minimum Viable Presentation Structure",
    "type": "model_framework",
    "confidence": 0.92,
    "description": "A standard three-slide minimum structure for any presentation regardless of complexity",
    "components": [
      "Intro/cover page",
      "Core content (one-pager)",
      "Next steps page"
    ],
    "evidence_quote": "I would say anything that's being done minimum, even if it's just something that's quick, is like a three slide presentation where you're going to have the intro cover page and then you'll have, you know, whatever the one pager is and then like a next steps page is the format that I've seen.",
    "source_transcript": "transcripts_normalized/Presentation Interview - Sade 2025-09-26 17_07 transcript.json",
    "source_date": "2025-09-26"
  },
  {
    "name": "Slide Reuse and Adaptation Strategy",
    "type": "process_framework",
    "confidence": 0.94,
    "description": "A methodology for efficiently creating presentations by adapting existing content rather than starting from scratch",
    "components": [
      "Identify similar previous presentations",
      "Extract relevant content/insights",
      "Adapt to new value proposition or audience",
      "Maintain historical versions in same document for iterative projects"
    ],
    "evidence_quote": "My personal approach to making presentations is I always start by leveraging existing slides...Right now I'm working on some slides for a customer. I went back to previous slides that I had worked on for another customer to use as the basis for this slides. Even though the weigh in that I'm using for the latest version is a bit different, it's going to still leverage a lot of the information although I'll be like illustrating a different value proposition.",
    "source_transcript": "transcripts_normalized/Presentation Interview - Sade 2025-09-26 17_07 transcript.json",
    "source_date": "2025-09-26"
  },
  {
    "name": "Presentation Purpose Categorization",
    "type": "model_framework",
    "confidence": 0.9,
    "description": "A classification system for different types of presentations based on audience and purpose",
    "components": [
      "Internal Leadership: business updates, alignment on recommendations, sharing information",
      "Internal Teams: onboarding (customer teams, agency teams)",
      "External: buyer-facing presentations"
    ],
    "evidence_quote": "In terms of how I am using presentation in my current job, I would say a lot and they could serve for. It could be for a number of purposes rather. So we are using them both internally and externally. Internally it would be key leadership stakeholders. We make a lot of presentation slides to share up the leadership chain, to give business updates, to get alignment. On recommendations that we've made on also to share out information. So for instance with customer teams, you know, we'd see or agency teams to kind of onboard them onto a project and then externally they're used with buyers as well.",
    "source_transcript": "transcripts_normalized/Presentation Interview - Sade 2025-09-26 17_07 transcript.json",
    "source_date": "2025-09-26"
  },
  {
    "name": "AI-Assisted Presentation Planning Framework",
    "type": "process_framework",
    "confidence": 0.93,
    "description": "A methodology for using AI tools to create presentation structure by inputting key contextual parameters",
    "components": [
      "Define communication goal",
      "Identify target audience",
      "Determine time constraints",
      "Input parameters into AI tool (ChatGPT/Claude)",
      "Receive outline/layout recommendations"
    ],
    "evidence_quote": "I'll take that back and I'll be like, okay, if this is the goal of what I want to communicate, this is to whom I'm communicating to. This is how much time I have to do it. And I'll kind of start to build a framework using like ChatGPT. I've been more recently. Think tinkering Claude and getting recommendations on like what that. How I could start to like outline or lay out the slides.",
    "source_transcript": "transcripts_normalized/Presentation Interview - Sade 2025-09-26 17_07 transcript.json",
    "source_date": "2025-09-26"
  },
  {
    "name": "Iterative Version Control Strategy",
    "type": "process_framework",
    "confidence": 0.88,
    "description": "A method for managing presentation iterations by maintaining all historical versions within a single document",
    "components": [
      "Create initial version in document",
      "Make updates in same file for each iteration",
      "Preserve historical versions within document",
      "Use for projects requiring multiple levels of leadership alignment"
    ],
    "evidence_quote": "I've also noticed that for things that are iterative. So for instance if you're. I remember we were working to get some alignment from different levels of leadership on a strategy we would continue to make the updates in the same document or that person was making the updates in the same document so that they had all the historical versions of the presentation of the like of the edits in one file.",
    "source_transcript": "transcripts_normalized/Presentation Interview - Sade 2025-09-26 17_07 transcript.json",
    "source_date": "2025-09-26"
  },
  {
    "name": "Collaborative Review Decision Framework",
    "type": "decision_framework",
    "confidence": 0.85,
    "description": "A decision logic for choosing between different collaboration approaches based on project needs",
    "components": [
      "Option A: Working session with colleague for live collaborative edits",
      "Option B: Present to colleague, receive feedback, then make edits independently"
    ],
    "evidence_quote": "I might do a working session with another colleague where we like talk about it together and make edits live. Or I might just present it to another colleague, then they give me notes and then I take it back and make edits.",
    "source_transcript": "transcripts_normalized/Presentation Interview - Sade 2025-09-26 17_07 transcript.json",
    "source_date": "2025-09-26"
  },
  {
    "name": "External Presentation Enhancement Framework",
    "type": "process_framework",
    "confidence": 0.87,
    "description": "A specialized process for client-facing presentations involving professional design support",
    "components": [
      "Complete content development internally",
      "Engage agency partner for design beautification",
      "Agency creates custom design",
      "Final deck is enhanced for external presentation"
    ],
    "evidence_quote": "I know that even for our external slides, for one customer meeting we had, they actually had an agency just come in and take the final deck and beautify it, create a design, a custom design and then like, you know, like basically judge up the slide. So but that was for external use.",
    "source_transcript": "transcripts_normalized/Presentation Interview - Sade 2025-09-26 17_07 transcript.json",
    "source_date": "2025-09-26"
  },
  {
    "name": "Pilot-to-Scale Revenue Framework",
    "type": "scaling_framework",
    "confidence": 0.92,
    "description": "A framework for evaluating and scaling from an initial pilot engagement to expanded partnership based on demonstrating quality execution in the pilot phase",
    "components": [
      "Initial pilot engagement (entry level)",
      "Quality demonstration phase",
      "Expansion beyond pilot based on performance",
      "Long-term partnership development"
    ],
    "evidence_quote": "this is the entry level to show that you can do good work. We'd be open to, like, that we want to start with a pilot on this level. Right. So this is far from the end. All be all as it relates.",
    "source_transcript": "transcripts_normalized/Bobby Kyra OpenAi Huddle 2025-10-23 16_48 transcript.json",
    "source_date": "2025-10-23"
  },
  {
    "name": "Go/No-Go Decision Framework",
    "type": "decision_framework",
    "confidence": 0.89,
    "description": "A decision-making process for evaluating whether to accept a revenue opportunity based on confidence in execution quality and expansion potential rather than just immediate revenue",
    "components": [
      "Review client materials in advance",
      "Assess ability to do good work",
      "Evaluate expansion potential",
      "Make go/no-go decision before commitment"
    ],
    "evidence_quote": "I want to make sure that we can do a good job. Right. Because, yes, there's a revenue opportunity in Q4, and we take that, but it's not worth it if we don't. We're not confident that we can do good work and then we can expand beyond that.",
    "source_transcript": "transcripts_normalized/Bobby Kyra OpenAi Huddle 2025-10-23 16_48 transcript.json",
    "source_date": "2025-10-23"
  },
  {
    "name": "Instructor Staffing Cost Model",
    "type": "model_framework",
    "confidence": 0.88,
    "description": "A two-tier instructor staffing model to manage costs and capacity, distinguishing between premium instructors for enterprise work and contracted specialists for volume work",
    "components": [
      "Existing per-workshop model ($2,500 per workshop)",
      "New retainer model (X workshops per month at fixed rate)",
      "Premium instructor tier (reserved for enterprise)",
      "Volume instructor tier (new AI expert bench)",
      "Hybrid approach with lead facilitator transitioning"
    ],
    "evidence_quote": "we would potentially want to think about instructor staffing slightly differently because right now we have paid people on a per workshop basis. It's $2,500, which obviously cuts into the margins pretty significantly at this rate... maybe we sort of have them on like a retainer or some sort of like, you know, this is this new contract type. It will be five workshops a month at X rate",
    "source_transcript": "transcripts_normalized/Bobby Kyra OpenAi Huddle 2025-10-23 16_48 transcript.json",
    "source_date": "2025-10-23"
  },
  {
    "name": "Volume-Based Capacity Planning Framework",
    "type": "process_framework",
    "confidence": 0.85,
    "description": "A methodology for calculating realistic delivery capacity by accounting for actual working time minus holidays and converting opportunity pipeline to delivery requirements",
    "components": [
      "Calculate total pipeline opportunities (20-30)",
      "Apply conversion rate (50% close rate = 10-15 clients)",
      "Determine actual working timeframe (6 weeks after holidays)",
      "Calculate weekly delivery rate (2-3 per week)",
      "Determine lead time requirements (72 hours to 4 days)",
      "Assess staffing needs against capacity"
    ],
    "evidence_quote": "they think It'll be about 20 to 30 opportunities to us. Meaning clients say, okay, we'd like sections to help 30 of those. And they said, okay, if you close about half of them... that gives us two months remaining in the year. But then you take out the holidays. So it's really like we have like six weeks of actual weeks of working and 10 on the low side. Of new customers. But 15 on the high side",
    "source_transcript": "transcripts_normalized/Bobby Kyra OpenAi Huddle 2025-10-23 16_48 transcript.json",
    "source_date": "2025-10-23"
  },
  {
    "name": "Scalable Instructor Development Process",
    "type": "process_framework",
    "confidence": 0.87,
    "description": "A systematic approach to developing instructors with dual capabilities by creating standardized training materials to bridge skill gaps",
    "components": [
      "Identify skill gap (AI experts vs facilitators)",
      "Create standardized playbook",
      "Develop training guide for expected quality level",
      "Bridge niche skill requirements",
      "Scale instructor capacity"
    ],
    "evidence_quote": "we have a lot of AI experts who maybe need help being facilitators and we have some facilitators who need help being AI experts. And part of this might be sort of creating a playbook and a little bit of a training guide on how to do this at the level that we expect.",
    "source_transcript": "transcripts_normalized/Bobby Kyra OpenAi Huddle 2025-10-23 16_48 transcript.json",
    "source_date": "2025-10-23"
  },
  {
    "name": "Content Reusability Framework",
    "type": "process_framework",
    "confidence": 0.83,
    "description": "A methodology for leveraging existing off-the-shelf content with minimal customization to reduce build time and maintain margins",
    "components": [
      "Review client's existing materials",
      "Assess build time estimate (30-40 hours baseline)",
      "Leverage off-the-shelf content (AI crash course, custom GPT building)",
      "Add minimal platform-specific customization (ChatGPT focus, workspace setup)",
      "Minimize net new content creation"
    ],
    "evidence_quote": "I was. So I. Have they. So I know it's like two to three workshops, Right. That are not going to be customized. Potentially a combination of building off of what they've created with. With some of what we've created... they think that we should just run our stand like almost kind of like our off the shelf content.",
    "source_transcript": "transcripts_normalized/Bobby Kyra OpenAi Huddle 2025-10-23 16_48 transcript.json",
    "source_date": "2025-10-23"
  },
  {
    "name": "Pre-Commitment Material Assessment Process",
    "type": "process_framework",
    "confidence": 0.86,
    "description": "A step-by-step process for evaluating scope and feasibility before final commitment by reviewing client materials to determine build requirements",
    "components": [
      "Request client's existing materials",
      "Review materials before go/no-go decision",
      "Assess build time based on materials quality",
      "Determine content reusability",
      "Make informed commitment decision"
    ],
    "evidence_quote": "Have you seen any of their materials at all? No. And in fact, I haven't asked to them to send over because they said that they could send over their existing material. So as soon as I get that, I can share. And that would be in advance of, like, the go, no go decision. Yeah. Okay. Because I think that will help me determine a lot of like, you know, we're assuming 30 to 40 hours to build it, but it could potentially be less",
    "source_transcript": "transcripts_normalized/Bobby Kyra OpenAi Huddle 2025-10-23 16_48 transcript.json",
    "source_date": "2025-10-23"
  },
  {
    "name": "Decision Architecture Framework",
    "type": "model_framework",
    "confidence": 0.92,
    "description": "A user experience design approach that focuses on mapping user decisions at each stage of the journey rather than visual flows, creating constraints for designers to work within",
    "components": [
      "Decision identification per page/stage",
      "User choice mapping (e.g., social login, email entry)",
      "Experience definition for each stage",
      "Constraint creation for design work"
    ],
    "evidence_quote": "The easiest thing that works for me or how I've done it in the past is I kind of like layouts the user journey in terms of the decisions that I made at every stage. So I'm not really interested in drawing a flow, you know, I'm just interested in the decisions. Oh, this onboarding, what are decisions we want people to make? Are they choosing their social login, are they entering their email? You know, so there's decisions on every page or every. So that's kind of my own part, like defining the. They call it decision architecture decisions.",
    "source_transcript": "transcripts_normalized/igk-srzo-vax summary 2025-09-10 17_02 transcript.json",
    "source_date": "2025-09-10"
  },
  {
    "name": "Collaborative UI/UX Design Process",
    "type": "process_framework",
    "confidence": 0.89,
    "description": "A step-by-step methodology for working with designers on novel products that don't have established patterns, requiring active stakeholder involvement",
    "components": [
      "Step 1: Conduct competitive analysis (teardown of competitors' flows)",
      "Step 2: Document what works and what doesn't from competitors",
      "Step 3: Align team on thought process and vision",
      "Step 4: Define decision architecture collaboratively",
      "Step 5: Designer translates vision into flows with ongoing stakeholder involvement"
    ],
    "evidence_quote": "Unlike some other projects, I can't really say, hey, go do a user flow for this, because I don't even know what the user flow needs to be. So it has to be collaborative. It has to be you folks who need some hours on the call too, with whoever designer it is to get your own sense of what don't you like from the existing flows.",
    "source_transcript": "transcripts_normalized/igk-srzo-vax summary 2025-09-10 17_02 transcript.json",
    "source_date": "2025-09-10"
  },
  {
    "name": "Competitive Analysis to Product Differentiation Framework",
    "type": "process_framework",
    "confidence": 0.85,
    "description": "A methodology for analyzing competitors to identify advantages and inform unique product experience design",
    "components": [
      "Review multiple competitor tools",
      "Identify what works in each competitor",
      "Identify what doesn't work",
      "Document potential advantages",
      "Synthesize best elements into unique offering"
    ],
    "evidence_quote": "We looked at multiple tools. Why we like it, why we don't like it, what the issue is, which is some of, like, the advantages we may have... The idea is going to be an aggregation. That takes the best out of all the things out there based on the conversations I've had so far.",
    "source_transcript": "transcripts_normalized/igk-srzo-vax summary 2025-09-10 17_02 transcript.json",
    "source_date": "2025-09-10"
  },
  {
    "name": "Designer Vetting and Scoping Framework",
    "type": "decision_framework",
    "confidence": 0.78,
    "description": "A multi-criteria evaluation process for selecting and engaging design resources",
    "components": [
      "Assess capability (who can do the work)",
      "Check availability (who's free)",
      "Evaluate scope understanding (what work involves)",
      "Determine collaboration requirements"
    ],
    "evidence_quote": "So I spoke with maybe like four or five UI UX folks, you know, just to first of all to see who can do the work and also see who's free. Also get a sense of what is going to involve.",
    "source_transcript": "transcripts_normalized/igk-srzo-vax summary 2025-09-10 17_02 transcript.json",
    "source_date": "2025-09-10"
  },
  {
    "name": "Vision Translation Model",
    "type": "engagement_framework",
    "confidence": 0.81,
    "description": "A collaborative model where designers translate stakeholder vision into user flows with facilitation, requiring active stakeholder participation rather than passive handoff",
    "components": [
      "Stakeholders define vision and constraints",
      "Facilitator/PM bridges understanding",
      "Designer translates to visual/flow representation",
      "Continuous stakeholder involvement throughout",
      "Iterative feedback loops"
    ],
    "evidence_quote": "These designers, first of all, they are just designers, right? Like, they're not like experts in AI, experts in presentations or anything like that. So what they're essentially doing is translating your vision, I mean, with my help to. But that. That's what they're doing. So you can't really just leave it to them and go away",
    "source_transcript": "transcripts_normalized/igk-srzo-vax summary 2025-09-10 17_02 transcript.json",
    "source_date": "2025-09-10"
  },
  {
    "name": "AI Use Case Discovery and Prioritization Framework",
    "type": "process_framework",
    "confidence": 0.98,
    "description": "A three-phase methodology for identifying, evaluating, and prioritizing AI use cases within an organization",
    "components": [
      "Phase 1: Capture all potential use cases (existing solutions in progress, previously shared use cases, new ideas)",
      "Phase 2: Evaluate and prioritize using dual metrics (quality enhancement and efficiency improvement)",
      "Phase 3: Align on top use cases for pilot testing"
    ],
    "evidence_quote": "First is to make sure we have a clear understanding of all the potential use cases for AI... First is just capturing the use cases with solutions already in progress. The second is go through any new use cases that you guys have already shared with us. And then the third is seeing if there's any ideas that we haven't captured... Next we'll jump to all use, like begin the evaluation and prioritization process... And then we just want to align on what are the top new use cases",
    "source_transcript": "transcripts_normalized/FW_ AI use-case Discovery and Prioritization Session - E&C New Partner Growth 2025-08-05 08_31 transcript.json",
    "source_date": "2025-08-05"
  },
  {
    "name": "Dual-Metric Impact Assessment Framework",
    "type": "measurement_framework",
    "confidence": 0.96,
    "description": "A two-dimensional evaluation system for measuring AI use case impact on both quality and efficiency",
    "components": [
      "Metric 1: Ability to enhance quality",
      "Metric 2: Ability to improve efficiency",
      "Scale: High, medium, low impact rating",
      "Primary classification: Determine whether primarily enhancing efficiency or quality"
    ],
    "evidence_quote": "So we'll want to evaluate two main metrics. First is its ability to enhance quality. And the second is its ability to improve efficiency. So we'll do like a very simple high, medium, low impact evaluation for its ability to improve efficiency and then for quality... Is it primarily enhancing efficiency or primarily enhancing quality?",
    "source_transcript": "transcripts_normalized/FW_ AI use-case Discovery and Prioritization Session - E&C New Partner Growth 2025-08-05 08_31 transcript.json",
    "source_date": "2025-08-05"
  },
  {
    "name": "AI Pilot to Production Framework",
    "type": "scaling_framework",
    "confidence": 0.92,
    "description": "A structured approach for moving from use case identification to scaled organizational implementation",
    "components": [
      "Step 1: Identify and prioritize use cases through team sessions",
      "Step 2: Identify optimal AI tool for each use case (third-party vendor or in-house build)",
      "Step 3: Craft testing/piloting process",
      "Step 4: Scale from individual/team to broader organizational deployment"
    ],
    "evidence_quote": "After this, the team will start. Identifying what would be the best, most optimal AI tool for each of the use cases and we'll start crafting what a testing or piloting process should look like. So in your case it wouldn't just be for the three of you and your team, it would be for the broader new partner strategy team.",
    "source_transcript": "transcripts_normalized/FW_ AI use-case Discovery and Prioritization Session - E&C New Partner Growth 2025-08-05 08_31 transcript.json",
    "source_date": "2025-08-05"
  },
  {
    "name": "Organizational Scale Impact Assessment Framework",
    "type": "measurement_framework",
    "confidence": 0.89,
    "description": "A framework for measuring impact at organizational scale rather than individual or small team level",
    "components": [
      "Focus: Organization-wide or team-wide application",
      "Scope: Multiple people/scaled deployment",
      "Question: What would be the impact for the function if scaled?"
    ],
    "evidence_quote": "the question that we're trying to answer is if this is applied to the organization as a whole or to the team as a whole, what would be the impact for that function? So less about maybe your team or like let's say one individual applying this tool, more so about like if we scale this to multiple people, what would be the impact for the organization?",
    "source_transcript": "transcripts_normalized/FW_ AI use-case Discovery and Prioritization Session - E&C New Partner Growth 2025-08-05 08_31 transcript.json",
    "source_date": "2025-08-05"
  },
  {
    "name": "Cross-Functional AI Discovery Framework",
    "type": "engagement_framework",
    "confidence": 0.87,
    "description": "A structured approach for engaging different functional teams to identify AI use cases through scheduled discovery sessions",
    "components": [
      "Schedule team-specific discovery sessions (typically 2 hours)",
      "Distribute pre-work materials",
      "Conduct collaborative discovery and evaluation",
      "Capture team-specific and cross-functional use cases"
    ],
    "evidence_quote": "most of these sessions have been scheduled for two hours because there's. They're pretty big teams and the use cases are kind of long and unrelated... It looks like you've both been able to go through the pre work... We've had conversations with like the broader technology team",
    "source_transcript": "transcripts_normalized/FW_ AI use-case Discovery and Prioritization Session - E&C New Partner Growth 2025-08-05 08_31 transcript.json",
    "source_date": "2025-08-05"
  },
  {
    "name": "Presentation Deck Categorization Framework",
    "type": "model_framework",
    "confidence": 0.92,
    "description": "A hierarchical model for categorizing business presentation decks based on audience (internal vs external) and purpose, used at Meta for organizing different types of business communications",
    "components": [
      "Internal Decks: POV/Request decks",
      "Internal Decks: Project status updates",
      "Internal Decks: Single source of truth archives (100+ pages)",
      "Internal Decks: Cross-functional asset repositories",
      "Internal Decks: Leadership presentation contributions",
      "External Decks: Project-specific program information",
      "External Decks: Agency concept reviews and campaign updates"
    ],
    "evidence_quote": "if I'm starting from a macro level, I think you have your internal decks versus your external decks...the internal decks you have your summarize like your POV or just like requests that you're trying to do. You have other decks where it's just like, hey, what is the latest and greatest with this project that you're leading? You have decks where I need a single source of truth of everything that's gone on with this product...you get the random leadership as decks...external like facing maybe for project specific programs",
    "source_transcript": "transcripts_normalized/Presentation Interivew Kwaku 2025-09-26 16_31 transcript.json",
    "source_date": "2025-09-26"
  },
  {
    "name": "Presentation Style Adaptation Framework",
    "type": "decision_framework",
    "confidence": 0.88,
    "description": "A decision logic for adjusting presentation style based on organizational culture - choosing between straightforward data presentation versus storytelling approach",
    "components": [
      "If Meta: straightforward, minimal fluff, direct approach",
      "If Pepsi: storytelling approach, bring people along the narrative",
      "Adjust style according to company culture and expectations"
    ],
    "evidence_quote": "I'm not the fanciest deck maker. I'm very simple, straight to the point where it's just like, hey, this is what we're trying to do. Here's the ass, here's what I need, here are the teams...Meta is definitely a little bit more, they appreciate just going straightforward, not as much fluff. Whereas like Pepsi is a little bit more like you want to bring people along and like storytell. So I've adjusted my style accordingly.",
    "source_transcript": "transcripts_normalized/Presentation Interivew Kwaku 2025-09-26 16_31 transcript.json",
    "source_date": "2025-09-26"
  },
  {
    "name": "Template Reuse Workaround Process",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "A step-by-step process for saving and reusing presentation templates when the native save function fails, using AI drive storage and prompt-based template adaptation",
    "components": [
      "Create a slide with desired template design",
      "Save the slide to AI drive",
      "When creating new presentation, upload the saved slide",
      "Prompt AI to adapt the template from the previous slide",
      "AI replicates the template for new content"
    ],
    "evidence_quote": "all I have to do is since there's. There's an AI drive once I create a slide that I want and then I save it there, if I have to create another slide using that template, all I have to do is to upload the slide and then give you my instructions the prompt to say adapt the templates that you used for this previous slide and that it will do that",
    "source_transcript": "transcripts_normalized/Review 1 2025-08-13 08_06 transcript.json",
    "source_date": "2025-08-13"
  },
  {
    "name": "Brand Color Integration Process",
    "type": "process_framework",
    "confidence": 0.9,
    "description": "Two alternative methods for integrating brand colors into AI-generated presentations: direct color code input or logo-based color extraction",
    "components": [
      "Method 1: Provide specific brand color codes to AI",
      "Method 2: Upload brand logo and ask AI to extract color codes",
      "AI generates template variations using extracted/provided colors",
      "Review and select preferred color-dominant version"
    ],
    "evidence_quote": "What I did for this particular slide was that I gave it the codes for the brand color... I didn't have the brand color. So what I did was I took the church logo and I told genspark to determine what the color code would be and then create a brand template using the logo",
    "source_transcript": "transcripts_normalized/Review 1 2025-08-13 08_06 transcript.json",
    "source_date": "2025-08-13"
  },
  {
    "name": "AI Misunderstanding Resolution Process",
    "type": "decision_framework",
    "confidence": 0.88,
    "description": "A troubleshooting framework for resolving AI hallucination or misunderstanding issues by escalating from text prompts to visual examples",
    "components": [
      "Attempt text-based reprompting (multiple iterations)",
      "Provide detailed textual explanation of the error",
      "If issue persists after 6+ attempts, take screenshot of problem",
      "Feed visual example to AI with clarification",
      "AI aligns and corrects immediately with visual context"
    ],
    "evidence_quote": "I tried to reprompt it and reprompt it. I think I did over six times. But he wasn't getting it... So eventually I decided that a good thing to do would be to take a screenshot. So I took a screenshot of the COVID page and I fed it to you to say this is what I'm referring to. And then, you know, say, oh, I get it now",
    "source_transcript": "transcripts_normalized/Review 1 2025-08-13 08_06 transcript.json",
    "source_date": "2025-08-13"
  },
  {
    "name": "Content Formatting Optimization Process",
    "type": "process_framework",
    "confidence": 0.85,
    "description": "Method for ensuring AI-generated slide content fits properly for export by prompting for non-interactive, single-view formatting",
    "components": [
      "AI generates initial slide with content",
      "Identify if content requires scrolling or is cut off",
      "Prompt AI to 'fit to screen' or show 'at a glance'",
      "Explain export constraints (PDF/PPT format limitations)",
      "AI reformats to static, fully visible layout"
    ],
    "evidence_quote": "if you give it the a further prompt to say something like fit to screen or something like saying write it in such a way that I see the I see all the information at a glance or at a snapshot. Because most of these slides that it creates are usually interactive in nature where you can scroll. But when you're giving it a prompt you have to explain to it that you don't have the opportunity to scroll",
    "source_transcript": "transcripts_normalized/Review 1 2025-08-13 08_06 transcript.json",
    "source_date": "2025-08-13"
  },
  {
    "name": "Technical Implementation Support Framework",
    "type": "engagement_framework",
    "confidence": 0.82,
    "description": "Process for engaging technical experts to implement complex open-source tools through guided walkthroughs while managing confidentiality considerations",
    "components": [
      "Identify technical barrier (firewall, setup complexity)",
      "Consider seeking developer assistance",
      "Verify confidentiality/sharing permissions before engagement",
      "Set up screen-sharing walkthrough session",
      "Replicate implementation steps while observing expert"
    ],
    "evidence_quote": "I wanted to know even though it's an open resource, if I could ask one of my friend that is a developer to walk me through like sort of be implementing it and then I'm seeing what he's doing on his screen and then I'm able to replicate it. But I wanted to know if it was something that I could share so that I don't breach confidentiality",
    "source_transcript": "transcripts_normalized/Review 1 2025-08-13 08_06 transcript.json",
    "source_date": "2025-08-13"
  },
  {
    "name": "Prompt Clarity Effectiveness Principle",
    "type": "measurement_framework",
    "confidence": 0.8,
    "description": "Observation-based principle that AI execution speed correlates with prompt clarity, serving as an indicator of prompt quality",
    "components": [
      "Clear, specific prompts result in fast changes",
      "Vague prompts result in slower or incorrect outputs",
      "Speed of accurate response indicates prompt effectiveness"
    ],
    "evidence_quote": "It makes changes very very fast where it's not vague, where it's very clear",
    "source_transcript": "transcripts_normalized/Review 1 2025-08-13 08_06 transcript.json",
    "source_date": "2025-08-13"
  },
  {
    "name": "AI Use Case Discovery and Implementation Framework",
    "type": "process_framework",
    "confidence": 0.98,
    "description": "A three-step methodology for identifying, evaluating, and prioritizing AI use cases for product teams, followed by solution research, piloting, and rollout",
    "components": [
      "Review and align on potential AI use cases",
      "Evaluate use cases by impact nature (quality enhancement, efficiency improvement) and identify roadblocks",
      "Prioritize and create ranked list of 3-5 top use cases",
      "Research potential tools (vendor solutions or internal builds)",
      "Design and execute pilots/tests",
      "Roll out to full launch"
    ],
    "evidence_quote": "The first is to just review and make sure we're aligned on all the potential use cases for AI for the product side of enc... We'll then want to, as a team, evaluate all the use cases, starting with the highest impact ones... And then the main output that we want from this meeting is to have a list of use cases based on the greatest potential for the team for AI impact... So in terms of next steps, we'll probably circle back internally and start researching what are potential tools... And eventually we'll want to start piloting and testing these.",
    "source_transcript": "transcripts_normalized/AI Discovery and Prioritization Session - E&C Product 2025-08-06 12_01 transcript.json",
    "source_date": "2025-08-06"
  },
  {
    "name": "AI Impact Evaluation Framework",
    "type": "measurement_framework",
    "confidence": 0.92,
    "description": "A framework for evaluating AI use cases based on impact dimensions, focusing on quality enhancement and efficiency improvement, while identifying adoption barriers",
    "components": [
      "Nature of impact assessment",
      "Quality enhancement evaluation",
      "Efficiency improvement measurement",
      "Roadblock identification",
      "Adoption requirement analysis"
    ],
    "evidence_quote": "We'll then want to, as a team, evaluate all the use cases, starting with the highest impact ones and make sure that we evaluate them with a lens of what is the nature of this impact. So if we think an opportunity is high impact for a team, do we think that it's because it's going to enhance the quality, improve efficiency, so make people work a lot faster. And if there's any roadblocks. Or anything that we think is needed to drive adoption.",
    "source_transcript": "transcripts_normalized/AI Discovery and Prioritization Session - E&C Product 2025-08-06 12_01 transcript.json",
    "source_date": "2025-08-06"
  },
  {
    "name": "AI Solution Sourcing Framework",
    "type": "decision_framework",
    "confidence": 0.88,
    "description": "A decision framework for determining whether to use vendor tools, improve existing tool utilization, or build internal solutions for AI use cases",
    "components": [
      "Vendor/known tool assessment",
      "Tool utilization improvement evaluation",
      "Internal build option (agents, engineering collaboration)",
      "Solution selection and implementation"
    ],
    "evidence_quote": "This will vary a lot. Sometimes it's working with a vendor or a known tool like Gamma or figma and like improving the utilization of those tools. Sometimes it's building something internally like creating agents or working with the engineers to try to create solutions.",
    "source_transcript": "transcripts_normalized/AI Discovery and Prioritization Session - E&C Product 2025-08-06 12_01 transcript.json",
    "source_date": "2025-08-06"
  },
  {
    "name": "Pilot-to-Production Scaling Framework",
    "type": "scaling_framework",
    "confidence": 0.85,
    "description": "A methodology for scaling AI solutions from initial testing through pilot phases to full organizational launch",
    "components": [
      "Pilot/test design",
      "Scale determination (small vs. larger)",
      "Full launch rollout",
      "Team feedback and iteration"
    ],
    "evidence_quote": "And eventually we'll want to start piloting and testing these. So we'll also start thinking through the process of what a pilot or a test should look like, whether it should be small scale, larger scale, and how we can then roll it out to a full launch.",
    "source_transcript": "transcripts_normalized/AI Discovery and Prioritization Session - E&C Product 2025-08-06 12_01 transcript.json",
    "source_date": "2025-08-06"
  },
  {
    "name": "Stakeholder Preparation Framework",
    "type": "engagement_framework",
    "confidence": 0.9,
    "description": "A pre-meeting engagement approach using pre-work and pre-read materials to establish context and enable productive discussions",
    "components": [
      "Pre-work assignment",
      "Pre-read materials distribution",
      "Context setting before meeting",
      "Efficient meeting startup"
    ],
    "evidence_quote": "And thanks for filling out the pre work and pre read. I know it's a little bit of time, so I appreciate it... It sets a lot context, allows us to get started... Thanks again for doing the pre work and looking through the materials. It just really helps kind of guide the conversation and not start from scratch.",
    "source_transcript": "transcripts_normalized/AI Discovery and Prioritization Session - E&C Product 2025-08-06 12_01 transcript.json",
    "source_date": "2025-08-06"
  },
  {
    "name": "Vendor Evaluation and Selection Framework",
    "type": "decision_framework",
    "confidence": 0.87,
    "description": "A framework for evaluating multiple vendors based on use case requirements, narrowing down options by distinguishing between IDE and non-IDE solutions for different team needs",
    "components": [
      "Multiple vendor evaluation (starting with 3)",
      "Use case alignment (rapid prototyping vs. production deployment)",
      "Tool categorization (IDE vs. non-IDE)",
      "Narrowing to final selection (goal of 2 solutions)",
      "Strength-based selection for different workflows"
    ],
    "evidence_quote": "We're talking with three vendors right now... 3 with the getting down to 2 like 1 is a non ID, so not something that would deploy into production... we're looking at lovable and v0 that's more for like as we'll get into these use cases. Rapid prototyping and then the IDE is one where design and product engineering would leverage the same software... They both have strengths of different things at things.",
    "source_transcript": "transcripts_normalized/AI Discovery and Prioritization Session - E&C Product 2025-08-06 12_01 transcript.json",
    "source_date": "2025-08-06"
  },
  {
    "name": "Tech Shots Training Model",
    "type": "model_framework",
    "confidence": 0.92,
    "description": "A quick, interactive coaching session format designed to introduce employees to technical solutions they may not be aware of or underutilizing",
    "components": [
      "Quick interactive coaching sessions",
      "Focus on available but underutilized solutions",
      "Tech team derived content",
      "Regular monthly cadence"
    ],
    "evidence_quote": "we started this new thing called Tech Shots, trying to make like a play on a name and whether being a liquor company, like quick, interactive kind of coaching sessions to tell people about different solutions that we have that they may not be aware of or that they're not utilizing.",
    "source_transcript": "transcripts_normalized/Patrick Johnson and Kyra Atekwana 2025-07-22 12_02 transcript (1).json",
    "source_date": "2025-07-22"
  },
  {
    "name": "AI Training Evolution Process",
    "type": "process_framework",
    "confidence": 0.88,
    "description": "A phased approach to rolling out AI training, starting with basic tool introduction and evolving to advanced use cases based on user maturity",
    "components": [
      "Phase 1: Introduce Copilot in Edge (Windows 11 license introduction)",
      "Phase 2: Create standardized training session with use cases",
      "Phase 3: Scale globally with multiple coaches and languages",
      "Phase 4: Evolve to 2.0 version for advanced users"
    ],
    "evidence_quote": "We're going to come back in September with kind of like a 2.0 or we're still going to still do the same session, but we wanted to move forward with more of like a higher level. We feel like people are getting the basics now and they really can move forward.",
    "source_transcript": "transcripts_normalized/Patrick Johnson and Kyra Atekwana 2025-07-22 12_02 transcript (1).json",
    "source_date": "2025-07-22"
  },
  {
    "name": "Global Training Delivery Framework",
    "type": "scaling_framework",
    "confidence": 0.9,
    "description": "A scalable approach to delivering consistent training globally while allowing for local customization",
    "components": [
      "Core standardized content",
      "Multiple coaches globally",
      "Multiple language support",
      "Coach-specific examples and customization",
      "Open registration via IT calendar",
      "Custom sessions for specific divisions on request"
    ],
    "evidence_quote": "It's myself, a few other coaches globally. We're now up to a few more languages that would coach on these... we tried to coach people on this is the content we want to get across, more or less use your own examples or your own business cases maybe that are unique to the audience you're going to speak to",
    "source_transcript": "transcripts_normalized/Patrick Johnson and Kyra Atekwana 2025-07-22 12_02 transcript (1).json",
    "source_date": "2025-07-22"
  },
  {
    "name": "Six Use Case Demonstration Framework",
    "type": "engagement_framework",
    "confidence": 0.93,
    "description": "A structured demonstration approach using six practical business use cases to show AI capabilities in context of a coherent scenario",
    "components": [
      "Use Case 1: Craft professional emails (manager inviting new hires)",
      "Use Case 2: Create interactive quizzes (product/brand knowledge)",
      "Use Case 3: Generate images for presentations",
      "Use Case 4: Research and compile structured information (finding venues with specific criteria in table format)",
      "Cohesive narrative: New hire onboarding scenario",
      "Live demonstration with audience input"
    ],
    "evidence_quote": "we go through the six use cases and we kind of just show them the different ways that they can use it... the role that I usually play is I become like a manager of a team. I have a bunch of new hires on my team and I'm inviting them to New York for like an onboarding. So I craft an email using the AI... I make like a quiz on our products... we would create like some images for the presentation... We find a bar to go to",
    "source_transcript": "transcripts_normalized/Patrick Johnson and Kyra Atekwana 2025-07-22 12_02 transcript (1).json",
    "source_date": "2025-07-22"
  },
  {
    "name": "Content Delivery Approach",
    "type": "engagement_framework",
    "confidence": 0.85,
    "description": "A discovery-based learning approach that demonstrates capabilities while encouraging participant questions and idea generation",
    "components": [
      "Discovery class format",
      "Demonstration-led (not hands-on participation)",
      "Show speed and ease of execution",
      "Limited interactive elements (mic opens for suggestions)",
      "Encourage questions throughout",
      "Focus on replicable use cases"
    ],
    "evidence_quote": "This one is kind of like in a discovery class. So we go through the six use cases and we kind of just show them the different ways that they can use it... just kind of giving them some tangible, like, ways that get their, like their gears grinding on how they could then replicate some of these on their own",
    "source_transcript": "transcripts_normalized/Patrick Johnson and Kyra Atekwana 2025-07-22 12_02 transcript (1).json",
    "source_date": "2025-07-22"
  },
  {
    "name": "Training Access Model",
    "type": "engagement_framework",
    "confidence": 0.87,
    "description": "A dual-access approach offering both open enrollment and customized sessions for specific groups",
    "components": [
      "Open sessions: Monthly IT calendar with open registration",
      "Custom sessions: Division/team-specific requests",
      "Custom sessions triggered by: Town halls, group requests, word-of-mouth",
      "Ability to customize content for specific audiences"
    ],
    "evidence_quote": "For the most part it's been open sessions. Definitely have done quite a few, like division or like different groups that have reached out and said, you know, hey, we really like these sessions or somebody took it. Can you coach like our group at our, you know, town hall",
    "source_transcript": "transcripts_normalized/Patrick Johnson and Kyra Atekwana 2025-07-22 12_02 transcript (1).json",
    "source_date": "2025-07-22"
  },
  {
    "name": "Training Content Adaptation Framework",
    "type": "process_framework",
    "confidence": 0.86,
    "description": "An iterative approach to evolving training content in response to product changes and feature availability",
    "components": [
      "Monitor product evolution (Copilot feature changes)",
      "Adapt content to available features",
      "Update based on data protection/compliance changes",
      "Shift focus as capabilities change (Edge compose features to chat features)"
    ],
    "evidence_quote": "It's evolved a little bit from the start... Copilot has changed a little bit as well. Because we were predominantly just talking about Copilot and Edge at the time. Now we've moved over to, you know, Copilot chat... They've changed a lot around with after the data protection in regards to some of the features that we had... like the compose and all the features in Edge is kind of like gone",
    "source_transcript": "transcripts_normalized/Patrick Johnson and Kyra Atekwana 2025-07-22 12_02 transcript (1).json",
    "source_date": "2025-07-22"
  },
  {
    "name": "Training Reach Measurement",
    "type": "measurement_framework",
    "confidence": 0.8,
    "description": "Basic metrics tracked to measure training adoption and reach",
    "components": [
      "Number of people coached",
      "Time period tracked",
      "Geographic/global reach"
    ],
    "evidence_quote": "we've coached about a little over 2,000 people within the last year and a year and a few months",
    "source_transcript": "transcripts_normalized/Patrick Johnson and Kyra Atekwana 2025-07-22 12_02 transcript (1).json",
    "source_date": "2025-07-22"
  },
  {
    "name": "AI Use Case Prioritization Framework",
    "type": "process_framework",
    "confidence": 0.98,
    "description": "A three-phase methodology for evaluating and prioritizing AI use cases across organizational functions",
    "components": [
      "Phase 1: Review use cases and ensure alignment on definitions",
      "Phase 2: Evaluate potential impact (efficiency vs quality gains), understand blockers, and determine adoption requirements",
      "Phase 3: Rank order high-priority use cases from top to bottom"
    ],
    "evidence_quote": "So we'll spend just a little bit time up front, just kind of quick review of the use cases, make sure everyone's on the same page, kind of understands what they are so that when we get to prioritizing, we're all speaking the same language and then spend the bulk of our time evaluating them on their potential impact... And then we can spend the last few minutes maybe just going through the highs if we get to the mediums. Great of just, hey, let's rank order these.",
    "source_transcript": "transcripts_normalized/Technology - AI Discovery & Prioritization Session 2025-08-04 11_31 transcript.json",
    "source_date": "2025-08-04"
  },
  {
    "name": "AI Impact Assessment Model",
    "type": "model_framework",
    "confidence": 0.92,
    "description": "A dual-dimension model for classifying AI use case impact based on type of value created and priority level",
    "components": [
      "Impact Level Classification: High, Medium, or Low",
      "Value Type Classification: Efficiency gains vs Quality gains",
      "Blocker Identification: What prevents implementation today",
      "Adoption Requirements: What is needed to drive future adoption"
    ],
    "evidence_quote": "What I really want to focus on in this second part... is understanding why we're saying it's high, medium or low impact for potential AI use. And then understanding is it primarily an efficiency or a quality gain. And then for the ones that are high, I want to spend a little time discussing, hey, what's kind of blocking this from happening today and then what's really needed to drive adoption in the future.",
    "source_transcript": "transcripts_normalized/Technology - AI Discovery & Prioritization Session 2025-08-04 11_31 transcript.json",
    "source_date": "2025-08-04"
  },
  {
    "name": "AI Pilot-to-Production Process",
    "type": "scaling_framework",
    "confidence": 0.88,
    "description": "A staged approach for moving from AI use case identification to pilot testing and production deployment",
    "components": [
      "Step 1: Identify and prioritize use cases across functions",
      "Step 2: Research and identify AI tools that address prioritized use cases",
      "Step 3: Design tests and pilots",
      "Step 4: Measure impact and success metrics",
      "Step 5: Scale successful pilots"
    ],
    "evidence_quote": "And then from there we'll kind of go away and work with you guys as well. And I think I saw some people even already filling in some tools. But look for what are the AI tools out there that can address these solutions or these use cases. And then we'll work with you all to start designing tests and pilots where appropriate.",
    "source_transcript": "transcripts_normalized/Technology - AI Discovery & Prioritization Session 2025-08-04 11_31 transcript.json",
    "source_date": "2025-08-04"
  },
  {
    "name": "Cross-Functional AI Discovery Framework",
    "type": "engagement_framework",
    "confidence": 0.9,
    "description": "A systematic approach to gathering AI use cases by conducting function-by-function meetings across the organization",
    "components": [
      "Function-by-function meetings",
      "Identification of highest priority use cases",
      "Include both underway and potential new use cases",
      "Create consolidated prioritized list per function"
    ],
    "evidence_quote": "But quick reminder, we're kind of been going across function by function, looking for what are the highest priority AI Use cases, both underway and potential new ones. So hoping to spend the time today with the end goal of coming out of this with a list of all the use cases in technology, kind of prioritize top to bottom.",
    "source_transcript": "transcripts_normalized/Technology - AI Discovery & Prioritization Session 2025-08-04 11_31 transcript.json",
    "source_date": "2025-08-04"
  },
  {
    "name": "AI Technology Organizational Taxonomy",
    "type": "model_framework",
    "confidence": 0.85,
    "description": "A categorical structure for organizing AI use cases by technology function area",
    "components": [
      "Engineering (coding, testing, documentation)",
      "Security",
      "Infrastructure",
      "Data Analytics"
    ],
    "evidence_quote": "So I've kind of broken this up into a few buckets. Engineering, security and infrastructure. The one piece of kind of the technology org that I think we're, we don't have as many ideas for is data analytics.",
    "source_transcript": "transcripts_normalized/Technology - AI Discovery & Prioritization Session 2025-08-04 11_31 transcript.json",
    "source_date": "2025-08-04"
  },
  {
    "name": "AI Value Measurement Framework",
    "type": "measurement_framework",
    "confidence": 0.87,
    "description": "An emerging framework for measuring and tracking the impact of AI deployments to demonstrate business value",
    "components": [
      "Identify what to measure (e.g., Engineer Throughput)",
      "Track deployment locations",
      "Measure impact quantitatively",
      "Report results to executive stakeholders (BHAG)"
    ],
    "evidence_quote": "Tom, as you have, you guys have been, as you've been standing up the pilot, have you put in anything to kind of measure the impact of that? I know that's one thing that's going to be coming up, you know, in a couple months here. I know BHAG is going to start to get interested in not just where we're deploying AI, but how we're measuring that impact and how impactful it is.",
    "source_transcript": "transcripts_normalized/Technology - AI Discovery & Prioritization Session 2025-08-04 11_31 transcript.json",
    "source_date": "2025-08-04"
  },
  {
    "name": "Subject Matter Expert Escalation Protocol",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "A methodology for handling technical questions beyond trainer expertise by positioning and utilizing client SMEs during training sessions",
    "components": [
      "Acknowledge expertise boundaries (AI experts, not domain experts)",
      "Position client SME availability upfront",
      "Mark escalation points explicitly in training outline",
      "Redirect technical questions to designated client expert during session"
    ],
    "evidence_quote": "we are AI experts, we are not any other kind of expert... if people start asking really in depth questions, you have to have somebody on your team available and ready to respond to those... if in the outline, as you revamp it, you could call out explicitly where those places are so that they can be prepared to know that should questions come up during this session, we are going to refer all of those questions to Katie or to Julia",
    "source_transcript": "transcripts_normalized/Kyra _ Tahnee Post Feedback TB 2025-10-24 15_39 transcript.json",
    "source_date": "2025-10-24"
  },
  {
    "name": "Generic vs. Client-Specific Activity Design",
    "type": "decision_framework",
    "confidence": 0.88,
    "description": "Decision logic for determining whether training activities should be generic or client-specific based on session management complexity",
    "components": [
      "If activity needs to be same for all participants: use generic version",
      "If client-specific customization desired: assign as homework",
      "Rationale: avoid confusion from different exercises in same session",
      "Position generic as 'test your knowledge' exercise"
    ],
    "evidence_quote": "If they want to do it where it's their own clients or it's like not generic, they need to make it a homework assignment. If we're going to do an activity, it has to be the same for everybody. Otherwise people will get confused and we can even say, like, hey, this is just a generic exercise to, like, test your knowledge",
    "source_transcript": "transcripts_normalized/Kyra _ Tahnee Post Feedback TB 2025-10-24 15_39 transcript.json",
    "source_date": "2025-10-24"
  },
  {
    "name": "Workshop Content Development Approval Process",
    "type": "process_framework",
    "confidence": 0.85,
    "description": "Iterative process for developing customized workshop content with client validation checkpoints",
    "components": [
      "Build initial content/exercises",
      "Review with client stakeholder (e.g., Taylor)",
      "Validate against client expectations",
      "Request client-specific slides/materials for integration",
      "Revise outline incorporating feedback"
    ],
    "evidence_quote": "I built out some of those, so it would just be a matter of running them by maybe Taylor and saying, is this what you expected?... I think what I need to see, though, is some of those slides they were talking about, because I think in their mind, they have very specific ways they want me to cover",
    "source_transcript": "transcripts_normalized/Kyra _ Tahnee Post Feedback TB 2025-10-24 15_39 transcript.json",
    "source_date": "2025-10-24"
  },
  {
    "name": "Workshop Complexity Classification",
    "type": "decision_framework",
    "confidence": 0.9,
    "description": "Framework for categorizing workshop difficulty and resource requirements based on existing materials and client clarity",
    "components": [
      "Easy workshops: existing deck, common material, established talk track, demos available",
      "Hard workshops: custom content, unclear client requirements, requires extensive development hours",
      "Decision factor: client knows what they want vs. client discovering requirements",
      "Resource allocation based on complexity tier"
    ],
    "evidence_quote": "The ones that are the best are like Autodesk as an example. Like, you already have the makings of Deck. It's got a lot of common material, so you can sign me up for those because they're easy... The ones that are hot are like, Horizon... it's already, like, hours and hours of work... the problem is Horizon doesn't know what they want",
    "source_transcript": "transcripts_normalized/Kyra _ Tahnee Post Feedback TB 2025-10-24 15_39 transcript.json",
    "source_date": "2025-10-24"
  },
  {
    "name": "Capacity Planning and Availability Management",
    "type": "scaling_framework",
    "confidence": 0.87,
    "description": "Proactive approach to managing trainer capacity by collecting advance availability to accommodate rapid workshop growth",
    "components": [
      "Identify major calendar blocks in advance (holidays, speaking engagements)",
      "Project potential workshop volume (e.g., 15+ workshops)",
      "Confirm capacity availability",
      "Enable sales team with trainer availability data",
      "Shift from ad hoc scheduling to advance planning"
    ],
    "evidence_quote": "we do a lot of, like, ad hoc outreach right now... are thinking about ways to sort of get people's availability in advance and, like, make it easier... What is your availability look like for November and December?... if we were to schedule for, let's say, like, 15 more workshops at the end of the year, is that something you think you'd have capacity for?",
    "source_transcript": "transcripts_normalized/Kyra _ Tahnee Post Feedback TB 2025-10-24 15_39 transcript.json",
    "source_date": "2025-10-24"
  },
  {
    "name": "Client Strong Opinion Management Protocol",
    "type": "engagement_framework",
    "confidence": 0.83,
    "description": "Approach for managing challenging client engagements where client has unclear requirements combined with strong opinions while service provider lacks domain-specific point of view",
    "components": [
      "Identify client clarity level (knows vs. doesn't know what they want)",
      "Assess strength of client opinions",
      "Evaluate provider's domain expertise and ability to guide",
      "Recognize challenging combinations (unclear + opinionated, weak provider POV)",
      "Sales team receives feedback to avoid similar engagements"
    ],
    "evidence_quote": "the problem is Horizon doesn't know what they want. And we're kind of, like, stuck trying to help them figure it out... it's tough because, like, we obviously don't have a very strong point of view. And so when we have, like, the combination of don't know what they want with strong opinions, where we don't have a strong opinion... we have pushed back on the sales team that they are no longer allowed to sell things like that",
    "source_transcript": "transcripts_normalized/Kyra _ Tahnee Post Feedback TB 2025-10-24 15_39 transcript.json",
    "source_date": "2025-10-24"
  },
  {
    "name": "AI Use Case Prioritization Framework",
    "type": "process_framework",
    "confidence": 0.98,
    "description": "A structured three-phase approach to identifying, evaluating, and piloting AI use cases in marketing",
    "components": [
      "Phase 1: Review and identify all AI use cases (45 minutes) - current solutions, new use cases from master sheet, and team-identified tools",
      "Phase 2: Evaluation using dual metrics - rate each use case by quality enhancement and efficiency improvement (high/medium/low)",
      "Phase 3: Prioritization and selection - create ranked list and select top 3-5 use cases for piloting"
    ],
    "evidence_quote": "We're going to start off the first roughly 45 minutes reviewing and making sure we have a clear understanding of all the use cases for AI and marketing... after we're done kind of making sure we have the right list, we're going to start the evaluation process... The goal at the end is to have a prioritized list of use cases based on their greatest potential for AI enablement. So we're going to select which ones are the top three to five use cases",
    "source_transcript": "transcripts_normalized/FW_ Marketing AI Discovery and Prioritization Session 2025-07-29 13_00 transcript.json",
    "source_date": "2025-07-29"
  },
  {
    "name": "Dual Metric Evaluation Framework",
    "type": "measurement_framework",
    "confidence": 0.95,
    "description": "A two-dimensional assessment system for evaluating AI use cases based on quality and efficiency impact",
    "components": [
      "Metric 1: Tool's ability to enhance quality of output",
      "Metric 2: Tool's ability to improve efficiency",
      "Rating scale: High, Medium, Low for each metric",
      "Overall score derived from both metrics"
    ],
    "evidence_quote": "And there's two main metrics we're going to look at. Once is the tool's ability or the use cases, ability to enhance quality of output and the tool's ability to improve efficiency. So we're going to tick through each of the main use case buckets, categorize each of them into high, medium, low, so pretty high level. And then we're going to have an overall score",
    "source_transcript": "transcripts_normalized/FW_ Marketing AI Discovery and Prioritization Session 2025-07-29 13_00 transcript.json",
    "source_date": "2025-07-29"
  },
  {
    "name": "AI Tool Deployment and Pilot Framework",
    "type": "scaling_framework",
    "confidence": 0.92,
    "description": "A structured approach to move from use case identification through piloting to organizational rollout",
    "components": [
      "Step 1: Identify suitable AI tool (or validate already-identified tool)",
      "Step 2: Engage with vendor or internal teams for feasibility assessment",
      "Step 3: Structure pilot or testing session",
      "Step 4: Define clear KPIs to measure pilot performance",
      "Step 5: Conditional broader rollout based on pilot results"
    ],
    "evidence_quote": "After we're done with this session, we are then going to start identifying what would be a suitable AI tool. If we've already identified an AI tool, we can then start talking to the vendor. If it's internal, start talking to the right teams, seeing if this is even feasible... Then we're going to think about how to structure a pilot or a testing session to see what the AI tool can actually perform. And we'll make sure to have a clear defined set of KPIs that we measure before we roll out to the broader organization",
    "source_transcript": "transcripts_normalized/FW_ Marketing AI Discovery and Prioritization Session 2025-07-29 13_00 transcript.json",
    "source_date": "2025-07-29"
  },
  {
    "name": "Enterprise AI Transformation Team Engagement Model",
    "type": "engagement_framework",
    "confidence": 0.9,
    "description": "Defines the role and boundaries of the central AI transformation team as enablers rather than gatekeepers",
    "components": [
      "Team autonomy: Marketing has decision-making authority for tool deployment",
      "Facilitation role: Transformation team enables deployment, not approval authority",
      "Compliance support: Help navigate information security requirements",
      "Process improvement: Streamline AI tool approval processes",
      "Impact tracking: Report successes to executive leadership and board"
    ],
    "evidence_quote": "our Enterprise AI Transformation team, helps facilitate deployment of AI tools within marketing. We're not intended to be a gatekeeper or an approval entity that says yes or no to tools like you guys have autonomy... the goal is that you guys can deploy tools that you think are going to move the needle in marketing. And our role as part of the Transformation team is to help enable that... we're working through now is streamlining of the approval process... There may be also a role that we play which is helping to kind of track the impact of the bigger tools",
    "source_transcript": "transcripts_normalized/FW_ Marketing AI Discovery and Prioritization Session 2025-07-29 13_00 transcript.json",
    "source_date": "2025-07-29"
  },
  {
    "name": "Three Distinct Features for Enterprise Adoption",
    "type": "model_framework",
    "confidence": 0.92,
    "description": "A product differentiation model requiring three unique features that solve direct enterprise problems to compete against established platforms like Microsoft",
    "components": [
      "Feature must be distinct/unique from existing solutions",
      "Feature must solve a direct enterprise problem",
      "Need minimum of three such features for viable product"
    ],
    "evidence_quote": "you need like, we need like three. The advice I got is you almost need like three very distinct features that are unique. Right. That solves a direct problem on an enterprise because Microsoft is not going to go down that direction.",
    "source_transcript": "transcripts_normalized/Review 2025-09-21 14_00 transcript.json",
    "source_date": "2025-09-21"
  },
  {
    "name": "Enterprise Feature Stack",
    "type": "model_framework",
    "confidence": 0.88,
    "description": "A four-component feature model for enterprise presentation tools that addresses data management, visualization intelligence, verification, and consistency",
    "components": [
      "Fact checker with source verification",
      "Data puller/deck finder for searching old decks and slides",
      "Intelligent visualization selection (appropriate chart types for data)",
      "Consistency checker (tick and tie slides, color palettes)"
    ],
    "evidence_quote": "So fact checker, a data puller, a deck finder, And so, like the last one we said last week was it also helps you tick and tie your slides. You know, if you go to Slide 30, make sure the information is consistent with Slide 4 and consistent with Slide 3, that kind of thing, Consistent color palettes, all that",
    "source_transcript": "transcripts_normalized/Review 2025-09-21 14_00 transcript.json",
    "source_date": "2025-09-21"
  },
  {
    "name": "Cash Grab vs Enterprise Value Decision Framework",
    "type": "decision_framework",
    "confidence": 0.9,
    "description": "A strategic decision framework that determines product architecture based on business objectives",
    "components": [
      "If goal is 'cash grab' \u2192 choose browser extension approach",
      "If goal is 'enterprise value creation' \u2192 choose standalone product approach"
    ],
    "evidence_quote": "If this is a cash grab, you should go browser extension. If you're trying to create enterprise value, I think we have to have a standalone product.",
    "source_transcript": "transcripts_normalized/Review 2025-09-21 14_00 transcript.json",
    "source_date": "2025-09-21"
  },
  {
    "name": "Enterprise Adoption Risk Assessment",
    "type": "measurement_framework",
    "confidence": 0.85,
    "description": "A framework for evaluating whether an enterprise problem is painful enough to justify adoption costs, measuring problem severity against implementation barriers",
    "components": [
      "Problem must be painful/significant",
      "Problem must affect Fortune 3000 companies",
      "Value must justify risk of adopting new tool",
      "Value must justify training hundreds of employees",
      "Value must justify price point (e.g., $200)"
    ],
    "evidence_quote": "what specific enterprise presentation problem or problem is painful, that a Fortune 3000 company would risk adopting a new tool, train hundreds of employees and pay 200 to solve it?",
    "source_transcript": "transcripts_normalized/Review 2025-09-21 14_00 transcript.json",
    "source_date": "2025-09-21"
  },
  {
    "name": "Corporate Focus vs Niche Solution Strategy",
    "type": "decision_framework",
    "confidence": 0.87,
    "description": "A competitive positioning framework based on incumbent behavior - targeting specific problems that large corporations won't solve due to their broad focus",
    "components": [
      "Identify what incumbents solve for 'everybody all at once'",
      "Identify specific problems incumbents won't address",
      "Build solutions for those specific corporate needs",
      "Position for potential acquisition by solving what's too narrow for incumbents"
    ],
    "evidence_quote": "So if you, if you're able to solve those other things, then go ahead with it and they will most likely just buy you out because it's going to take them too long to do so... they're not focused on corporations, they're focused on things they can solve for everybody all at once.",
    "source_transcript": "transcripts_normalized/Review 2025-09-21 14_00 transcript.json",
    "source_date": "2025-09-21"
  },
  {
    "name": "First Call Qualification Framework",
    "type": "process_framework",
    "confidence": 0.98,
    "description": "A structured approach for conducting initial sales calls that focuses on qualifying prospects rather than just pitching, using a four-part agenda structure",
    "components": [
      "Understand their current state and priorities",
      "Share approach to building AI powered orgs",
      "Determine fit/no-fit",
      "Define next steps or respectfully exit"
    ],
    "evidence_quote": "We set an agenda and we talk about, hey, we want to understand your priorities and then share our approach to building AI powered orgs. So we go through and we understand what's their current state, what's our approach to driving AI powered workforces, and then next steps.",
    "source_transcript": "transcripts_normalized/Company Lunch & Learn 2025-09-12 13_04 transcript.json",
    "source_date": "2025-09-12"
  },
  {
    "name": "Sales Pipeline Time Optimization Framework",
    "type": "decision_framework",
    "confidence": 0.95,
    "description": "A qualification-focused decision framework to determine which prospects warrant continued investment of time based on their seriousness about change management",
    "components": [
      "Qualify prospects in or out early",
      "Assess commitment to serious change management approach",
      "Eliminate 'wiki-load' prospects (AI curious but not serious)",
      "Focus time on prospects likely to convert"
    ],
    "evidence_quote": "We actually don't want to spend too much time talking to people that aren't going to give us money, for lack of a better term. Right. So a lot of the first callback is to qualify are these people that could be customers for us. Right. Should we spend more time with these folks?",
    "source_transcript": "transcripts_normalized/Company Lunch & Learn 2025-09-12 13_04 transcript.json",
    "source_date": "2025-09-12"
  },
  {
    "name": "Respect Contract Framework",
    "type": "engagement_framework",
    "confidence": 0.92,
    "description": "A mutual agreement approach that gives prospects explicit permission to say no, reducing wasted time on non-committal prospects",
    "components": [
      "Present agenda upfront",
      "Discuss objectives and approach",
      "Offer explicit exit option",
      "Encourage honest fit/no-fit feedback"
    ],
    "evidence_quote": "It's something called a respect contract. We say, hey, we're going to talk a little bit about your objectives. We're going to share our approach. If it's a fit, let's schedule more time and continue the discussion. If it's not, that's okay, you can tell us, right? Because the last thing we want to be as salespeople is like strung along with people that aren't that are, that are too nice to say no.",
    "source_transcript": "transcripts_normalized/Company Lunch & Learn 2025-09-12 13_04 transcript.json",
    "source_date": "2025-09-12"
  },
  {
    "name": "Two-Layer Sales Deck Framework",
    "type": "model_framework",
    "confidence": 0.9,
    "description": "A conceptual model that separates 'what' (the promised land/outcomes) from 'how' (implementation details) in early sales conversations",
    "components": [
      "Credibility warmer (establish legitimacy)",
      "Preview 'what we help with' (promised land)",
      "Withhold 'how we do it' (implementation details)",
      "Qualify for next conversation"
    ],
    "evidence_quote": "We are previewing what we help customers with, like the promised land. We're not necessarily getting into the details of how we do it. Right. And that's an important distinction. We're not trying to show them exactly how we do these things, but more what we do so we can see does it align.",
    "source_transcript": "transcripts_normalized/Company Lunch & Learn 2025-09-12 13_04 transcript.json",
    "source_date": "2025-09-12"
  },
  {
    "name": "Prospect Qualification Criteria Framework",
    "type": "decision_framework",
    "confidence": 0.93,
    "description": "Specific criteria for determining if a prospect should advance in the pipeline, focused on commitment to serious organizational change",
    "components": [
      "Assess commitment to change management approach",
      "Evaluate seriousness about AI deployment (not just AI curiosity)",
      "Determine if problems align with Section's solutions",
      "Verify prospect has decision-making authority/intent"
    ],
    "evidence_quote": "This deck is intended to qualify out. Understand who is not interested in and you'll notice in bold, a serious change management approach to AI deployment. Right. We're not really interested in wiki load as people that are just kind of like interested in AI for the sake of AI.",
    "source_transcript": "transcripts_normalized/Company Lunch & Learn 2025-09-12 13_04 transcript.json",
    "source_date": "2025-09-12"
  },
  {
    "name": "New Hire Onboarding Process",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "Step-by-step methodology for onboarding new employees from notification to successful onboarding, executed on a bi-weekly cycle",
    "components": [
      "Receive notification from Bamboo HR (hire name, team, location, manager)",
      "Add to master new hire tracker with start dates and details",
      "Create personal tracking sheet with checklist items",
      "Add start date to executive's calendar",
      "Send email to hiring manager",
      "Schedule meetings (TNE compliance, day one, week one, month one)",
      "Send email to new hire (timing: less than 10 days before start)",
      "Manual daily check-in to tracker to complete tasks"
    ],
    "evidence_quote": "Basically we get a notification from Bamboo HR saying, you know, that this is the new hire. This is the team they're on, is the location they're in. And then from there I then put it into...one tracker that has all of our new hires in one place and the dates they start...Then I have my own personal tracker...I have little check boxes for each separate one...there's a whole timeline on when those things need to be done.",
    "source_transcript": "transcripts_normalized/Valentina Pannullo and Kyra Atekwana 2025-09-22 15_31 transcript.json",
    "source_date": "2025-09-22"
  },
  {
    "name": "Time-Based Task Management Framework",
    "type": "decision_framework",
    "confidence": 0.85,
    "description": "Manual decision-making logic for determining when onboarding tasks should be executed based on proximity to start date",
    "components": [
      "Daily manual review of tracking sheet",
      "Task prioritization based on start date proximity",
      "10-day threshold for new hire email trigger",
      "Personal knowledge-based execution (no automated triggers)"
    ],
    "evidence_quote": "It's so not automated to the point where like I just look, I like live in this sheet and I know like for example...now I just go into the sheet every day. I just kind of check off the things that I need to do, and I just know when. Like if I haven't sent the new hire that email yet and it's now less than 10 days before, I just know that, that I need to do that. Nothing is emailing me, triggering me to do these things.",
    "source_transcript": "transcripts_normalized/Valentina Pannullo and Kyra Atekwana 2025-09-22 15_31 transcript.json",
    "source_date": "2025-09-22"
  },
  {
    "name": "EA Needs Assessment Consultation Framework",
    "type": "engagement_framework",
    "confidence": 0.88,
    "description": "Structured approach to understanding client needs for AI upskilling through role analysis and process discovery",
    "components": [
      "Understand organizational needs",
      "Build custom learning content based on needs",
      "Ask about individual role and scope",
      "Explore typical week structure",
      "Deep dive into specific processes",
      "Identify automation opportunities",
      "Distinguish between AI solutions vs. traditional automation"
    ],
    "evidence_quote": "I work with all of our clients to basically do what I'm doing right now, understand what the needs are within the organization and then build some custom learning content based on that...would just love to learn a little bit more about you and if you could sort of give me a little insight on the scope of your role...what does your week typically look like...I would actually love to dig into that a little bit deeper.",
    "source_transcript": "transcripts_normalized/Valentina Pannullo and Kyra Atekwana 2025-09-22 15_31 transcript.json",
    "source_date": "2025-09-22"
  },
  {
    "name": "Rapid Growth HR Scaling Model",
    "type": "model_framework",
    "confidence": 0.78,
    "description": "Organizational approach to managing HR operations during rapid company growth with emphasis on standardization and re-onboarding",
    "components": [
      "Bi-weekly new hire cohorts (every 2 weeks)",
      "Standardized onboarding timeline (day one, week one, month one touchpoints)",
      "Company-wide re-onboarding initiative for alignment",
      "Project-based HR support model",
      "Organizational mapping and structure documentation"
    ],
    "evidence_quote": "we've doubled in size in the past year so we definitely have a lot of initiatives around onboarding and the HR team in general...we have new hires starting every two weeks...We're broadly like trying to re onboard the whole company as far as like just learning but kind of backtracking, like making sure everyone's on the same page with things.",
    "source_transcript": "transcripts_normalized/Valentina Pannullo and Kyra Atekwana 2025-09-22 15_31 transcript.json",
    "source_date": "2025-09-22"
  },
  {
    "name": "AI-Assisted Prompt Engineering Workflow",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "Multi-step process for creating comprehensive prompts using AI assistance, involving data collection, prompt generation through one AI tool, and execution through another",
    "components": [
      "Collect source materials (chats, polls, transcripts)",
      "Send to GPT5Pro to generate system prompt and 15 follow-up prompts",
      "Transfer prompts to Claude project for better document management",
      "Execute initial analysis prompt (25 minutes)",
      "Run sub-prompts and follow-ups for deeper analysis"
    ],
    "evidence_quote": "I went through and got all of the chats and the polls and the transcripts of everything from January to October, sent it to GPT5Pro, told it to come up with a series of 15 prompts, including a system prompt and a kickoff prompt. So I could put that into a cloud project which manages attachments and memory for these types of documents much better",
    "source_transcript": "transcripts_normalized/Tom _ Kyra_ Working Session 2025-10-23 14_03 transcript.json",
    "source_date": "2025-10-23"
  },
  {
    "name": "Progressive Prompt Practice Framework",
    "type": "engagement_framework",
    "confidence": 0.88,
    "description": "Two-stage approach to teaching prompt engineering through hands-on exercises with sharing and comparison",
    "components": [
      "Provide basic prompt template",
      "Have participants create comprehensive prompt (using framework screenshot)",
      "Participants share prompts and insights in chat",
      "Execute and compare differences",
      "Alternative: AI-guided interview method to build prompts"
    ],
    "evidence_quote": "here's a basic prompt, now make a comprehend. I just skipped straight to like make a comprehensive one based on this. And then people can share and then it's like. And then do that and pay are the differences. Share your prompt and your insights in the chat",
    "source_transcript": "transcripts_normalized/Tom _ Kyra_ Working Session 2025-10-23 14_03 transcript.json",
    "source_date": "2025-10-23"
  },
  {
    "name": "Meta-Prompting Interview Method",
    "type": "process_framework",
    "confidence": 0.85,
    "description": "AI-guided process where the AI interviews the user through framework components to create a final prompt",
    "components": [
      "Share framework slides with AI",
      "Ask AI to interview you through each building block",
      "AI creates final prompt based on interview responses"
    ],
    "evidence_quote": "I gave the slides to her and then basically asked her to be like ask ChatGPT to take you through each building block to interview you so you can create and then it will create the prompt for you at the end",
    "source_transcript": "transcripts_normalized/Tom _ Kyra_ Working Session 2025-10-23 14_03 transcript.json",
    "source_date": "2025-10-23"
  },
  {
    "name": "Use Case Translation Framework",
    "type": "decision_framework",
    "confidence": 0.78,
    "description": "Approach to help users understand how to apply demonstrated examples to their own work context by recognizing transferable patterns",
    "components": [
      "Identify pattern in demonstration (e.g., creating a brief)",
      "Recognize parallel use case in own work (e.g., creating a memo)",
      "Apply same methodology one-to-one to new context"
    ],
    "evidence_quote": "I think part of it is that people don't understand how to find use cases for themselves for work. And so I want you to tell me how I should be using it for work as opposed to like, oh, I just saw you do it for. To create like a brief. I could probably do that to create my next like memo",
    "source_transcript": "transcripts_normalized/Tom _ Kyra_ Working Session 2025-10-23 14_03 transcript.json",
    "source_date": "2025-10-23"
  },
  {
    "name": "AI Context Enhancement Through Meeting Transcription",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "A systematic approach to providing rich context to LLMs by recording meetings, transcribing them, and uploading transcripts to AI tools for enhanced contextual understanding",
    "components": [
      "Record all work meetings using automated transcription tool",
      "Sync transcription tool with calendar for automatic joining",
      "Generate transcripts with speaker identification and summaries",
      "Upload 2-3 relevant transcripts to LLM when working on related tasks",
      "Enable memory/personalization settings in AI tool to retain context"
    ],
    "evidence_quote": "I record 100 of my meetings... it comes automatically. I sync it with my calendar and it joins the meeting and then, and then you have those transcripts. And the transcripts become extremely rich context for the LLM. So when I, anytime I'm doing anything work related, I'm uploading like two to three transcripts from the meetings I was in where these things were discussed.",
    "source_transcript": "transcripts_normalized/Fotemah 1_1 Session 2025-11-02 20_30 transcript.json",
    "source_date": "2025-11-02"
  },
  {
    "name": "AI Model Selection Decision Framework",
    "type": "decision_framework",
    "confidence": 0.88,
    "description": "A decision logic for choosing between different AI model speeds based on task complexity and accuracy requirements",
    "components": [
      "Fast/Instant mode: For quick, straightforward queries requiring immediate responses",
      "Thinking mode: For research, analysis, and complex problems requiring planning and higher accuracy",
      "Deep Research mode: For comprehensive internet-wide research with limited monthly usage"
    ],
    "evidence_quote": "You basically have really fast, really slow. And in between is what these different models are and they relate to how much work it's doing to come up with a plan and a process. So if you're doing things like research or an analysis, like you want to have your thinking mode turned on because then it's going to create a plan and then work through that plan instead of just predicting the next answer",
    "source_transcript": "transcripts_normalized/Fotemah 1_1 Session 2025-11-02 20_30 transcript.json",
    "source_date": "2025-11-02"
  },
  {
    "name": "AI Agent vs Prompt Tool Distinction Model",
    "type": "model_framework",
    "confidence": 0.85,
    "description": "A conceptual model differentiating between AI agents that execute goals autonomously versus simple prompt-based tools that respond to specific tasks",
    "components": [
      "Prompt-based tool: Receives specific task, responds without deep planning",
      "AI Agent (Agentic tool): Receives goal, creates plan, asks clarifying questions, executes autonomously"
    ],
    "evidence_quote": "It's an agentic tool. It's an AI agent because it's going out and it's executing on some goal that you give it as opposed to a prompt you're giving a specific task. It's not really thinking about it. In this case, it is actually going to make a plan based on what you shared with it.",
    "source_transcript": "transcripts_normalized/Fotemah 1_1 Session 2025-11-02 20_30 transcript.json",
    "source_date": "2025-11-02"
  },
  {
    "name": "LLM Context Maximization Strategy",
    "type": "process_framework",
    "confidence": 0.9,
    "description": "A methodology for maximizing AI performance by systematically feeding it comprehensive context through personalization settings and memory features",
    "components": [
      "Enable memory/personalization settings in AI tool",
      "Provide specific instructions about your work context",
      "Allow AI to remember information about your projects and domain",
      "Continuously feed relevant transcripts and documents for context accumulation"
    ],
    "evidence_quote": "My personal opinion, like, the more context you give these things, especially because they have memory, the better. Because if you go into your personalization settings... You can give ChatGPT specific instructions and you can also have it remember things about you... it will start using. It'll understand all of your context",
    "source_transcript": "transcripts_normalized/Fotemah 1_1 Session 2025-11-02 20_30 transcript.json",
    "source_date": "2025-11-02"
  },
  {
    "name": "Product Redesign Project Timeline Framework",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "An aggressive timeline-based project approach where initial requirements gathering phase (2 weeks) is critical to achieving final delivery deadline (January)",
    "components": [
      "Project kickoff",
      "Requirements gathering phase (2 weeks)",
      "Execution phase",
      "Final delivery (January target)"
    ],
    "evidence_quote": "if we don't do this, then we won't finish until like, March... it all hinges on basically the next, like, two weeks, just like, gathering everything that you need to then be able to go do the work",
    "source_transcript": "transcripts_normalized/Section x Asurion_ Workflow Redesign Weekly Sync 2025-11-04 11_00 transcript.json",
    "source_date": "2025-11-04"
  },
  {
    "name": "PRD Cross-Functional Workflow Decomposition Model",
    "type": "model_framework",
    "confidence": 0.98,
    "description": "A model that breaks down the PRD process from a single workflow into multiple embedded workflows, identifying three core workflows ripe for automation",
    "components": [
      "Brief generation workflow",
      "Brief evaluation workflow",
      "PRD creation workflow"
    ],
    "evidence_quote": "we started with the idea that this PRD process was a single workflow, but it actually is this cross functional business process that has most multiple workflows embedded within it. And the three that we think are most ripe for automation are the brief generation step, the brief evaluation workflow and then the PRD creation workflow",
    "source_transcript": "transcripts_normalized/Section x Asurion_ Workflow Redesign Weekly Sync 2025-11-04 11_00 transcript.json",
    "source_date": "2025-11-04"
  },
  {
    "name": "AI Automation Implementation Framework",
    "type": "process_framework",
    "confidence": 0.96,
    "description": "A systematic approach to implementing LLM-based automation across identified workflows using custom GPT solutions",
    "components": [
      "Identify automation opportunities per workflow",
      "Build three LLM automations (likely custom GPTs)",
      "Deploy at least one GPT per workflow (brief generation, evaluation, PRD creation)",
      "Develop custom v0 vibe coding workshop for systematized adoption"
    ],
    "evidence_quote": "what we're going to build are three LLM automations. The assumption right now is probably custom GPTs... at least one, if not multiple GPTs for each of these workflows of generating the briefs, evaluating them and then also creating the PRDs and then let them know about this custom v0 vibe coding workshop",
    "source_transcript": "transcripts_normalized/Section x Asurion_ Workflow Redesign Weekly Sync 2025-11-04 11_00 transcript.json",
    "source_date": "2025-11-04"
  },
  {
    "name": "Workshop Adoption and Capability Building Framework",
    "type": "scaling_framework",
    "confidence": 0.88,
    "description": "A framework for scaling AI tool adoption through workshop-based training to systematize usage and build organizational capabilities",
    "components": [
      "Custom v0 vibe coding workshop development",
      "Systematize adoption across team",
      "Build vibe coding capabilities",
      "Lay groundwork for future expansion"
    ],
    "evidence_quote": "this custom v0 vibe coding workshop that we want to develop to help systematize that adoption across the team, build a vibe coding capabilities and also lay the groundwork for fut",
    "source_transcript": "transcripts_normalized/Section x Asurion_ Workflow Redesign Weekly Sync 2025-11-04 11_00 transcript.json",
    "source_date": "2025-11-04"
  },
  {
    "name": "Stakeholder Alignment Communication Framework",
    "type": "engagement_framework",
    "confidence": 0.9,
    "description": "A structured approach to ensuring stakeholder alignment through review meetings before formal delivery to ensure project success",
    "components": [
      "Draft project plan/approach",
      "Review with leadership/extended team for feedback",
      "Iterate based on input",
      "Deliver aligned plan to product team"
    ],
    "evidence_quote": "the purpose of the meeting is really to make sure that we have alignment on what we're doing with the team and how we intend to work with them moving forward in order to ensure success... just see if there's any thoughts or feedback before we deliver that to the team",
    "source_transcript": "transcripts_normalized/Section x Asurion_ Workflow Redesign Weekly Sync 2025-11-04 11_00 transcript.json",
    "source_date": "2025-11-04"
  },
  {
    "name": "AI Workflow Integration Framework",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "A step-by-step methodology for integrating AI into team workflows by identifying goals, breaking down processes, and determining AI value-add points",
    "components": [
      "Prioritize your workflow",
      "Define what you're trying to achieve with the workflow",
      "Break down your workflow into steps",
      "Identify within each step where AI could add value",
      "Determine appropriate AI solution (prompting, custom GPTs, or agents)"
    ],
    "evidence_quote": "So first you prioritize your workflow, then you think about what are you trying to achieve with that particular workflow that you do... And then you break down your workflow into steps. And then you think about what are the steps in, within each step, what are the ways that AI could add value?",
    "source_transcript": "transcripts_normalized/Kyra Atekwana's Zoom Meeting summary 2025-09-16 20_02 transcript.json",
    "source_date": "2025-09-16"
  },
  {
    "name": "Workflow Audit Framework",
    "type": "process_framework",
    "confidence": 0.85,
    "description": "A methodology for auditing existing workflows to identify tasks appropriate for AI augmentation or automation",
    "components": [
      "Review current tasks",
      "Identify tasks appropriate for AI augmentation",
      "Identify tasks appropriate for AI automation",
      "Classify based on suitability"
    ],
    "evidence_quote": "they're going to learn more like how to audit their workflows. Basically going through and saying what, what are the tasks that I'm doing that would be appropriate for AI for augmentation or automation purposes?",
    "source_transcript": "transcripts_normalized/Kyra Atekwana's Zoom Meeting summary 2025-09-16 20_02 transcript.json",
    "source_date": "2025-09-16"
  },
  {
    "name": "AI Solution Selection Framework",
    "type": "decision_framework",
    "confidence": 0.88,
    "description": "A decision logic for determining which AI solution to use based on workflow scenario and requirements",
    "components": [
      "Evaluate if prompting is sufficient",
      "Assess if custom GPTs are needed",
      "Determine if agent building is appropriate",
      "Consider who will build and maintain the solution"
    ],
    "evidence_quote": "So it sounds to me like, so it starts to be like, what you should be teaching them is what to use in what scenario of these solutions... this is like prompting and JPTs or building an agent. If that is a solution that makes sense to you",
    "source_transcript": "transcripts_normalized/Kyra Atekwana's Zoom Meeting summary 2025-09-16 20_02 transcript.json",
    "source_date": "2025-09-16"
  },
  {
    "name": "Workshop Business Line Development",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "A step-by-step approach to evolving workshops from a service offering into a formal business line with explicit financial tracking",
    "components": [
      "Start with mixed services revenue (workshops embedded)",
      "Grow revenue from $1M to $2M",
      "Line item workshops separately in business plan",
      "Establish formal business line status"
    ],
    "evidence_quote": "we sold about a million dollars in workshops or we will, I think this year, maybe a little more. And so I'll be honest, there's no explicit right now workshops line item in the business. It's all services. And so it's all mixed together. I think a great outcome for you would be grow that million to 2 million next year or more. And frankly at that point we'd probably line item that out in the business plan.",
    "source_transcript": "transcripts_normalized/Workshops Lead Role - Initial Convo 2025-10-23 16_07 transcript.json",
    "source_date": "2025-10-23"
  },
  {
    "name": "Workshop Product Leadership Model",
    "type": "model_framework",
    "confidence": 0.89,
    "description": "A three-component model for leading workshops as a product and business line, evolving from pure content creation to full business ownership",
    "components": [
      "Content quality: High-quality workshop content development",
      "Revenue generation: Involvement in proposals and sales",
      "Cost management: Owning costs and margin analysis"
    ],
    "evidence_quote": "what comes with that is not just what you've been really good at, which is making high quality content, but it's being more involved on the revenue generation side, largely through the proposal review which you've started to do. And I want to kind of make that official. And there's definitely some things that could probably be improved there and then on the cost side, really owning the costs and thinking about the costs and thinking about the margins of the business.",
    "source_transcript": "transcripts_normalized/Workshops Lead Role - Initial Convo 2025-10-23 16_07 transcript.json",
    "source_date": "2025-10-23"
  },
  {
    "name": "Business Planning Resource Model",
    "type": "model_framework",
    "confidence": 0.87,
    "description": "A framework for building annual business plans that integrates resource allocation with project planning to meet business objectives",
    "components": [
      "Resource planning: How to allocate and think about resources",
      "Key projects identification: Mission-critical initiatives",
      "Business objectives alignment: Connecting projects to goals"
    ],
    "evidence_quote": "my expectation of you is that as you look to 2026, you basically build the plan that you need, aka like both the resource, how you're going to think about your resources and how you're going to think about kind of your like key projects to deliver on kind of the business objectives.",
    "source_transcript": "transcripts_normalized/Workshops Lead Role - Initial Convo 2025-10-23 16_07 transcript.json",
    "source_date": "2025-10-23"
  },
  {
    "name": "Content to Product Evolution Framework",
    "type": "scaling_framework",
    "confidence": 0.85,
    "description": "A framework for transitioning workshops from custom content to productized, scalable offerings",
    "components": [
      "Strong content foundation",
      "Product thinking: Standardization and reusability",
      "Business line development: Revenue and cost management",
      "Scale optimization: Making workshops repeatable"
    ],
    "evidence_quote": "I think that's a good opportunity for you as the workshops lead and especially as we start really pushing you to think of this as not just really strong content but a product and then a business line like doing these types of engagements.",
    "source_transcript": "transcripts_normalized/Workshops Lead Role - Initial Convo 2025-10-23 16_07 transcript.json",
    "source_date": "2025-10-23"
  },
  {
    "name": "Instructor Problem V1 Reset Process",
    "type": "process_framework",
    "confidence": 0.83,
    "description": "An iterative approach to solving persistent operational problems through version resets and continuous improvement",
    "components": [
      "Acknowledge persistent friction point",
      "Create V1 solution within defined timeframe",
      "Review sessions (1-2 iterations)",
      "Establish 'good enough' baseline",
      "Continue incremental improvements"
    ],
    "evidence_quote": "I think the biggest thing for me is the instructor piece. I think that that is, like, it just has always been a friction point. We've never solved it. We're not going to solve it overnight. But at the same time, I think we need kind of a reset a little bit like, of the V1, like you just did with the workshop content, kind of the same thing with the instructor piece. So I do think, you know, that's. That's just more short term. I would say, like, in the next, let's say by, you know, November 15th, we've hopefully had one or two sessions where we've looked at a V1 from you, and then. Then we've kind of said, okay, this is good enough for now, and then you'll keep continuing to improve it.",
    "source_transcript": "transcripts_normalized/Workshops Lead Role - Initial Convo 2025-10-23 16_07 transcript.json",
    "source_date": "2025-10-23"
  },
  {
    "name": "Measurement Framework for Workshops Business",
    "type": "measurement_framework",
    "confidence": 0.88,
    "description": "A dual-metric approach to tracking workshop business performance through revenue and cost dimensions",
    "components": [
      "Revenue tracking: Workshop sales and growth",
      "Cost analysis: Resource expenses and allocation",
      "Margin calculation: Profitability assessment",
      "Growth target: Year-over-year revenue increase (e.g., $1M to $2M)"
    ],
    "evidence_quote": "I pulled these numbers and this is a. And my expectation of you is that as you look to 2026, you basically build the plan that you need... I tried to give pull together for you where we're roughly at today both in terms of the revenue and then down in the resources available, you know, pulling in the costs.",
    "source_transcript": "transcripts_normalized/Workshops Lead Role - Initial Convo 2025-10-23 16_07 transcript.json",
    "source_date": "2025-10-23"
  },
  {
    "name": "Team Transition Stakeholder Process",
    "type": "engagement_framework",
    "confidence": 0.81,
    "description": "A collaborative process for transitioning team members between departments with multiple stakeholder review",
    "components": [
      "Review proposed job description",
      "Cross-check with current manager",
      "Account for unmet needs",
      "Set transition date",
      "Execute move"
    ],
    "evidence_quote": "So I think what you should do is let me look once more at your proposed JD that you sent for her. See if I have any. See anything. I might send it to Gloria. I gave Gloria a heads up that we're probably gonna move Mary over to you. I might send it to her just to do a gut check on her side of anything that's, like, kind of not accounted for. And then we can do that pretty fast. We can do that November 1st or something like that.",
    "source_transcript": "transcripts_normalized/Workshops Lead Role - Initial Convo 2025-10-23 16_07 transcript.json",
    "source_date": "2025-10-23"
  },
  {
    "name": "Pilot-to-Production Scaling Framework",
    "type": "scaling_framework",
    "confidence": 0.92,
    "description": "A two-phase approach to scaling AI enablement from pilot group to full organization",
    "components": [
      "Phase 1: Pilot with 150 salespeople",
      "Custom workshops",
      "Access to Prof. AI and AI Academy",
      "Proficiency benchmark",
      "Phase 2: Rollout to all 2,000 sales org employees"
    ],
    "evidence_quote": "Adobe did a pilot with 150 salespeople across their enterprise org and then included two custom workshops as well as, like, access to Prof. AI and AI Academy, along with the proficiency benchmark. So that's why phase one is a pilot. We're now talking about rolling this out to all of the sales org, which is about 2,000 employees.",
    "source_transcript": "transcripts_normalized/Kyra, Louise, Taylor _ re Adobe Proposal 2025-08-05 11_01 transcript.json",
    "source_date": "2025-08-05"
  },
  {
    "name": "Embedded Adoption Framework",
    "type": "engagement_framework",
    "confidence": 0.88,
    "description": "Strategy to drive adoption by embedding solutions into existing workflows rather than requiring separate time commitments",
    "components": [
      "Recognize time constraints (workshop dropout after 30 minutes)",
      "Make solutions embedded in the way people work",
      "Provide tangible and actionable solutions",
      "Account for user perception of busyness"
    ],
    "evidence_quote": "A big thing I'm thinking about is, like, how do we make this more embedded in the way people work and, like, put forward solutions here that are tangible and like, actionable, knowing that these people think that their lives are busier than anyone else.",
    "source_transcript": "transcripts_normalized/Kyra, Louise, Taylor _ re Adobe Proposal 2025-08-05 11_01 transcript.json",
    "source_date": "2025-08-05"
  },
  {
    "name": "Workflow Redesign Identification Framework",
    "type": "process_framework",
    "confidence": 0.85,
    "description": "Process for identifying and validating workflow redesign opportunities through stakeholder conversations",
    "components": [
      "Conduct stakeholder interviews focused on variety of workflows",
      "Identify candidate workflows (e.g., deal management)",
      "Validate workflow ideas through consolidation",
      "Map entire seller journey and identify pain points",
      "Prioritize workflows for implementation"
    ],
    "evidence_quote": "I think we tended, because I was trying to consolidate for the workshop. It's a lot of, you know, a couple of ideas and then you validate them... They had mapped out basically the entire seller journey and identified pain points along that... This could be an opportunity to just build on what they have identified. If they have needed some. Some prioritized workflows already and we could start from there.",
    "source_transcript": "transcripts_normalized/Kyra, Louise, Taylor _ re Adobe Proposal 2025-08-05 11_01 transcript.json",
    "source_date": "2025-08-05"
  },
  {
    "name": "Stakeholder Navigation Framework",
    "type": "engagement_framework",
    "confidence": 0.9,
    "description": "Approach to navigating organizational politics when assessment findings conflict with internal team perceptions",
    "components": [
      "Identify decision makers and sponsors (Amy, Don, CRO, CFO)",
      "Understand relationship dynamics (Amy and sales enablement team)",
      "Navigate 'don't call your baby ugly' situations",
      "Position recommendations appropriately",
      "Come in with strong point of view while being diplomatic"
    ],
    "evidence_quote": "There's even been comments, like, in the proficiency readout... people are saying there's no centralized repository. And Amy was like, yes, there is. Like, we've rolled it out, like, blah, blah, blah... So like, there's a little bit of this, like, we don't want to call your baby ugly situation. But like, also this is the reality. So that's a little bit like a path we have to walk.",
    "source_transcript": "transcripts_normalized/Kyra, Louise, Taylor _ re Adobe Proposal 2025-08-05 11_01 transcript.json",
    "source_date": "2025-08-05"
  },
  {
    "name": "Proposal Architecture Framework",
    "type": "model_framework",
    "confidence": 0.87,
    "description": "Two-part structure for presenting solution proposals that combines previously discussed elements with new assessment-based recommendations",
    "components": [
      "Top part: Natural phase two recommendations (previously discussed, e.g., 12 workshops series)",
      "Bottom part: Additional recommendations from proficiency assessment",
      "Integration of assessment findings with existing proposals"
    ],
    "evidence_quote": "The proposed solution. So top part is, what we'd already talked to her about is like, this would be the natural phase two. And then bottom part is coming out of their assessment what some of the additional recommendations were.",
    "source_transcript": "transcripts_normalized/Kyra, Louise, Taylor _ re Adobe Proposal 2025-08-05 11_01 transcript.json",
    "source_date": "2025-08-05"
  },
  {
    "name": "Reality Check Decision Framework",
    "type": "decision_framework",
    "confidence": 0.83,
    "description": "Logic for reassessing previously proposed solutions based on changed circumstances and pilot learnings",
    "components": [
      "Evaluate time elapsed since original proposal",
      "Assess if context has changed significantly",
      "Review pilot results and dropout patterns",
      "Determine if original approach needs modification"
    ],
    "evidence_quote": "When did he propose to her these? I want to say like two months ago... So I think having done the workshops, they would have a point of view on how to do these differently... we did the workshops, people dropped off after 30 minutes each time because they're so busy.",
    "source_transcript": "transcripts_normalized/Kyra, Louise, Taylor _ re Adobe Proposal 2025-08-05 11_01 transcript.json",
    "source_date": "2025-08-05"
  },
  {
    "name": "Tech Shots Training Evolution Framework",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "A phased approach to scaling AI training from basic tool introduction to advanced use cases, with iterative refinement based on feature changes and user maturity",
    "components": [
      "Phase 1: Introduction to Copilot in Edge (initial launch with Windows 11)",
      "Phase 2: Core session development with use cases",
      "Phase 3: Global scaling with multiple coaches and languages",
      "Phase 4: Version 2.0 for advanced users (post-basics)"
    ],
    "evidence_quote": "It's evolved a little bit from the start...we were predominantly just talking about Copilot and Edge at the time. Now we've moved over to, you know, Copilot chat...We're going to come back in September with kind of like a 2.0...We feel like people are getting the basics now and they really can move forward.",
    "source_transcript": "transcripts_normalized/Patrick Johnson and Kyra Atekwana 2025-07-22 12_02 transcript.json",
    "source_date": "2025-07-22"
  },
  {
    "name": "Six Use Case Demonstration Framework",
    "type": "engagement_framework",
    "confidence": 0.88,
    "description": "A scenario-based training approach using a cohesive narrative (new hire onboarding) to demonstrate six practical AI use cases in sequence",
    "components": [
      "Email composition for team communication",
      "Quiz/content generation for training materials",
      "Image creation for presentations",
      "Structured data retrieval (venue research with specific parameters)",
      "Interactive Q&A with participants",
      "Real-world business context demonstration"
    ],
    "evidence_quote": "we go through the six use cases...I become like a manager of a team. I have a bunch of new hires on my team and I'm inviting them to New York for like an onboarding. So I craft an email using the AI...I make like a quiz on our products...we would create like some images for the presentation...We find a bar to go to or to like host the event at by putting in some specific details",
    "source_transcript": "transcripts_normalized/Patrick Johnson and Kyra Atekwana 2025-07-22 12_02 transcript.json",
    "source_date": "2025-07-22"
  },
  {
    "name": "Multi-Coach Content Delivery Framework",
    "type": "scaling_framework",
    "confidence": 0.85,
    "description": "A scalable training delivery model that maintains content consistency while allowing coach customization for different audiences and languages",
    "components": [
      "Core content standardization across coaches",
      "Coach flexibility for examples and business cases",
      "Audience-specific customization option",
      "Multi-language delivery capability",
      "Global coach distribution"
    ],
    "evidence_quote": "It's myself, a few other coaches globally. We're now up to a few more languages...each coach has a little bit of a different way of bringing the content to life with their examples. So we tried to coach people on this is the content we want to get across, more or less use your own examples or your own business cases maybe that are unique to the audience you're going to speak to",
    "source_transcript": "transcripts_normalized/Patrick Johnson and Kyra Atekwana 2025-07-22 12_02 transcript.json",
    "source_date": "2025-07-22"
  },
  {
    "name": "Open Registration with Custom Sessions Framework",
    "type": "engagement_framework",
    "confidence": 0.83,
    "description": "A dual-track engagement model offering both open monthly sessions for general access and customized sessions for specific divisions or groups",
    "components": [
      "Monthly open sessions via IT calendar",
      "Self-service registration for any employee globally",
      "Custom sessions for divisions upon request",
      "Town hall integration opportunities",
      "Article-based promotion each month"
    ],
    "evidence_quote": "For the most part it's been open sessions. Definitely have done quite a few, like division or like different groups that have reached out...we have like an article we put out every month. Anyone from anywhere across the globe can register",
    "source_transcript": "transcripts_normalized/Patrick Johnson and Kyra Atekwana 2025-07-22 12_02 transcript.json",
    "source_date": "2025-07-22"
  },
  {
    "name": "Discovery Class Training Model",
    "type": "engagement_framework",
    "confidence": 0.8,
    "description": "A demonstrate-then-discuss training approach focused on showing capabilities through examples rather than hands-on exercises, with open Q&A for exploration",
    "components": [
      "Guided tool access demonstration",
      "Sequential use case walkthroughs",
      "Minimal participant hands-on activity",
      "Open microphone for suggestions during demos",
      "Q&A-driven interaction for specific questions"
    ],
    "evidence_quote": "it's not so much, at least the Gen AI one, it's been a lot more like just giving them the content as compared to some of the other tech shots. It's a lot more interactive...This one is kind of like in a discovery class...for the most part we're kind of guiding them and they're just asking us lots of questions",
    "source_transcript": "transcripts_normalized/Patrick Johnson and Kyra Atekwana 2025-07-22 12_02 transcript.json",
    "source_date": "2025-07-22"
  },
  {
    "name": "Tech Shots Product Launch Framework",
    "type": "process_framework",
    "confidence": 0.78,
    "description": "A repeatable format for introducing new tech solutions through quick, interactive coaching sessions that educate on underutilized or new capabilities",
    "components": [
      "Identify new tech solution or underutilized tool",
      "Create quick, interactive coaching session format",
      "Brand with engaging name (Tech Shots)",
      "Deploy as part of regular IT calendar offerings",
      "Scale with multiple coaches and languages"
    ],
    "evidence_quote": "we started this new thing called Tech Shots, trying to make like a play on a name and whether being a liquor company, like quick, interactive kind of coaching sessions to tell people about different solutions that we have that they may not be aware of or that they're not utilizing",
    "source_transcript": "transcripts_normalized/Patrick Johnson and Kyra Atekwana 2025-07-22 12_02 transcript.json",
    "source_date": "2025-07-22"
  },
  {
    "name": "AI Value Dichotomy Framework",
    "type": "decision_framework",
    "confidence": 0.85,
    "description": "A decision logic for determining AI effectiveness based on usage approach - proper use yields power, improper use yields uselessness",
    "components": [
      "Knowledge accessibility assessment",
      "Usage approach evaluation",
      "Binary outcome determination (powerful vs useless)"
    ],
    "evidence_quote": "look it's the sum of basically our knowledge is available to you and if you know how to use it it's incredibly powerful and if you're using it the wrong way it's incredibly useless",
    "source_transcript": "transcripts_normalized/transcript.json",
    "source_date": "unknown"
  },
  {
    "name": "Resource-Constrained AI Adoption Framework",
    "type": "process_framework",
    "confidence": 0.82,
    "description": "A necessity-driven approach to AI adoption for organizations with limited resources, focusing on bootstrapping and achieving high-impact results with minimal budget",
    "components": [
      "Identify resource constraints (lack of resources, need to bootstrap)",
      "Apply AI solutions to address gaps",
      "Achieve disproportionate impact (big brand energy on shoestring budget)"
    ],
    "evidence_quote": "my journey with AI has very much been out of necessity out of a lack of resources out of a need to bootstrap my way through how to have big brand Energy on a shoestring budget",
    "source_transcript": "transcripts_normalized/transcript.json",
    "source_date": "unknown"
  },
  {
    "name": "AI Business Application Framework",
    "type": "model_framework",
    "confidence": 0.88,
    "description": "A three-pillar model for applying AI in business contexts to enhance organizational capability",
    "components": [
      "Productivity enhancement",
      "Efficiency optimization",
      "Innovation enablement"
    ],
    "evidence_quote": "we find the ways for you to utilize artificial intelligence and help you on that Journey...whether that's productivity thinking about efficiency thinking about Innovation",
    "source_transcript": "transcripts_normalized/transcript.json",
    "source_date": "unknown"
  },
  {
    "name": "Ice House Impact Measurement Framework",
    "type": "measurement_framework",
    "confidence": 0.78,
    "description": "An organizational performance framework that measures success through economic impact generated by small enterprise support activities",
    "components": [
      "Small enterprise support delivery",
      "Economic impact tracking",
      "Success measurement through enterprise outcomes"
    ],
    "evidence_quote": "we're measured by the impact we had on the economy through the efforts of small Enterprises",
    "source_transcript": "transcripts_normalized/transcript.json",
    "source_date": "unknown"
  },
  {
    "name": "Dual-Path Onboarding Strategy",
    "type": "model_framework",
    "confidence": 0.88,
    "description": "A conceptual model offering users two integration options: native tool integration (browser extension within existing tools like PowerPoint/Google Slides) or standalone tool usage, with the ability to export results in compatible formats",
    "components": [
      "Native integration option (browser extension)",
      "Standalone tool option",
      "Export functionality for cross-platform compatibility",
      "Pre-onboarding requirements (enterprise security and compliance)"
    ],
    "evidence_quote": "We also talked about enterprise security and compliance. So those are things that kind of need to happen as preconditions even before folks can actually use it... So we have the option of either native integration. So wherever they're doing their work, being able to use it to there, or just having it be its own standalone tool.",
    "source_transcript": "transcripts_normalized/DeckSense Feature Discussion 2025-09-27 12_16 transcript.json",
    "source_date": "2025-09-27"
  },
  {
    "name": "HFM Integration Model",
    "type": "model_framework",
    "confidence": 0.82,
    "description": "A reference framework from HFM/OneStream software that provides both browser extension integration within Excel and standalone tool access to reduce friction and change user behavior",
    "components": [
      "Browser extension within existing tool (Excel)",
      "Standalone software access",
      "User choice between both options"
    ],
    "evidence_quote": "There's a browser extension you can have on your Excel... or you can just go into the actual one stream HFM tool and, you know, sort of like, use it... for this to be successful... you need to be able to do both.",
    "source_transcript": "transcripts_normalized/DeckSense Feature Discussion 2025-09-27 12_16 transcript.json",
    "source_date": "2025-09-27"
  },
  {
    "name": "Switching Cost Decision Framework",
    "type": "decision_framework",
    "confidence": 0.85,
    "description": "A decision logic comparing user attachment to tools based on power-user status: Excel users have higher switching costs due to deep expertise, while PowerPoint users have lower switching costs due to lower tool mastery, informing integration strategy",
    "components": [
      "Assess user expertise level with current tool",
      "Evaluate switching costs based on power-user status",
      "Determine integration necessity accordingly"
    ],
    "evidence_quote": "people who work in Excel are super users of Excel. The people who work in PowerPoint are not super users of PowerPoint... there's more switching costs from Excel to a different tool than there is from PowerPoint to a different tool.",
    "source_transcript": "transcripts_normalized/DeckSense Feature Discussion 2025-09-27 12_16 transcript.json",
    "source_date": "2025-09-27"
  },
  {
    "name": "Collaborative Card Sorting Process",
    "type": "process_framework",
    "confidence": 0.78,
    "description": "A workshop methodology for mapping customer journey stages where participants create cards for insights in real-time, then stack/prioritize cards by importance at each stage",
    "components": [
      "Click on any card to create new cards (plus sign)",
      "Create cards as insights emerge during discussion",
      "Stack cards around stages at end of exercise",
      "Identify what's most important in each stage"
    ],
    "evidence_quote": "When you click on any card, you can just. There's a plus sign come up, so you can just create another card. So as we're talking, feel free to create cards and maybe at the end of the exercise, we can stack around the cards so you can see what's more important in each stage.",
    "source_transcript": "transcripts_normalized/DeckSense Feature Discussion 2025-09-27 12_16 transcript.json",
    "source_date": "2025-09-27"
  },
  {
    "name": "Onboarding Preconditions Framework",
    "type": "process_framework",
    "confidence": 0.8,
    "description": "A sequential framework where enterprise security and compliance requirements must be satisfied as preconditions before users can access and use the tool",
    "components": [
      "Enterprise security implementation",
      "Compliance verification",
      "User access enablement",
      "Feature availability (native integration or standalone)"
    ],
    "evidence_quote": "We also talked about enterprise security and compliance. So those are things that kind of need to happen as preconditions even before folks can actually use it... In terms of the experience, they happen right at the beginning. So as they're onboarding these features supposedly already present.",
    "source_transcript": "transcripts_normalized/DeckSense Feature Discussion 2025-09-27 12_16 transcript.json",
    "source_date": "2025-09-27"
  },
  {
    "name": "AI Context Enrichment through Meeting Transcripts",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "A systematic approach to providing AI tools with rich context by recording meetings, transcribing them, and uploading transcripts to LLMs for enhanced output quality",
    "components": [
      "Record 100% of meetings using automated tools",
      "Sync recording tool with calendar for automatic joining",
      "Generate transcripts with speaker attribution",
      "Upload 2-3 relevant transcripts when doing AI-related work",
      "Enable memory/personalization settings in AI tool",
      "Provide specific instructions to ChatGPT about context"
    ],
    "evidence_quote": "So I use this assistant, which is too expensive. Don't use this one. But I'll show you another one that I think is pretty good. And so it comes to all my work meetings. Like it comes automatically. I sync it with my calendar and it joins the meeting and then, and then you have those transcripts. And the transcripts become extremely rich context for the LLM. So when I, anytime I'm doing anything work related, I'm uploading like two to three transcripts from the meetings I was in where these things were discussed.",
    "source_transcript": "transcripts_normalized/Fotemah 1_1 Session 2025-11-02 20_30 transcript (1).json",
    "source_date": "2025-11-02"
  },
  {
    "name": "ChatGPT Model Selection Framework",
    "type": "decision_framework",
    "confidence": 0.88,
    "description": "A decision logic for choosing between ChatGPT modes based on task complexity and need for depth versus speed",
    "components": [
      "Instant mode: For quick answers with immediate prediction",
      "Thinking mode: For research, analysis, and complex tasks requiring planning",
      "Thinking mode creates a plan before answering",
      "Instant mode predicts next answer without planning",
      "Trade-off: Speed vs. accuracy and depth"
    ],
    "evidence_quote": "What I would say is you basically have really fast, really slow. And in between is what these different models are and they relate to how much work it's doing to come up with a plan and a process. So if you're doing things like research or an analysis, like you want to have your thinking mode turned on because then it's going to create a plan and then work through that plan instead of just predicting the next answer, which is what it will do if you have it on instant.",
    "source_transcript": "transcripts_normalized/Fotemah 1_1 Session 2025-11-02 20_30 transcript (1).json",
    "source_date": "2025-11-02"
  },
  {
    "name": "Otter Transcription Tool Implementation",
    "type": "model_framework",
    "confidence": 0.85,
    "description": "A tiered model for implementing meeting transcription with free and paid options based on usage needs",
    "components": [
      "Free tier: 30-minute meetings, 300-600 minutes per month",
      "Paid tier ($20): 1200 minutes per month",
      "Features: Live transcription, speaker identification, meeting summaries, action items, searchable transcripts"
    ],
    "evidence_quote": "There's a free version that allows you to record 30 minute meetings and you can record I think 600 minutes a month or 300 minutes a month or something like that for free. The paid plan is like 20 bucks. And then you get 1200 meetings. Sorry, 1200 minutes per month.",
    "source_transcript": "transcripts_normalized/Fotemah 1_1 Session 2025-11-02 20_30 transcript (1).json",
    "source_date": "2025-11-02"
  },
  {
    "name": "Deep Research Agent Framework",
    "type": "process_framework",
    "confidence": 0.9,
    "description": "An agentic AI approach for conducting comprehensive research through iterative planning, clarification questions, and multi-source web searching",
    "components": [
      "User provides initial research topic/goal",
      "AI agent asks follow-up clarification questions",
      "User refines scope and focus areas",
      "Agent creates research plan",
      "Agent searches hundreds of websites (7-30 minutes)",
      "Agent synthesizes comprehensive report"
    ],
    "evidence_quote": "It's an AI agent because it's going out and it's executing on some goal that you give it as opposed to a prompt you're giving a specific task. It's not really thinking about it. In this case, it is actually going to make a plan based on what you shared with it. And so it's always going to ask you a couple of follow up questions to make sure that it deeply understands what it is that you're looking for so that it knows how to go and find that for you.",
    "source_transcript": "transcripts_normalized/Fotemah 1_1 Session 2025-11-02 20_30 transcript (1).json",
    "source_date": "2025-11-02"
  },
  {
    "name": "Context Maximization Principle",
    "type": "model_framework",
    "confidence": 0.87,
    "description": "A philosophical approach emphasizing maximum context provision to AI tools through memory settings and detailed information sharing",
    "components": [
      "Enable personalization settings in AI tool",
      "Turn on memory features",
      "Provide domain-specific context about work",
      "Allow AI to remember user preferences and context",
      "Rich context leads to more relevant responses"
    ],
    "evidence_quote": "Like my personal opinion, like, the more context you give these things, especially because they have memory, the better. Because if you go into your personalization settings... You can give ChatGPT specific instructions and you can also have it remember things about you... It'll understand all of your context and like, oh yeah, you know, you're working on God engineering. So I'm going to give you responses that relate to like clothing or whatever it might be.",
    "source_transcript": "transcripts_normalized/Fotemah 1_1 Session 2025-11-02 20_30 transcript (1).json",
    "source_date": "2025-11-02"
  },
  {
    "name": "MARTECH Baseline Knowledge Elevation",
    "type": "engagement_framework",
    "confidence": 0.88,
    "description": "A framework for elevating organizational knowledge about MARTECH across client-facing teams through structured expert interviews and workshop development",
    "components": [
      "Expert source identification (client architects, new business team, technical specialists)",
      "Structured interview sessions with different stakeholder groups",
      "Content synthesis for workshop creation",
      "Baseline knowledge elevation across organization",
      "Reduction of dependency on specialists for client conversations"
    ],
    "evidence_quote": "the goal is to really elevate the baseline knowledge across Horizon teams, especially teams that are operating in a client facing capacity. We're not under the illusion that people are going to become MARTECH experts overnight... But the goal again is to just raise the baseline knowledge across the organization so people aren't so dependent on your team or on specialists to have client conversations.",
    "source_transcript": "transcripts_normalized/[CLIENT ARCHITECTS] Martech 101 Discovery Session with Section  2025-06-23 11_30 transcript.json",
    "source_date": "2025-06-23"
  },
  {
    "name": "Multi-Stakeholder Interview Sequence",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "A phased interview approach to gather comprehensive MARTECH knowledge from different organizational perspectives",
    "components": [
      "Week 1: New business team perspective (Julia and Caroline)",
      "Week 2: Client architects perspective (Brina and Megan)",
      "Week 2: Technical/partnerships perspective (John, Krish, Rich)"
    ],
    "evidence_quote": "just for your context as well, we had Julia and Caroline last week. We'll have this conversation now. And then this afternoon we actually have John, Krish and Rich in a conversation just pertaining to some of the partnerships world, but also some of the more technical topics as well.",
    "source_transcript": "transcripts_normalized/[CLIENT ARCHITECTS] Martech 101 Discovery Session with Section  2025-06-23 11_30 transcript.json",
    "source_date": "2025-06-23"
  },
  {
    "name": "Client Architects Team Evolution Model",
    "type": "model_framework",
    "confidence": 0.85,
    "description": "A strategic shift from day-to-day technical experts to a center of excellence model for tools and integrations",
    "components": [
      "Current state: Day-to-day experts on Blue and data",
      "Future state: Center of excellence for tools comparison (e.g., Adobe vs Experian)",
      "Specialization in integrations and custom integration needs",
      "Client teams become generalists",
      "Architects become tools and tech experts"
    ],
    "evidence_quote": "Our team kind of sits right now is the day to day experts on everything blue and data. But we are moving to be more of a coefficient for anything that is in this conversation particular. So we'll be the experts when it comes like Adobe versus Excel. Experian and our integrations and if someone needs a custom integration, but more of that like tools and tech expert where the day to day clients will be more of I guess like generalists",
    "source_transcript": "transcripts_normalized/[CLIENT ARCHITECTS] Martech 101 Discovery Session with Section  2025-06-23 11_30 transcript.json",
    "source_date": "2025-06-23"
  },
  {
    "name": "Project Management Tool Consolidation Framework",
    "type": "process_framework",
    "confidence": 0.85,
    "description": "A methodology for consolidating meeting outputs and action items through a centralized dashboard that organizes by projects and enables chat functionality across all project transcripts",
    "components": [
      "Consolidate all action items from every meeting in single dashboard",
      "Create projects with transcripts",
      "Chat with all projects",
      "Move meetings into relevant projects",
      "View all action items at a glance per project"
    ],
    "evidence_quote": "it consolidates all of your action items from every meeting within a single dashboard. And then you can also create projects with your transcripts and then chat with all of those projects... I have a running project for all of my one on ones running product for Shan. And you can just move all of your meetings in there and then you can see all your action items at a glance",
    "source_transcript": "transcripts_normalized/Asurion Standup 2025-09-08 13_04 transcript.json",
    "source_date": "2025-09-08"
  },
  {
    "name": "Launch Dependency Framework",
    "type": "process_framework",
    "confidence": 0.9,
    "description": "A sequential process for managing product launch dependencies with clear gates and approvals needed before launch execution",
    "components": [
      "Confirm communication timing and content from stakeholders",
      "Get technical testing validation from assigned users",
      "Determine UI banner/linking requirements",
      "Resource internal team appropriately with calendar holds",
      "Execute launch at confirmed time"
    ],
    "evidence_quote": "I still haven't heard back from Abigail. Not Abigail, Abby. For when the comms are going out, what the comms are, what's in them. And I'm still waiting for Sam to test out that the AI policy works on his end and waiting to hear back from Jackie on if like they want to add that other banner... So still waiting on quite a few things in order to launch on Wednesday",
    "source_transcript": "transcripts_normalized/Asurion Standup 2025-09-08 13_04 transcript.json",
    "source_date": "2025-09-08"
  },
  {
    "name": "Meeting Agenda Prioritization Framework",
    "type": "decision_framework",
    "confidence": 0.88,
    "description": "A framework for sequencing meeting topics based on urgency and dependency, with time-sensitive launch items taking priority over strategic planning work",
    "components": [
      "Identify time-sensitive action items with external dependencies",
      "Schedule these as first agenda items",
      "Follow with strategic/planning items that can be discussed after urgent items",
      "Confirm agenda sequence with all participants"
    ],
    "evidence_quote": "So we want to do for sure. I think first should be Chloe's action items around the launch. And then Louise, do we want to do our next iteration of the product? Proposal in the for the rest of the meeting tomorrow",
    "source_transcript": "transcripts_normalized/Asurion Standup 2025-09-08 13_04 transcript.json",
    "source_date": "2025-09-08"
  },
  {
    "name": "Functional Enablement Model",
    "type": "model_framework",
    "confidence": 0.92,
    "description": "A three-component organizational model for enabling functions after completing initial phase, structured around roadmap development, service delivery, and training",
    "components": [
      "AI roadmap development",
      "Workflow as a service",
      "Role-based training"
    ],
    "evidence_quote": "Essentially I just simplified it all to be like we did phase one and as a result of that Assurian central AI team is going forward in the organization wide initiatives now where we need to focus is enabling the function. So everything is under that umbrella title of functional enablement. And so for that functional enablement we have three things... one is the AI roadmap... The second is workflow as a service and then the third I currently have called role based training",
    "source_transcript": "transcripts_normalized/Asurion Standup 2025-09-08 13_04 transcript.json",
    "source_date": "2025-09-08"
  },
  {
    "name": "Launch Readiness Decision Framework",
    "type": "decision_framework",
    "confidence": 0.87,
    "description": "A conditional decision logic for determining if a launch can proceed based on stakeholder confirmations and technical feasibility",
    "components": [
      "If banner implementation is approved and feasible, proceed with quick implementation",
      "If banner cannot be added to courses dashboard, determine alternative approach",
      "If all confirmations received by previous day, internal team has sufficient time to execute",
      "If not all confirmations received, assess risk and delay if necessary"
    ],
    "evidence_quote": "I think it's doable to do it. If they agree that doing that banner is fine, then that's no big deal for our team to implement that quickly. But if that doesn't work for them, because we can't add it to the courses dashboard because that's where they wanted it to be, and we can't do that",
    "source_transcript": "transcripts_normalized/Asurion Standup 2025-09-08 13_04 transcript.json",
    "source_date": "2025-09-08"
  },
  {
    "name": "Phased Implementation Scaling Framework",
    "type": "scaling_framework",
    "confidence": 0.85,
    "description": "A two-phase approach moving from organization-wide initiatives to function-specific enablement",
    "components": [
      "Phase 1: Organization-wide AI initiatives through central team",
      "Phase 2: Functional enablement with targeted roadmaps, services, and training"
    ],
    "evidence_quote": "we did phase one and as a result of that Assurian central AI team is going forward in the organization wide initiatives now where we need to focus is enabling the function",
    "source_transcript": "transcripts_normalized/Asurion Standup 2025-09-08 13_04 transcript.json",
    "source_date": "2025-09-08"
  },
  {
    "name": "AI Use Case Identification Workshop Framework",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "A structured methodology for helping teams identify and implement AI use cases within their existing workflows through workshop-based exercises",
    "components": [
      "Workshop presentation on finding AI use cases (approximately 60 minutes)",
      "Team breakout sessions organized by function/workflow",
      "Workflow audit mapping (pre-workshop preparation)",
      "Guided exercise to identify automation opportunities within mapped processes",
      "Moderator-facilitated discussions per team",
      "Output generation: prompt use cases by team"
    ],
    "evidence_quote": "The first hour or so is going to be about finding your AI use case. So it's kind of the same concept deck that we've done for others around finding your AI use case...then there's going to be breakouts where the purpose of the breakouts is for them to basically identify like their own use cases...they want people to think about the different steps in each of these different processes and think about where AI can automate some of these steps.",
    "source_transcript": "transcripts_normalized/Sync on Doordash presentation 2025-09-09 14_01 transcript.json",
    "source_date": "2025-09-09"
  },
  {
    "name": "Workflow-Based AI Implementation Model",
    "type": "model_framework",
    "confidence": 0.88,
    "description": "A conceptual model for AI adoption that maps existing workflow processes and identifies automation opportunities at specific steps within those workflows",
    "components": [
      "Ecosystem mapping of all work streams",
      "Process step documentation by team",
      "AI automation opportunity identification at step level",
      "Team-specific workflow guidance",
      "Function-based use case clustering"
    ],
    "evidence_quote": "They've been going through the process of mapping out their ecosystem and like all of the different work streams that folks have...they want people to think about the different steps in each of these different processes and think about where AI can automate some of these steps...the people would get broken out by team. They'll have this guidance in terms of the workflows that have already been audited.",
    "source_transcript": "transcripts_normalized/Sync on Doordash presentation 2025-09-09 14_01 transcript.json",
    "source_date": "2025-09-09"
  },
  {
    "name": "Workshop Content Structure Framework",
    "type": "process_framework",
    "confidence": 0.85,
    "description": "A 50-50 split structure for AI enablement workshops balancing instructional content with hands-on application",
    "components": [
      "First half: Educational content on AI use case identification (50% of 120 minutes)",
      "Second half: Interactive breakout exercises with facilitation (50% of 120 minutes)",
      "Pre-identified workflow guidance materials",
      "Moderator support structure for breakouts",
      "Expected outputs defined upfront"
    ],
    "evidence_quote": "The content is 50 50, it's 120 minutes. The first hour or so is going to be about finding your AI use case...and then there's going to be breakouts where the purpose of the breakouts is for them to basically identify like their own use cases...the expected output we talked about was prompt use cases by team.",
    "source_transcript": "transcripts_normalized/Sync on Doordash presentation 2025-09-09 14_01 transcript.json",
    "source_date": "2025-09-09"
  },
  {
    "name": "Workshop Delivery Engagement Framework",
    "type": "engagement_framework",
    "confidence": 0.83,
    "description": "A structured approach to stakeholder coordination and preparation for workshop delivery including speaker, client team, and facilitators",
    "components": [
      "Client stakeholder introduction and alignment session",
      "Content requirements gathering from client",
      "Speaker logistics coordination (travel, scheduling)",
      "Facilitator/moderator briefing and guidance",
      "Team-specific breakout structure definition",
      "Pre-workshop context sharing (recordings, documents)"
    ],
    "evidence_quote": "I'd like to introduce you guys to Hannah, who's the VP of AI, the head of AI for marketing at Doordash this week, if possible. Just to orient on, like, here's the process, here's what we're going to do, here's what we need from you...on their side they're going to have people who are helping to moderate the different breakouts. So just something worth noting, we'll probably need to give Tani some guidance and then we'll need to work with them on like, okay, what is the structure for that and how do you, what are we asking for people to do and how did the moderators help?",
    "source_transcript": "transcripts_normalized/Sync on Doordash presentation 2025-09-09 14_01 transcript.json",
    "source_date": "2025-09-09"
  },
  {
    "name": "AI Use Case Evaluation and Prioritization Framework",
    "type": "process_framework",
    "confidence": 0.98,
    "description": "A structured three-phase approach to identify, evaluate, and pilot AI solutions in marketing, moving from discovery to implementation",
    "components": [
      "Phase 1: Use Case Collection (45 min) - Review existing AI solutions, capture new use cases from Master Marketing AI Excel sheet, and identify gaps",
      "Phase 2: Evaluation Process - Score use cases on two metrics: ability to enhance quality of output and ability to improve efficiency (high/medium/low)",
      "Phase 3: Prioritization and Selection - Create prioritized list and select top 3-5 use cases for piloting",
      "Phase 4: Tool Identification - Identify suitable AI tools or engage with vendors/internal teams",
      "Phase 5: Pilot Structure - Design testing session with clear defined KPIs before broader rollout"
    ],
    "evidence_quote": "We're going to start off the first roughly 45 minutes reviewing and making sure we have a clear understanding of all the use cases for AI and marketing... After we're done kind of making sure we have the right list, we're going to start the evaluation process... The goal at the end is to have a prioritized list of use cases based on their greatest potential for AI enablement... After we're done with this session, we are then going to start identifying what would be a suitable AI tool... Then we're going to think about how to structure a pilot or a testing session",
    "source_transcript": "transcripts_normalized/FW_ Marketing AI Discovery and Prioritization Session 2025-07-29 10_00 transcript.json",
    "source_date": "2025-07-29"
  },
  {
    "name": "Dual-Metric AI Use Case Evaluation Model",
    "type": "measurement_framework",
    "confidence": 0.95,
    "description": "A two-dimensional evaluation system for assessing AI use cases based on quality enhancement and efficiency improvement",
    "components": [
      "Metric 1: Tool's ability to enhance quality of output (High/Medium/Low)",
      "Metric 2: Tool's ability to improve efficiency (High/Medium/Low)",
      "Overall score combining both dimensions",
      "Ranking to determine greatest potential for AI enablement"
    ],
    "evidence_quote": "And there's two main metrics we're going to look at. Once is the tool's ability or the use cases, ability to enhance quality of output and the tool's ability to improve efficiency. So we're going to tick through each of the main use case buckets, categorize each of them into high, medium, low, so pretty high level. And then we're going to have an overall score for each of the use cases.",
    "source_transcript": "transcripts_normalized/FW_ Marketing AI Discovery and Prioritization Session 2025-07-29 10_00 transcript.json",
    "source_date": "2025-07-29"
  },
  {
    "name": "Enterprise AI Transformation Engagement Model",
    "type": "engagement_framework",
    "confidence": 0.92,
    "description": "A facilitation-based model defining the role of the Enterprise AI Transformation team as enablers rather than gatekeepers for function-specific AI deployment",
    "components": [
      "Function autonomy: Business units have decision-making authority for AI tool deployment",
      "Facilitation role: Transformation team helps enable deployment, not approve/disapprove",
      "Streamlined approval: Help navigate information security and approval processes",
      "Impact tracking: Monitor and report success stories to executive leadership and board",
      "Information security compliance: Ensure tools meet security requirements"
    ],
    "evidence_quote": "I think there's always a question of, well, how much do we internally do within the marketing team versus how much do you guys do as part of the Enterprise AI Transformation team and the goal is that this, our Enterprise AI Transformation team, helps facilitate deployment of AI tools within marketing. We're not intended to be a gatekeeper or an approval entity that says yes or no to tools like you guys have autonomy... our role as part of the Transformation team is to help enable that",
    "source_transcript": "transcripts_normalized/FW_ Marketing AI Discovery and Prioritization Session 2025-07-29 10_00 transcript.json",
    "source_date": "2025-07-29"
  },
  {
    "name": "AI Pilot-to-Production Scaling Framework",
    "type": "scaling_framework",
    "confidence": 0.88,
    "description": "A gated approach to scaling AI solutions from pilot testing to organization-wide deployment based on defined KPI performance",
    "components": [
      "Pilot/Testing Phase: Structured testing session with selected use case",
      "KPI Definition: Establish clear defined set of KPIs before pilot begins",
      "Performance Measurement: Measure actual performance against KPIs during pilot",
      "Rollout Decision: Determine if and how to roll out to broader organization based on results"
    ],
    "evidence_quote": "Then we're going to think about how to structure a pilot or a testing session to see what the AI tool can actually perform. And we'll make sure to have a clear defined set of KPIs that we measure before we roll out to the broader organization. If that's where we land",
    "source_transcript": "transcripts_normalized/FW_ Marketing AI Discovery and Prioritization Session 2025-07-29 10_00 transcript.json",
    "source_date": "2025-07-29"
  },
  {
    "name": "AI Tool Sourcing Decision Framework",
    "type": "decision_framework",
    "confidence": 0.85,
    "description": "A logic-based approach for determining whether to engage with external vendors or internal teams for AI tool implementation",
    "components": [
      "If tool already identified: Begin vendor/internal team engagement",
      "If external tool: Talk to vendor, assess feasibility and expectations",
      "If internal capability: Engage with internal teams, validate feasibility",
      "Feasibility assessment: Determine if solution will meet expectations"
    ],
    "evidence_quote": "After we're done with this session, we are then going to start identifying what would be a suitable AI tool. If we've already identified an AI tool, we can then start talking to the vendor. If it's internal, start talking to the right teams, seeing if this is even feasible and if it will meet to the expectations that we have.",
    "source_transcript": "transcripts_normalized/FW_ Marketing AI Discovery and Prioritization Session 2025-07-29 10_00 transcript.json",
    "source_date": "2025-07-29"
  },
  {
    "name": "Amazon-Style Document Review Process",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "A meeting methodology where participants silently read a pre-prepared document for a set time period before discussion begins, rather than presenting slides",
    "components": [
      "Distribute document link to all participants",
      "Set specific time limit for silent reading (5 minutes)",
      "Stop screen sharing during reading period",
      "Resume discussion after time expires"
    ],
    "evidence_quote": "this is what I want to do actually is we're going to go Amazon style and I'm going to put this link in the chat...Take five minutes. We'll come back at 1:11, 1:11 for me and then discuss. And I'm going to stop sharing my screen while we all do that.",
    "source_transcript": "transcripts_normalized/Company Lunch & Learn 2025-10-24 13_01 transcript.json",
    "source_date": "2025-10-24"
  },
  {
    "name": "Use Case Desert Model",
    "type": "model_framework",
    "confidence": 0.88,
    "description": "A conceptual model describing the gap between basic AI awareness/proficiency and actual implementation of advanced use cases in organizations",
    "components": [
      "High AI proficiency scores (85%+)",
      "Low actual use case implementation (<50%)",
      "Predominance of beginner use cases (90%)",
      "Self-perception vs. reality gap"
    ],
    "evidence_quote": "I feel like I'm seeing more and more companies where we're doing their AI maturity report and like people know how to use AI. Like they know the basics of it. They'll score like 85% proficiency. And then when I go into the data, like less than half of them actually have a use case. And then those that do, it's like 90% beginner use cases.",
    "source_transcript": "transcripts_normalized/Company Lunch & Learn 2025-10-24 13_01 transcript.json",
    "source_date": "2025-10-24"
  },
  {
    "name": "Presentation Agenda Framework",
    "type": "process_framework",
    "confidence": 0.85,
    "description": "A structured approach to presenting product features and strategy with progressive depth",
    "components": [
      "Problem definition",
      "Product demo",
      "Anticipated FAQs",
      "Roadmap and timeline",
      "Follow-up discussion at offsite for macro vision"
    ],
    "evidence_quote": "So I'm going to talk a little bit about the problem we're going to solve. Then I'm going to show you the demo...I've got some answers to what I think are likely going to be the FAQs and then some upcoming roadmap and release timeline stuff...And then we'll talk about this again probably at the off site.",
    "source_transcript": "transcripts_normalized/Company Lunch & Learn 2025-10-24 13_01 transcript.json",
    "source_date": "2025-10-24"
  },
  {
    "name": "Self-Fulfilling Expertise Illusion Cycle",
    "type": "model_framework",
    "confidence": 0.8,
    "description": "A cyclical model explaining how organizations become trapped in basic AI usage due to overestimating their capabilities",
    "components": [
      "Self-assessment of expertise",
      "Perception of having great use cases",
      "Reality of basic implementation only",
      "Barrier to learning due to false confidence",
      "Perpetuation of basic usage"
    ],
    "evidence_quote": "there's a sort of like cycle that's self fulfilling of like I tell myself that I'm an expert here and I have a bunch of great use cases, but in reality I don't. And so that it sort of creates like a black hole effect of like never going to learn anything if you keep telling yourself that you're amazing.",
    "source_transcript": "transcripts_normalized/Company Lunch & Learn 2025-10-24 13_01 transcript.json",
    "source_date": "2025-10-24"
  },
  {
    "name": "Policy-Capability Gap Measurement",
    "type": "measurement_framework",
    "confidence": 0.75,
    "description": "A framework for assessing organizational AI readiness by measuring the gap between user readiness and policy constraints",
    "components": [
      "Team readiness level",
      "Policy restrictions (data upload, sharing constraints)",
      "Available use cases given constraints",
      "Gap between desired and permitted usage"
    ],
    "evidence_quote": "you also have teams that they feel very ready and they seem like they're kind of really eager to use it in a more advanced way, but then they are stuck by the policies and not able to do it...they're not allowed to upload things or they're not allowed to share certain data, and they're like, well, then what do I do with it, other than summarize emails?",
    "source_transcript": "transcripts_normalized/Company Lunch & Learn 2025-10-24 13_01 transcript.json",
    "source_date": "2025-10-24"
  },
  {
    "name": "Find Your Use Case Framework",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "A three-step methodology for identifying AI applications in work contexts by understanding AI capabilities, analyzing current work tasks, and mapping capabilities to work needs",
    "components": [
      "What are AI's capabilities?",
      "What are you doing at work?",
      "How can you apply AI's capabilities to your work?"
    ],
    "evidence_quote": "What are AI's capabilities? Because I think that a lot of people just don't understand that you understand what it can do and therefore don't know that it can do what they need. And think about what are you doing at work? And then think about how can you apply AI's capabilities to your work?",
    "source_transcript": "transcripts_normalized/Tom _ Kyra_ Working Session 2025-11-06 16_31 transcript.json",
    "source_date": "2025-11-06"
  },
  {
    "name": "Meta Prompting Practice Framework",
    "type": "process_framework",
    "confidence": 0.88,
    "description": "A structured approach to developing effective prompts by having AI ask clarifying questions before generating the final prompt",
    "components": [
      "Present the use case framework",
      "AI asks clarifying questions about the use case",
      "AI generates a customized prompt",
      "User edits and refines the prompt",
      "User considers what materials to upload/attach"
    ],
    "evidence_quote": "I think it should be basically just like, here's the framework. Ask me a couple of questions, make me a prompt is like, what that activity is, and then they can obviously edit the prompt as they see fit and think about, like, oh, what would you attach? Like, what would you upload to support this use case?",
    "source_transcript": "transcripts_normalized/Tom _ Kyra_ Working Session 2025-11-06 16_31 transcript.json",
    "source_date": "2025-11-06"
  },
  {
    "name": "Five Personas Model",
    "type": "model_framework",
    "confidence": 0.75,
    "description": "A categorization system for AI use cases, tentatively containing five mutually exclusive persona types (with consideration to reduce to four by removing 'transformer')",
    "components": [
      "Persona 1 (unspecified)",
      "Persona 2 (unspecified)",
      "Persona 3 (unspecified)",
      "Persona 4 (unspecified)",
      "The Transformer (under review for removal)"
    ],
    "evidence_quote": "So where we have the. Now the tentatively five Personas... I'm still like, oh, I would like to get feedback tomorrow on whether we should basically do four and cut what's right now the transformer.",
    "source_transcript": "transcripts_normalized/Tom _ Kyra_ Working Session 2025-11-06 16_31 transcript.json",
    "source_date": "2025-11-06"
  },
  {
    "name": "Crash Course Delivery Framework",
    "type": "engagement_framework",
    "confidence": 0.85,
    "description": "An approach to teaching AI tools through clear explanation and demonstration regardless of complexity, focusing on showcasing new ways to use AI",
    "components": [
      "Talk through demos clearly",
      "Explain what's happening at each step",
      "Focus on delivery and cadence",
      "Showcase ways to use AI people haven't thought about before",
      "Position tools as solving new use cases or overcoming previous frustrations"
    ],
    "evidence_quote": "I think it's all about, like, delivery and cadence there. Because, like, regardless of what demo you do, if you talk through it and explain what's happening, clearly, people will be like, great... I think the goal of the Crash Course is to showcase to people ways to use AI in which they haven't thought about before.",
    "source_transcript": "transcripts_normalized/Tom _ Kyra_ Working Session 2025-11-06 16_31 transcript.json",
    "source_date": "2025-11-06"
  },
  {
    "name": "AI Use Case Evaluation Framework",
    "type": "process_framework",
    "confidence": 0.98,
    "description": "Three-step structured approach to evaluating and prioritizing AI use cases in finance",
    "components": [
      "Alignment on potential AI use cases (existing pilots, tools at scale, new ideas)",
      "Evaluation and ranking (quality enhancement vs efficiency improvement, high/medium/low impact)",
      "Prioritization of top 3-5 use cases for pilot/testing"
    ],
    "evidence_quote": "So there's three main objectives. The first is to make sure we're aligned on all the potential use cases in AI for finance... Then we're going to start the evaluation... And then the last part is prioritize, which are the top three, maybe five use cases where we want to go and pilot or test an AI tool.",
    "source_transcript": "transcripts_normalized/FW_ Finance AI Discovery and Prioritization Session 2025-08-13 11_30 transcript.json",
    "source_date": "2025-08-13"
  },
  {
    "name": "AI Impact Assessment Matrix",
    "type": "measurement_framework",
    "confidence": 0.92,
    "description": "Dual-axis evaluation system for ranking AI use cases based on quality and efficiency dimensions",
    "components": [
      "Quality enhancement (doing things better)",
      "Efficiency improvement (doing things quicker)",
      "Ranking system (high, medium, low impact)",
      "Adoption roadblock identification"
    ],
    "evidence_quote": "Our goal is to identify which are the like where do each of the use cases rank in terms of high, medium and low when it comes to their ability to enhance quality or improve efficiency. So doing things quicker or doing things better.",
    "source_transcript": "transcripts_normalized/FW_ Finance AI Discovery and Prioritization Session 2025-08-13 11_30 transcript.json",
    "source_date": "2025-08-13"
  },
  {
    "name": "Pilot-to-Production Scaling Framework",
    "type": "scaling_framework",
    "confidence": 0.88,
    "description": "Differentiated approach to scaling AI solutions based on complexity and scope",
    "components": [
      "Full vendor pilot (for complex solutions like OneStream/Palantir)",
      "Fast testing with KPIs (for smaller scale tools)",
      "Tool research and suitability alignment",
      "Pilot design with clear metrics"
    ],
    "evidence_quote": "some, some projects might need a proper pilot with a vendor, as is the case with One Stream and Palantir, but other ones can just be like a faster testing process with key KPIs and we can see how the tools work at a smaller scale.",
    "source_transcript": "transcripts_normalized/FW_ Finance AI Discovery and Prioritization Session 2025-08-13 11_30 transcript.json",
    "source_date": "2025-08-13"
  },
  {
    "name": "Finance Organization Mapping Framework",
    "type": "model_framework",
    "confidence": 0.85,
    "description": "Comprehensive organizational structure breakdown for ensuring complete use case coverage across finance functions",
    "components": [
      "Global Strategic Finance",
      "Client Strategic Finance",
      "Operations Finance Transformation and Global Systems",
      "Corporate Strategic Finance",
      "Treasury Operations and Risk Management",
      "Accounting (including external reporting)",
      "FP&A"
    ],
    "evidence_quote": "So we have Global Strategic Finance, Client Strategic Finance, Operations Finance Transformation and Global Systems, Corporate Strategic Finance, Treasury Operations and Risk Management, Accounting, and then the home FP&A.",
    "source_transcript": "transcripts_normalized/FW_ Finance AI Discovery and Prioritization Session 2025-08-13 11_30 transcript.json",
    "source_date": "2025-08-13"
  },
  {
    "name": "Executive Stakeholder Engagement Framework",
    "type": "engagement_framework",
    "confidence": 0.9,
    "description": "Tiered stakeholder engagement model defining roles and reporting cadences for AI initiatives",
    "components": [
      "Executive sponsor (Baga) - regular updates on enterprise AI progress",
      "Technical partner (Parta) - engagement when internal tools need building",
      "Board-level reporting - high-impact use cases with potential impact metrics"
    ],
    "evidence_quote": "David Baga is the key, like executive sponsor and Parda is. If we want to build any internal tools then like we'll need to work with a tech team... Baga, in terms of updates, like regular updates on how this enterprise AI work is going and then Parto would just be when there's a need to build a tool.",
    "source_transcript": "transcripts_normalized/FW_ Finance AI Discovery and Prioritization Session 2025-08-13 11_30 transcript.json",
    "source_date": "2025-08-13"
  },
  {
    "name": "AI Pilot Validation Framework",
    "type": "measurement_framework",
    "confidence": 0.87,
    "description": "Back-testing methodology for validating AI forecasting accuracy before production deployment",
    "components": [
      "Tool and UI build completion",
      "Back-testing against actual operating plan (AOP)",
      "Forecast accuracy evaluation for unit actuals",
      "Regression analysis on machine learning approaches"
    ],
    "evidence_quote": "we're currently back testing. Right now. So we've got the tool build, we've got the UI build, we're back testing versus our AOP to see kind of forecast accuracy for unit actuals. And then we're also going to start thinking through some of the kind of the regression analysis approaches on the machine learning",
    "source_transcript": "transcripts_normalized/FW_ Finance AI Discovery and Prioritization Session 2025-08-13 11_30 transcript.json",
    "source_date": "2025-08-13"
  },
  {
    "name": "First Call Sales Qualification Framework",
    "type": "process_framework",
    "confidence": 0.98,
    "description": "A structured approach for conducting initial sales calls that focuses on qualifying prospects rather than just pitching, using a multi-stage conversation flow",
    "components": [
      "Set agenda with respect contract",
      "Understand prospect's current state and priorities",
      "Share approach to building AI powered orgs",
      "Determine next steps or mutual exit"
    ],
    "evidence_quote": "We set an agenda and we talk about, hey, we want to understand your priorities and then share our approach to building AI powered orgs. So we go through and we understand what's their current state, what's our approach to driving AI powered workforces, and then next steps.",
    "source_transcript": "transcripts_normalized/Company Lunch & Learn 2025-09-12 13_04 transcript (1).json",
    "source_date": "2025-09-12"
  },
  {
    "name": "Qualify Out Framework",
    "type": "decision_framework",
    "confidence": 0.95,
    "description": "A decision-making approach to determine early whether prospects should be disqualified from the sales pipeline based on their commitment to change management",
    "components": [
      "Assess seriousness about change management approach to AI",
      "Distinguish between casual interest vs. serious deployment intent",
      "Provide early exit opportunity (respect contract)",
      "Focus time on high-probability prospects"
    ],
    "evidence_quote": "This deck is intended to qualify out. Understand who is not interested in and you'll notice in bold, a serious change management approach to AI deployment. We're not really interested in wiki load as people that are just kind of like interested in AI for the sake of AI.",
    "source_transcript": "transcripts_normalized/Company Lunch & Learn 2025-09-12 13_04 transcript (1).json",
    "source_date": "2025-09-12"
  },
  {
    "name": "Respect Contract Engagement Framework",
    "type": "engagement_framework",
    "confidence": 0.92,
    "description": "A transparent engagement approach that gives prospects permission to exit early if there's not a fit, preventing wasted time for both parties",
    "components": [
      "Set clear expectations upfront",
      "Discuss objectives and share approach",
      "Offer explicit out if not a fit",
      "Prefer early no over prolonged uncertainty"
    ],
    "evidence_quote": "We say, hey, we're going to talk a little bit about your objectives. We're going to share our approach. If it's a fit, let's schedule more time and. Continue the discussion. If it's not, that's okay, you can tell us, right? Because the last thing we want to be as salespeople is like strung along with people that aren't that are, that are too nice to say no.",
    "source_transcript": "transcripts_normalized/Company Lunch & Learn 2025-09-12 13_04 transcript (1).json",
    "source_date": "2025-09-12"
  },
  {
    "name": "Sales Deck Positioning Framework",
    "type": "model_framework",
    "confidence": 0.9,
    "description": "A three-layer approach to structuring first call presentations that builds credibility, previews value, and qualifies interest",
    "components": [
      "Warmer: Establish credibility with social proof and metrics",
      "Preview: Show what we do (not how) to align with prospect problems",
      "Qualify: Determine if prospect has serious change management intent"
    ],
    "evidence_quote": "The first few slides in the deck is what we call a warmer. Right. We're kind of establishing our credibility. They're kind of realizing, okay, why should I be listening to this person talk to me? Why are they legit? So we talk a little bit about section.",
    "source_transcript": "transcripts_normalized/Company Lunch & Learn 2025-09-12 13_04 transcript (1).json",
    "source_date": "2025-09-12"
  },
  {
    "name": "Time as Currency Decision Framework",
    "type": "decision_framework",
    "confidence": 0.88,
    "description": "A principle-based approach to sales resource allocation that treats time as the primary constraint and optimizes for high-conversion prospects",
    "components": [
      "Recognize time is money principle",
      "Prioritize prospects likely to convert",
      "Seek early disqualification signals",
      "Avoid low-probability pipeline bloat"
    ],
    "evidence_quote": "Time is money. Right. So we actually don't want to spend too much time talking to people that aren't going to give us money, for lack of a better term. Right. So a lot of the first callback is to qualify are these people that could be customers for us.",
    "source_transcript": "transcripts_normalized/Company Lunch & Learn 2025-09-12 13_04 transcript (1).json",
    "source_date": "2025-09-12"
  },
  {
    "name": "Committee-Based Event Organization Framework",
    "type": "model_framework",
    "confidence": 0.92,
    "description": "A structural model for organizing large events by dividing responsibilities into specialized committees with designated chairs who work independently and report back to central coordination",
    "components": [
      "Committee formation with specific focus areas",
      "Committee chair designation",
      "Independent committee meetings",
      "Regular reporting back to central coordination",
      "Catering and drinks committee",
      "Hall setup committee"
    ],
    "evidence_quote": "So what I really like to do for this meeting really is to get committee chairs. We don't have enough time, as I've said, exactly two weeks to get things done. And so I'm really hoping that people will step up, be a committee chair, have your meeting behind the scene and then report back to us when we meet again.",
    "source_transcript": "transcripts_normalized/Maryland Funeral 2025-11-20 19_04 transcript.json",
    "source_date": "2025-11-20"
  },
  {
    "name": "Location Selection Decision Framework",
    "type": "decision_framework",
    "confidence": 0.88,
    "description": "A decision-making logic for selecting event locations based on proximity to attendees, transportation accessibility, and family connection to the location",
    "components": [
      "Proximity to majority of attendees",
      "Transportation infrastructure (multiple airports)",
      "Personal/family connection to location",
      "Cost considerations as secondary factor"
    ],
    "evidence_quote": "So papa lived in Maryland, A lot of family members out there. And so that's why I didn't have it in California. And I thought California is so far away, way, way across the country. And I would have to be moving everybody across the country to come to, to California. So we decided that we'll have it in Maryland where most people are not very far. New York is not very far from there, and lots of three different airports",
    "source_transcript": "transcripts_normalized/Maryland Funeral 2025-11-20 19_04 transcript.json",
    "source_date": "2025-11-20"
  },
  {
    "name": "Time-Constrained Event Planning Process",
    "type": "process_framework",
    "confidence": 0.85,
    "description": "A step-by-step methodology for managing event planning under tight deadlines through structured meetings, committee delegation, and weekly reporting cycles",
    "components": [
      "Initial full group meeting to establish committees",
      "Committee chair assignment",
      "Independent committee work periods",
      "Weekly progress meetings",
      "Final coordination two weeks before event"
    ],
    "evidence_quote": "We don't have enough time, as I've said, exactly two weeks to get things done... have your meeting behind the scene and then report back to us when we meet again. Hopefully we're going to meet again next week.",
    "source_transcript": "transcripts_normalized/Maryland Funeral 2025-11-20 19_04 transcript.json",
    "source_date": "2025-11-20"
  },
  {
    "name": "Stakeholder Engagement Framework for Memorial Events",
    "type": "engagement_framework",
    "confidence": 0.8,
    "description": "A framework for engaging family members and community in memorial event planning through prayer, committee participation, and role-based involvement",
    "components": [
      "Opening with prayer for spiritual grounding",
      "Acknowledging relationship to deceased (father, grandfather, uncle)",
      "Committee-based participation opportunities",
      "Regular communication touchpoints",
      "Distributed responsibility model"
    ],
    "evidence_quote": "Heavenly Father, we give you all the praise and glory for a wonderful evening like this where your people are gathered in your name... Lord, we are gathered here tonight to commemorate the memory of our father, our grandfather, our uncle, who departed from us to be with you.",
    "source_transcript": "transcripts_normalized/Maryland Funeral 2025-11-20 19_04 transcript.json",
    "source_date": "2025-11-20"
  },
  {
    "name": "AI Product Onboarding Framework",
    "type": "process_framework",
    "confidence": 0.88,
    "description": "Multi-step onboarding process for AI-powered presentation tools that involves template setup, brand customization, layout approval, and user fingerprinting before actual product use",
    "components": [
      "Upload brand template (PPTX)",
      "System extracts color palette and fonts",
      "User approves layout options",
      "User selects color sequence preferences",
      "User selects font color preferences",
      "Build communication fingerprint"
    ],
    "evidence_quote": "So I literally just created my account. This is the first thing... Yeah, it's there. So what is it says it takes three to four minutes... So you're basically going through to sort of approve for the right layout... Now let's build your communication fingerprint",
    "source_transcript": "transcripts_normalized/Product Teardown 2025-09-10 10_12 transcript.json",
    "source_date": "2025-09-10"
  },
  {
    "name": "Hybrid AI Service Model",
    "type": "model_framework",
    "confidence": 0.85,
    "description": "Product architecture combining automated AI solutions with human designer support as a fallback or premium option",
    "components": [
      "AI automated solution (primary)",
      "Human designer team (hybrid option)",
      "Security layer (confidentiality assurance)"
    ],
    "evidence_quote": "And I thought it's interesting, kind of like what we were talking about with the ADA thing, where it's like you have the AI solution and then you have the hybrid solution. They have this hybrid solution where they have a team of designers who can build slides for you",
    "source_transcript": "transcripts_normalized/Product Teardown 2025-09-10 10_12 transcript.json",
    "source_date": "2025-09-10"
  },
  {
    "name": "Template-First vs Content-First Decision Framework",
    "type": "decision_framework",
    "confidence": 0.82,
    "description": "Decision logic for optimal workflow sequence in template-based content creation systems",
    "components": [
      "If using branded templates: setup template first to avoid reformatting",
      "Else: create content then apply template (inefficient)"
    ],
    "evidence_quote": "Is it better if you do the decks and then put the. Put it into the template or put the template experience? I think you want to do the template first... Because if you do all the entire deck and then have to reformat everything, then that sort of defeats the purpose",
    "source_transcript": "transcripts_normalized/Product Teardown 2025-09-10 10_12 transcript.json",
    "source_date": "2025-09-10"
  },
  {
    "name": "Enterprise Onboarding Access Model",
    "type": "decision_framework",
    "confidence": 0.78,
    "description": "Framework for determining who needs to complete onboarding setup in enterprise software deployment",
    "components": [
      "Administrative setup (single admin user)",
      "Organization-wide deployment (no repeated setup)",
      "Individual vs enterprise configuration decision"
    ],
    "evidence_quote": "I mean, you wouldn't need every user in the organization to do this. It's only. I'm an individual using their demo. So, like, nobody else could do this except for me... Because it's enterprise, do we want to have, like, an onboarding where somebody actually does this for them?",
    "source_transcript": "transcripts_normalized/Product Teardown 2025-09-10 10_12 transcript.json",
    "source_date": "2025-09-10"
  },
  {
    "name": "Workshop Introduction Time Management Framework",
    "type": "measurement_framework",
    "confidence": 0.92,
    "description": "A target time allocation framework for workshop introductions with awareness of actual vs. ideal outcomes",
    "components": [
      "Ideal introduction: 10 minutes or less",
      "Actual introduction: typically 25 minutes",
      "Goal for all sessions: 10 minute introduction maximum"
    ],
    "evidence_quote": "our goal for everyone is like 10 minute introduction and then people go live and the introduction is always like 25 minutes. So yeah, 10 minutes or less is the ideal situation.",
    "source_transcript": "transcripts_normalized/AI for Negotiations Content Call_ Activities and Demos 2025-07-30 14_04 transcript.json",
    "source_date": "2025-07-30"
  },
  {
    "name": "Workshop Session Support Framework",
    "type": "process_framework",
    "confidence": 0.95,
    "description": "A role division framework for managing workshop delivery between instructor and session support",
    "components": [
      "Maxwell kicks things off",
      "Maxwell manages the chat and activities",
      "Maxwell manages polls and activities",
      "Instructor facilitates workshop content",
      "Maxwell manages Q&A in the chat",
      "Maxwell provides overview of upcoming sessions",
      "Anything not workshop content, Maxwell handles"
    ],
    "evidence_quote": "the typical amount of interaction is Maxwell kicks things off. She manages the chat and manages the activities. So the instructor will kick it off to. She'll manage the polls and manage the activities and then manage the Q and A in the chat and then provide the overview of the upcoming sessions. So it's usually the instructor facilitates the actual workshop content, and then anything not workshop content, Maxwell will do.",
    "source_transcript": "transcripts_normalized/AI for Negotiations Content Call_ Activities and Demos 2025-07-30 14_04 transcript.json",
    "source_date": "2025-07-30"
  },
  {
    "name": "Dry Run Feedback Framework",
    "type": "engagement_framework",
    "confidence": 0.9,
    "description": "A real-time feedback methodology for rehearsing workshop content with audience participation",
    "components": [
      "Go section by section with feedback",
      "Allow participants to interject feedback during presentation",
      "Types of feedback: cut that, change this, add a note here, animate that slide",
      "Purpose: get final kinks out",
      "Purpose: get audience interaction and feedback"
    ],
    "evidence_quote": "What we usually do is we'll go section by section and people will provide feedback, or you can let people, like, interject the feedback as you're presenting, if you prefer to do it that way. But yeah, it's where throughout the entire thing, we're like, cut that, change this, add a note here, animate that slide. So it's really to just, like, get all of the final kinks out and get some audience into the feedback and interaction.",
    "source_transcript": "transcripts_normalized/AI for Negotiations Content Call_ Activities and Demos 2025-07-30 14_04 transcript.json",
    "source_date": "2025-07-30"
  },
  {
    "name": "Three-Phase Workshop Activity Framework",
    "type": "process_framework",
    "confidence": 0.88,
    "description": "A progressive learning framework that builds from AI research to AI practice to live application, with a proposed closing loop",
    "components": [
      "Phase 1: Look up negotiation partner on Crystal (research)",
      "Phase 2: Practice with AI using partner's persona (preparation)",
      "Phase 3: Execute live role play using insights (application)",
      "Close the loop: connect preparation to live execution"
    ],
    "evidence_quote": "you looked me up on Crystal, you know what my personality type is and you've understood how to approach me for negotiations. You've practiced with my Persona that you uploaded into Crystal. That's now going to help you do the role play. So let's now do it live based on what you just practiced.",
    "source_transcript": "transcripts_normalized/AI for Negotiations Content Call_ Activities and Demos 2025-07-30 14_04 transcript.json",
    "source_date": "2025-07-30"
  },
  {
    "name": "Workshop Duration Framework",
    "type": "measurement_framework",
    "confidence": 0.85,
    "description": "A time allocation model for different workshop structures",
    "components": [
      "Three-phase workshop: typically 90 minute run time",
      "Current session: 2 hours available",
      "Additional time allows for live interaction elements"
    ],
    "evidence_quote": "I think we should have time for it given that we have two hours and typically with a three phase workshop, that's usually a 90 minute run time.",
    "source_transcript": "transcripts_normalized/AI for Negotiations Content Call_ Activities and Demos 2025-07-30 14_04 transcript.json",
    "source_date": "2025-07-30"
  },
  {
    "name": "Three-Step Workflow Redesign Framework",
    "type": "process_framework",
    "confidence": 0.95,
    "description": "A sequential methodology for redesigning workflows with AI, starting with identification, moving to capability mapping, and ending with implementation",
    "components": [
      "Step 1: Identifying Your Workflows - Prioritize workflows from audit, define goals and purpose, break down into individual steps",
      "Step 2: AI Superpowers - Map AI capabilities (research, ideation, etc.) to workflow steps",
      "Step 3: [Implementation - not fully described in transcript]"
    ],
    "evidence_quote": "And then there is this three step framework which is about identifying your workflows... And the second part of the framework is thinking about AI superpowers.",
    "source_transcript": "transcripts_normalized/Kyra __ Lucas Berkeley XMBA Workflow Redesign Workshop 2025-09-17 13_32 transcript.json",
    "source_date": "2025-09-17"
  },
  {
    "name": "Workflow Decomposition and Optimization Framework",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "Tool-agnostic process for breaking down sequences of actions into component parts and independently optimizing each part with appropriate automation levels",
    "components": [
      "Break down sequence of actions into subsequent parts",
      "Optimize each part independently",
      "Determine automation level per part (fully automated, human-only, or hybrid with human verification)"
    ],
    "evidence_quote": "for any particular set of actions, whether it's all within one LLM or it's across multiple LLMs or maybe an LLM plus an agent kind of agnostic of tools they can think about how do I break down that sequence of actions into subsequent parts and then optimize each of the parts independently... One of the parts may be completely a automated. One of the parts might be human, only the final step requires human verification or human feedback.",
    "source_transcript": "transcripts_normalized/Kyra __ Lucas Berkeley XMBA Workflow Redesign Workshop 2025-09-17 13_32 transcript.json",
    "source_date": "2025-09-17"
  },
  {
    "name": "Workflow Identification Sub-Framework",
    "type": "process_framework",
    "confidence": 0.88,
    "description": "Three-phase approach to properly scoping and understanding workflows before redesign",
    "components": [
      "Prioritize workflows from audit list to determine what to tackle first",
      "Define goals and purpose - understand why the workflow exists and what matters",
      "Break down workflows into individual steps"
    ],
    "evidence_quote": "how do you actually prioritize those to determine what to tackle first? And then from the ones that you've prioritized, then actually thinking about what are your goals, like, why do you engage in this workflow? What is actually important about it?... And then you break down those workflows into the steps that are involved in that workflow.",
    "source_transcript": "transcripts_normalized/Kyra __ Lucas Berkeley XMBA Workflow Redesign Workshop 2025-09-17 13_32 transcript.json",
    "source_date": "2025-09-17"
  },
  {
    "name": "AI Superpowers Capability Framework",
    "type": "model_framework",
    "confidence": 0.75,
    "description": "Categorization of AI capabilities that can be mapped to workflow steps (framework under development)",
    "components": [
      "Research capability",
      "Ideation/idea creation capability",
      "[Additional capabilities being developed - 5 total planned]"
    ],
    "evidence_quote": "And the second part of the framework is thinking about AI superpowers. So there are, we have five. I'm still working on those... You know, AI can conduct research, it can create ideas, it can",
    "source_transcript": "transcripts_normalized/Kyra __ Lucas Berkeley XMBA Workflow Redesign Workshop 2025-09-17 13_32 transcript.json",
    "source_date": "2025-09-17"
  },
  {
    "name": "Goal-Based Solution Design Framework",
    "type": "decision_framework",
    "confidence": 0.85,
    "description": "Decision logic where workflow goals (speed vs. quality, priority level) inform the type and extent of AI automation to implement",
    "components": [
      "Identify workflow purpose and organizational priority",
      "Determine primary goal (e.g., speed/efficiency vs. quality)",
      "Let goals inform solution design and AI support level"
    ],
    "evidence_quote": "like the purpose of it is really, it's supplementary to the experience because everything is on demand. So we want these live sessions, but they're really actually pretty low priority for the company. And so my actual goal is speed and efficiency, necessarily quality. And so that's going to inform the kind of solution I develop and where and how I let AI support me.",
    "source_transcript": "transcripts_normalized/Kyra __ Lucas Berkeley XMBA Workflow Redesign Workshop 2025-09-17 13_32 transcript.json",
    "source_date": "2025-09-17"
  },
  {
    "name": "Workflow Transformation Process",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "A systematic approach to identifying AI integration opportunities within existing workflows by mapping all process steps first, then identifying AI insertion points",
    "components": [
      "Meet with team leads individually",
      "Map out every step in team's current process",
      "Identify where AI could plug in during the mapping",
      "Specify tools for each AI intervention point"
    ],
    "evidence_quote": "over the past month or so, Shannon and I met with all the team leads, and we started building out, like, what is every step in your team's process... We laid out all the steps in the process... as we were going through that, we were like, oh, well, here's how AI could plug in. Here's the tool. Here's the tool. We were identifying where we could transform the workflow as we went.",
    "source_transcript": "transcripts_normalized/Marketing Offsite AI Workshop - Martech 2025-09-24 15_01 transcript.json",
    "source_date": "2025-09-24"
  },
  {
    "name": "Workshop Customization Framework",
    "type": "decision_framework",
    "confidence": 0.88,
    "description": "A tiered approach to customizing AI training based on team fluency levels and specific needs",
    "components": [
      "Assess team's AI fluency level",
      "Identify if team needs basic prompting or advanced tool building",
      "Meet with teams to understand specific use cases",
      "Customize workshop content accordingly (basic activity vs. GPT building)"
    ],
    "evidence_quote": "I know we have varying levels of fluency with AI. Some teams are like, they just need to learn how to prompt, like, full stop, teach me how to prompt. Some teams, like MarTech, are, like, well down the path of, like, building your own tools. So I would just want to make sure that the teams get out of it what they need.",
    "source_transcript": "transcripts_normalized/Marketing Offsite AI Workshop - Martech 2025-09-24 15_01 transcript.json",
    "source_date": "2025-09-24"
  },
  {
    "name": "Use Case Prioritization Workshop Structure",
    "type": "process_framework",
    "confidence": 0.9,
    "description": "A two-hour structured workshop format with general education followed by team-specific hands-on activity",
    "components": [
      "Hour 1: Moderator provides overarching view of AI in workflows",
      "Teams receive customized workbooks",
      "Teams prioritize their workflow components",
      "Teams score workflow pieces by effort required",
      "Teams identify how to solve prioritized items with AI",
      "Hour 2: Hands-on prompting or GPT building with expert support"
    ],
    "evidence_quote": "it's two hours, the first hour. We're going to have the moderator come in and sort of give, like, an overarching view... each team is going to get a workbook. So essentially, people are going to, like, prioritize their workflow, find a specific piece, think about how much effort it takes, score those pieces of their workflow, and then they're going to go through, like, okay, how are we going to solve those things?",
    "source_transcript": "transcripts_normalized/Marketing Offsite AI Workshop - Martech 2025-09-24 15_01 transcript.json",
    "source_date": "2025-09-24"
  },
  {
    "name": "Workflow Effort Scoring Model",
    "type": "measurement_framework",
    "confidence": 0.85,
    "description": "A method to evaluate and prioritize workflow components for AI intervention based on effort metrics",
    "components": [
      "Identify specific workflow pieces",
      "Score each piece by effort/difficulty",
      "Prioritize based on scores",
      "Select high-effort items for AI solutions"
    ],
    "evidence_quote": "people are going to, like, prioritize their workflow, find a specific piece, think about how much effort it takes, score those pieces of their workflow",
    "source_transcript": "transcripts_normalized/Marketing Offsite AI Workshop - Martech 2025-09-24 15_01 transcript.json",
    "source_date": "2025-09-24"
  },
  {
    "name": "Team AI Adoption Mandate",
    "type": "scaling_framework",
    "confidence": 0.87,
    "description": "A team-wide initiative to ensure all members build custom GPTs by a target date, with structured support",
    "components": [
      "Set team-wide goal (custom GPT per member)",
      "Establish timeline (before 2026)",
      "Identify barriers to entry",
      "Provide expert-led training sessions",
      "Differentiate between members who have/haven't built GPTs"
    ],
    "evidence_quote": "building a custom GPT is something that, like, we have challenged ourselves for every member on the martech side before 2026... I do think that's like a valuable lesson, but I think building a custom GPT is probably where the martech Org would lean towards, especially given that some of us have already built our own. And for those who haven't, that is kind of not the mandate per se, but like the ambitious push that we're providing to everyone on our team.",
    "source_transcript": "transcripts_normalized/Marketing Offsite AI Workshop - Martech 2025-09-24 15_01 transcript.json",
    "source_date": "2025-09-24"
  },
  {
    "name": "Use Case Scalability Decision Matrix",
    "type": "decision_framework",
    "confidence": 0.89,
    "description": "A framework for selecting which AI use cases to prioritize based on team-wide utility versus niche application",
    "components": [
      "Evaluate workflow improvement potential",
      "Assess benefit scope (team-wide vs. specific use case)",
      "Consider adoptability by broader organization",
      "Prioritize broadly useful solutions over niche ones"
    ],
    "evidence_quote": "what workflow are we trying to improve and build a custom GPT against? Is it documenting and providing back like meeting notes off of granola so that it's like a simple doc that we can easily pass through to Slack? That would make a lot of sense and everyone would get some benefit of that. As opposed to Drago 2.0... which is only for an attribution use case versus something that would be more so useful for everyone on martech, but also can be adopted by others in the Org.",
    "source_transcript": "transcripts_normalized/Marketing Offsite AI Workshop - Martech 2025-09-24 15_01 transcript.json",
    "source_date": "2025-09-24"
  },
  {
    "name": "Engagement Framework for AI Rollout",
    "type": "engagement_framework",
    "confidence": 0.86,
    "description": "A systematic approach to engaging teams in AI adoption through individual team consultations and customized training paths",
    "components": [
      "Schedule individual meetings with each team",
      "Understand team-specific needs and fluency levels",
      "Lay out team processes collaboratively",
      "Customize workshop content per team",
      "Provide team-appropriate activity packets and expert support"
    ],
    "evidence_quote": "I'm taking each team and sitting down and sort of talking through, like, do you want to customize your section in any way?... What I've started doing with folks is sort of had people lay out their specific use case that they think would be good for their team to, like, dive into... I'm meeting with everyone to do that.",
    "source_transcript": "transcripts_normalized/Marketing Offsite AI Workshop - Martech 2025-09-24 15_01 transcript.json",
    "source_date": "2025-09-24"
  },
  {
    "name": "Quarterly Fund Operations Cycle",
    "type": "process_framework",
    "confidence": 0.9,
    "description": "A cyclical quarterly process for fund operations reporting involving valuation work, MD meetings, and LP financial reporting",
    "components": [
      "Conduct quarterly valuation work with MDs",
      "Generate reporting for MD meetings",
      "Work with finance team to develop reports",
      "Generate financial reporting for limited partners",
      "Produce capital account statements using AllView"
    ],
    "evidence_quote": "a lot of the work that the fund operations team done is more like cyclical. So like on quarterly basis we're doing repetitive work and a lot of it is revolves around reporting. So right now we're in a cycle where we're doing valuation work with all of our MDs... From that, we're then generating and working with the finance team to develop reports. Reporting like financials, which are going to be delivered to our limited partners.",
    "source_transcript": "transcripts_normalized/Alyson Chizauskas and Kyra Atekwana 2025-09-24 11_30 transcript.json",
    "source_date": "2025-09-24"
  },
  {
    "name": "Data Integration and Reporting Pipeline",
    "type": "process_framework",
    "confidence": 0.85,
    "description": "A manual data flow process for transforming CRM data into structured reports through multiple systems",
    "components": [
      "Pull reports from Salesforce",
      "Upload data into Coda",
      "Generate reports from uploaded data"
    ],
    "evidence_quote": "Some of the manual processes that we were doing, you know, pulling reports from Salesforce and you know, you know, uploading them into Coda and then you know, potentially developing reports from that.",
    "source_transcript": "transcripts_normalized/Alyson Chizauskas and Kyra Atekwana 2025-09-24 11_30 transcript.json",
    "source_date": "2025-09-24"
  },
  {
    "name": "Process Documentation and Knowledge Management Framework",
    "type": "process_framework",
    "confidence": 0.88,
    "description": "A systematic approach to capturing and organizing institutional knowledge through video documentation for onboarding and knowledge retention",
    "components": [
      "Document processes using Loom videos",
      "Create a centralized library of documented processes",
      "Make library accessible for onboarding new team members",
      "Capture information to prevent knowledge loss"
    ],
    "evidence_quote": "the team over the last couple of years has generated a number of videos. They've used loom to capture all of these videos. So we have the processes documented and we're trying to kind of create a more robust library so that when people are onboarding, they have access to those things... capturing information and processes so they're not lost and just in people's minds.",
    "source_transcript": "transcripts_normalized/Alyson Chizauskas and Kyra Atekwana 2025-09-24 11_30 transcript.json",
    "source_date": "2025-09-24"
  },
  {
    "name": "AI-Assisted Event Planning Process",
    "type": "process_framework",
    "confidence": 0.82,
    "description": "A methodology for using AI as a collaborative partner in developing offsite agendas and activities",
    "components": [
      "Use ChatGPT as planning partner",
      "Develop event agenda collaboratively with AI",
      "Generate exercises aligned with daily themes"
    ],
    "evidence_quote": "When our last two off sites that we developed, I was kind of almost felt like, you know, chat, GPT became my own personal assistant and partner in helping me to develop. We developed our whole agenda. We came up with exercises that we were going to that like matched with the different themes of the day",
    "source_transcript": "transcripts_normalized/Alyson Chizauskas and Kyra Atekwana 2025-09-24 11_30 transcript.json",
    "source_date": "2025-09-24"
  },
  {
    "name": "Manual-to-Automated Process Evolution Framework",
    "type": "decision_framework",
    "confidence": 0.87,
    "description": "A strategic approach to identifying which manual processes to automate to enable higher-value analytical work",
    "components": [
      "Identify manual daily processes",
      "Evaluate automation opportunities",
      "Automate suitable processes",
      "Shift focus from task-oriented to deeper analytical work"
    ],
    "evidence_quote": "the biggest thing is how we can take some of the manual processes that we're doing daily and automate those in a way that we can then do deeper work and like more analytical work for our teams versus it being task oriented.",
    "source_transcript": "transcripts_normalized/Alyson Chizauskas and Kyra Atekwana 2025-09-24 11_30 transcript.json",
    "source_date": "2025-09-24"
  },
  {
    "name": "AI Use Case Evaluation Framework",
    "type": "process_framework",
    "confidence": 0.98,
    "description": "A three-phase structured approach for evaluating and prioritizing AI use cases across functional teams",
    "components": [
      "Phase 1: Review use cases - ensure common understanding across stakeholders",
      "Phase 2: Evaluate and prioritize - assess impact (high/medium/low), determine efficiency vs quality gains, identify blockers and adoption requirements",
      "Phase 3: Rank order - create prioritized list of use cases for implementation"
    ],
    "evidence_quote": "We'll spend just a little bit time up front, just kind of quick review of the use cases, make sure everyone's on the same page, kind of understands what they are so that when we get to prioritizing, we're all. Speaking the same language and then spend the bulk of our time evaluating them on their potential impact... understanding why we're saying it's high, medium or low impact for potential AI use. And then understanding is it primarily an efficiency or a quality gain. And then for the ones that are high, I want to spend a little time discussing, hey, what's kind of blocking this from happening today and then what's really needed to drive adoption in the future. And then we can spend the last few minutes maybe just going through the highs if we get to the mediums. Great of just, hey, let's rank order these.",
    "source_transcript": "transcripts_normalized/Technology - AI Discovery & Prioritization Session 2025-08-04 14_31 transcript.json",
    "source_date": "2025-08-04"
  },
  {
    "name": "AI Impact Assessment Dimensions",
    "type": "measurement_framework",
    "confidence": 0.92,
    "description": "A dual-dimension framework for assessing the value of AI use cases",
    "components": [
      "Impact level classification (high, medium, low)",
      "Value type determination (efficiency gain vs quality gain)"
    ],
    "evidence_quote": "understanding is it primarily an efficiency or a quality gain... understanding why we're saying it's high, medium or low impact for potential AI use",
    "source_transcript": "transcripts_normalized/Technology - AI Discovery & Prioritization Session 2025-08-04 14_31 transcript.json",
    "source_date": "2025-08-04"
  },
  {
    "name": "AI Use Case Categorization Model",
    "type": "model_framework",
    "confidence": 0.9,
    "description": "Organizational structure for categorizing AI initiatives across technology functions",
    "components": [
      "Engineering (coding, testing, documentation)",
      "Security",
      "Infrastructure",
      "Data Analytics"
    ],
    "evidence_quote": "I've kind of broken this up into a few buckets. Engineering, security and infrastructure. The one piece of kind of the technology org that I think we're, we don't have as many ideas for is data analytics.",
    "source_transcript": "transcripts_normalized/Technology - AI Discovery & Prioritization Session 2025-08-04 14_31 transcript.json",
    "source_date": "2025-08-04"
  },
  {
    "name": "AI Pilot to Production Framework",
    "type": "scaling_framework",
    "confidence": 0.85,
    "description": "Post-prioritization process for moving AI use cases from identification to implementation",
    "components": [
      "Identify and prioritize use cases",
      "Research available AI tools that address use cases",
      "Design tests and pilots",
      "Measure impact and success"
    ],
    "evidence_quote": "And then from there we'll kind of go away and work with you guys as well. And I think I saw some people even already filling in some tools. But look for what are the AI tools out there that can address these solutions or these use cases. And then we'll work with you all to start designing tests and pilots where appropriate.",
    "source_transcript": "transcripts_normalized/Technology - AI Discovery & Prioritization Session 2025-08-04 14_31 transcript.json",
    "source_date": "2025-08-04"
  },
  {
    "name": "AI Adoption Barrier Analysis",
    "type": "decision_framework",
    "confidence": 0.88,
    "description": "Framework for identifying and addressing obstacles to AI implementation",
    "components": [
      "Identify blockers preventing current implementation",
      "Determine requirements needed to drive future adoption"
    ],
    "evidence_quote": "And then for the ones that are high, I want to spend a little time discussing, hey, what's kind of blocking this from happening today and then what's really needed to drive adoption in the future.",
    "source_transcript": "transcripts_normalized/Technology - AI Discovery & Prioritization Session 2025-08-04 14_31 transcript.json",
    "source_date": "2025-08-04"
  },
  {
    "name": "Cross-Functional AI Discovery Process",
    "type": "engagement_framework",
    "confidence": 0.93,
    "description": "Systematic approach to gathering AI use cases across organizational functions",
    "components": [
      "Meet with stakeholders function by function",
      "Identify highest priority use cases (both underway and potential)",
      "Collaborative prioritization sessions with functional leaders",
      "Create consolidated prioritized list across all functions"
    ],
    "evidence_quote": "I think everyone here I've been able to meet with as we've been going through. But quick reminder, we're kind of been going across function by function, looking for what are the highest priority AI Use cases, both underway and potential new ones. So hoping to spend the time today with the end goal of coming out of this with a list of all the use cases in technology, kind of prioritize top to bottom.",
    "source_transcript": "transcripts_normalized/Technology - AI Discovery & Prioritization Session 2025-08-04 14_31 transcript.json",
    "source_date": "2025-08-04"
  },
  {
    "name": "Workshop Content Customization Framework",
    "type": "process_framework",
    "confidence": 0.88,
    "description": "A sequential approach to customizing enterprise workshop content: understanding client needs, assessing tool access, adapting content to available platforms, and applying relevant caveats for enterprise constraints",
    "components": [
      "Identify desired workshop topics and outcomes",
      "Assess available AI tools and platforms",
      "Determine data security constraints",
      "Customize content to approved tools",
      "Apply appropriate usage caveats"
    ],
    "evidence_quote": "The first question I have is actually what are the tools, the AI tools that your team has access to? Just to think about how we would customize that content... So it sounds like you all have access to ChatGPT. That might be something that they're able to do and then we can make sure that we caveat again that this is something, you know, where if you're going to use these features you need to ensure not to use company data.",
    "source_transcript": "transcripts_normalized/Section x HP Prep for Workshops 2025-10-06 16_03 transcript.json",
    "source_date": "2025-10-06"
  },
  {
    "name": "Enterprise AI Tool Decision Framework",
    "type": "decision_framework",
    "confidence": 0.92,
    "description": "A logic framework for selecting appropriate AI tools based on data sensitivity: approved tools for company data versus open tools for non-sensitive work",
    "components": [
      "Determine if work involves company/sensitive data",
      "If sensitive: use approved enterprise tool (Copilot)",
      "If not sensitive: can use external tools (ChatGPT)",
      "Default to prescribed enterprise tool for training"
    ],
    "evidence_quote": "We primarily have access to Copilot as our approved to enter HP data into AI platform. We are allowed to use for example ChatGPT, but obviously we don't have. We're not able to enter company information... Copilot is probably better because that's the one that we are really pushing and using.",
    "source_transcript": "transcripts_normalized/Section x HP Prep for Workshops 2025-10-06 16_03 transcript.json",
    "source_date": "2025-10-06"
  },
  {
    "name": "Workshop Topic Alignment Framework",
    "type": "process_framework",
    "confidence": 0.85,
    "description": "A methodology for aligning workshop content with broader organizational events and themes by reviewing overall program structure and ensuring topic relevance to multiple stakeholder groups",
    "components": [
      "Review how overall summit is coming together",
      "Align themes with other organizational summits",
      "Assess relevance to day-to-day work",
      "Ensure inclusivity across organizational units",
      "Adjust topic selection accordingly"
    ],
    "evidence_quote": "We were looking at how the overall summit is coming together and it's on the back of some other summits and trying to align those themes together and thinking through what really makes sense... We thought that might feel a little bit more hyper relevant to their day to day than the decision making piece.",
    "source_transcript": "transcripts_normalized/Section x HP Prep for Workshops 2025-10-06 16_03 transcript.json",
    "source_date": "2025-10-06"
  },
  {
    "name": "Enterprise Learning Deployment Framework",
    "type": "engagement_framework",
    "confidence": 0.82,
    "description": "A structured approach to deploying enterprise learning initiatives with separate tracks for content delivery and technical platform setup, managed by specialized roles",
    "components": [
      "Content and logistics team (workshop delivery)",
      "Customer success manager (platform setup)",
      "Separate coordination meetings for each track",
      "Program manager for logistics coordination",
      "Upskilling team for content customization"
    ],
    "evidence_quote": "The folks on the line on our side today are the folks who are going to be helping out with all of the workshop content, logistics, etc. There is another individual, Caitlin, who was invited today but couldn't join at this time. She will be your customer success manager and she'll be helping with all of the Prof. AI setup and deployment.",
    "source_transcript": "transcripts_normalized/Section x HP Prep for Workshops 2025-10-06 16_03 transcript.json",
    "source_date": "2025-10-06"
  },
  {
    "name": "VIP Relationship Touch Point Management System",
    "type": "process_framework",
    "confidence": 0.98,
    "description": "A tiered relationship management system that categorizes contacts and defines engagement frequency based on priority level",
    "components": [
      "Identify and label high priority contacts as Tier 1, 2, or 3",
      "Tier 1: Engage monthly",
      "Tier 2: Engage quarterly",
      "Tier 3: Engage annually",
      "Monthly review: Surface updates and identify stale relationships using touchpoint data",
      "Send stakeholder list of contacts requiring re-engagement"
    ],
    "evidence_quote": "We will identify a high priority contact. We label them Tier 1, 2 or 3 Tier 1 contacts. We want to ensure that Paul has talked to them every month, tier 2 contacts every quarter and tier 3 contacts once a year. And so every month I surface the updates from that month, send him using touchpoint data from Affinity, send him the information on those people who are starting to become stale.",
    "source_transcript": "transcripts_normalized/Amanda Lennon and Kyra Atekwana 2025-09-22 14_00 transcript.json",
    "source_date": "2025-09-22"
  },
  {
    "name": "Multi-System Data Integration Framework",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "A methodology for aggregating and enriching contact data from multiple sources into centralized repositories",
    "components": [
      "Extract base contact data from primary CRM (Affinity)",
      "Port contacts into secondary system (Coda)",
      "Manually enrich with personal details (dietary restrictions, family, interests)",
      "Maintain synchronized data across systems",
      "Leverage auto-populated fields where available"
    ],
    "evidence_quote": "I have a combination of just an affinity list of Paul's contacts which I also port into Coda where I can add more specific information like dietary restrictions, spouse's name is Karen, loves the Bruins, that kind of information. Because Affinity, which is the system that we use at the moment for pipeline management, is not a good contacts manager for Rolodex data.",
    "source_transcript": "transcripts_normalized/Amanda Lennon and Kyra Atekwana 2025-09-22 14_00 transcript.json",
    "source_date": "2025-09-22"
  },
  {
    "name": "High-Value Relationship Identification Pattern",
    "type": "decision_framework",
    "confidence": 0.89,
    "description": "Logic for identifying valuable relationships that risk being overlooked based on interaction patterns rather than frequency",
    "components": [
      "Exclude high-frequency contacts (board members, regular collaborators)",
      "Focus on low-to-medium touch contacts",
      "Identify: One-time meeting + email exchanges + single call pattern",
      "Look for introduction-based connections",
      "Flag relationships with initial value exchange that went dormant",
      "Use calendar and email data to detect patterns"
    ],
    "evidence_quote": "These aren't going to be the relationships where he has 50 touch points with them in the past year. These are going to be the people that a government official that he met once at a party, has exchanged a handful of emails with and maybe did a one on one call but then dropped off the face of the earth and we didn't foster that relationship.",
    "source_transcript": "transcripts_normalized/Amanda Lennon and Kyra Atekwana 2025-09-22 14_00 transcript.json",
    "source_date": "2025-09-22"
  },
  {
    "name": "Knowledge Capture and Preservation System",
    "type": "model_framework",
    "confidence": 0.9,
    "description": "A conceptual approach to capturing, storing, and activating relationship intelligence for strategic use",
    "components": [
      "Information capture layer: Collect personal details and preferences",
      "Data preservation layer: Store in accessible, structured format",
      "Tracking layer: Monitor relationship activity and staleness",
      "Activation layer: Surface relevant context before meetings"
    ],
    "evidence_quote": "I spend a lot of time thinking about both information capture and data preservation as well as tracking... In my wildest dreams AI would have the ability to, to sort of be clay earth on steroids. And allow me to say, I just found out that Theresa Carlson's favorite drink is a whiskey sour and just have that entered into a profile somewhere and then anytime Paul had a meeting with that person, it would spit out what we know about them.",
    "source_transcript": "transcripts_normalized/Amanda Lennon and Kyra Atekwana 2025-09-22 14_00 transcript.json",
    "source_date": "2025-09-22"
  },
  {
    "name": "Government Ecosystem Intelligence Tracking",
    "type": "process_framework",
    "confidence": 0.85,
    "description": "A methodology for monitoring and tracking government stakeholders and influencers relevant to portfolio companies",
    "components": [
      "Identify major players and influencers in government",
      "Monitor thought leadership and positioning (e.g., Twitter/X)",
      "Track relevance to portfolio companies seeking DOD contracts",
      "Aggregate intelligence for strategic decision-making"
    ],
    "evidence_quote": "One of the things that I've been working on for quite a while that I'm hoping to leverage AI to use or to assist with is ecosystem tracking. Particularly because we focus very heavily on government... It would be helpful to have a better tracker on kind of what major players or influencers related to the government are thinking.",
    "source_transcript": "transcripts_normalized/Amanda Lennon and Kyra Atekwana 2025-09-22 14_00 transcript.json",
    "source_date": "2025-09-22"
  },
  {
    "name": "User Experience Learning Framework",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "A three-step process for understanding product flows: 1) Step through actual user flows, 2) Map out interactions and steps, 3) Use insights to inform design decisions",
    "components": [
      "Step through 3-4 key flows to understand ground truth",
      "Document and flow out all interactions",
      "Apply learnings to new design specifications"
    ],
    "evidence_quote": "The first task really for them is really stepping through the like three or four of the key just to understand the flow. Because I feel like no matter how we talk about this, if you've not stepped through the flow, you really don't have a ground understanding of what is being talked about.",
    "source_transcript": "transcripts_normalized/DeckSense Strategy Discussion 2025-09-17 17_04 transcript.json",
    "source_date": "2025-09-17"
  },
  {
    "name": "Competitive Pattern Analysis Framework",
    "type": "process_framework",
    "confidence": 0.88,
    "description": "Methodology for analyzing competitor products by identifying reusable UX patterns and selectively incorporating best practices rather than copying wholesale",
    "components": [
      "Analyze top 3 competitor flows",
      "Identify effective UI/UX patterns from each",
      "Cherry-pick and combine patterns that fit specific needs",
      "Create hybrid solution from best elements"
    ],
    "evidence_quote": "it's probably going to be a hodgepodge of all different things that are delivered each particular one. The parts of the UX that we feel like oh they did something great, something that we can use because these are all patterns, you know, like I don't think there's anything I've seen that since from what I've seen so far that seems really unique.",
    "source_transcript": "transcripts_normalized/DeckSense Strategy Discussion 2025-09-17 17_04 transcript.json",
    "source_date": "2025-09-17"
  },
  {
    "name": "UI Integration Pattern Model",
    "type": "model_framework",
    "confidence": 0.9,
    "description": "Three distinct approaches for integrating AI functionality into presentation tools",
    "components": [
      "Sidecar approach: AI tool runs alongside main presentation interface",
      "ALVRID approach: Split view with slides on one side and AI configuration on other",
      "Insert approach: AI interface appears as overlay/modal within native tool"
    ],
    "evidence_quote": "So there's probably like different ways like the sidecar approach, which I think the first one, the ALVRID approach where you have the slides and you have the thing happening this +AI and it has an insert approach in terms of the slider.",
    "source_transcript": "transcripts_normalized/DeckSense Strategy Discussion 2025-09-17 17_04 transcript.json",
    "source_date": "2025-09-17"
  },
  {
    "name": "Onboarding Friction Minimization Framework",
    "type": "process_framework",
    "confidence": 0.91,
    "description": "Design principle focused on reducing steps outside the core product interface to accelerate time-to-value",
    "components": [
      "Minimize configuration steps before entering main interface",
      "Get users into 'slide universe' as quickly as possible",
      "Reduce setup friction to enable immediate value creation",
      "Prioritize one-click entry to core functionality"
    ],
    "evidence_quote": "I feel like any of the more steps that somebody has to do outside the slide universe, like in some menu or doing some config, like the goal should be to remove as as much of that as possible. Like we want them in the slide, you know, in that slide interface as quickly as possible.",
    "source_transcript": "transcripts_normalized/DeckSense Strategy Discussion 2025-09-17 17_04 transcript.json",
    "source_date": "2025-09-17"
  },
  {
    "name": "User Journey Mapping Framework",
    "type": "process_framework",
    "confidence": 0.87,
    "description": "End-to-end user story methodology from initial interaction to final outcome, defining clear beginning and ending states",
    "components": [
      "Define user entry point (onboarding interaction)",
      "Map intermediate steps and interactions",
      "Specify end result/story ending (share, save, download)",
      "Ensure outcome matches expectations from traditional tools"
    ],
    "evidence_quote": "This is basically like the flow of the story for the user. You know from when you come, you interact with that sense to when you get in the end result, the end of the story is you've created a presentation, you can share it, save it, however you would, whatever you would do with a real presentation.",
    "source_transcript": "transcripts_normalized/DeckSense Strategy Discussion 2025-09-17 17_04 transcript.json",
    "source_date": "2025-09-17"
  },
  {
    "name": "Designer Task Assignment Framework",
    "type": "process_framework",
    "confidence": 0.85,
    "description": "Sequential process for onboarding designers and assessing proficiency through progressive tasks",
    "components": [
      "Task 1: Analyze and flow out top 3 competitor user flows",
      "Task 2: Demonstrate proficiency in creating user flow diagrams",
      "Task 3: Create wireframes based on defined specifications",
      "Requirement: Deep product understanding before advanced design work"
    ],
    "evidence_quote": "for the designers now I want them to go through like whatever are top three. I want them to go through it and flow it out in terms of like flowing out the interactions, filling out the steps... to show their proficiency because they're going to be able to build me to do flow and also to show that they can do a user flow.",
    "source_transcript": "transcripts_normalized/DeckSense Strategy Discussion 2025-09-17 17_04 transcript.json",
    "source_date": "2025-09-17"
  },
  {
    "name": "Organizational Onboarding Model",
    "type": "model_framework",
    "confidence": 0.83,
    "description": "Two-tier onboarding approach distinguishing between organizational admin setup and end-user access",
    "components": [
      "Tier 1: Single motivated person completes complex organizational setup",
      "Tier 2: Other users join with simplified access without full configuration",
      "Recognition that not all users need identical onboarding flows"
    ],
    "evidence_quote": "because it's obviously an organizational tool, not everyone in the organization is going to have to go through that flow. One person in the organization would have to go through that flow and then everybody else just joins",
    "source_transcript": "transcripts_normalized/DeckSense Strategy Discussion 2025-09-17 17_04 transcript.json",
    "source_date": "2025-09-17"
  },
  {
    "name": "Environment-Dependent Design Decision Framework",
    "type": "decision_framework",
    "confidence": 0.86,
    "description": "Logic for making design decisions based on whether the tool exists as native integration vs. standalone product",
    "components": [
      "If native integration (Google Slides/PowerPoint/Keynote): Onboarding approach X",
      "If standalone tooling outside those platforms: Onboarding approach Y",
      "Recognition that environment fundamentally changes what constitutes 'onboarding'"
    ],
    "evidence_quote": "there's the environment where this leaves. So it's either in a Google Slide, a PowerPoint or it's a tooling of its own that. That's outside those things. Right. If. And that vastly differs in terms of like what you call on button.",
    "source_transcript": "transcripts_normalized/DeckSense Strategy Discussion 2025-09-17 17_04 transcript.json",
    "source_date": "2025-09-17"
  },
  {
    "name": "Collaborative Ideation Documentation Framework",
    "type": "process_framework",
    "confidence": 0.84,
    "description": "Methodology for capturing design ideas during working sessions at appropriate level of detail",
    "components": [
      "Capture high-level ideas for each step",
      "Document all possibilities (idea dump) without filtering",
      "Note what could work vs. what might not work",
      "Refine to specific details after initial broad capture"
    ],
    "evidence_quote": "So right now we just want to really capture like high level, you know, as, as much detail as we can in this session. Sure. But the focus is just on, just at, for each, each step, just knowing all the things we're thinking about doing. So it's like a dump, you know, for each step just going into details of, hey, these are all the things we're thinking about.",
    "source_transcript": "transcripts_normalized/DeckSense Strategy Discussion 2025-09-17 17_04 transcript.json",
    "source_date": "2025-09-17"
  },
  {
    "name": "Meeting Scheduling Process",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "Sequential workflow for processing meeting requests and scheduling calendar events",
    "components": [
      "Identify meeting participants/attendees",
      "Check executive's calendar availability",
      "Account for travel schedule constraints",
      "Reply to meeting requestor or coordinate"
    ],
    "evidence_quote": "One, I have to see who's on, who needs to be on the call. Then the second is seeing like, okay, what times work for Teresa, which she's traveling and if she would just stop saying yes to everything, this would make my life a lot easier. But she travels so much that it makes it difficult. So then once I know who's on the call, I go through her calendar, figure out like when she's available. And then I would reply to either the meeting person or",
    "source_transcript": "transcripts_normalized/Stephanie Ford and Kyra Atekwana 2025-09-24 09_31 transcript.json",
    "source_date": "2025-09-24"
  },
  {
    "name": "Geographic Time Zone Coordination",
    "type": "process_framework",
    "confidence": 0.85,
    "description": "Multi-region scheduling methodology accounting for global time zones and daylight saving variations",
    "components": [
      "Identify time zones (Europe, Middle East, London, India)",
      "Research time zone conversions via Google",
      "Check daylight saving time changes",
      "Coordinate availability across regions"
    ],
    "evidence_quote": "And I'm working through not just my, my executive and another executive on team but all our other executives and going through multiple time zone. The time zones are tricky because you know I'm trying to schedule with you know, Europe, the Middle East, London, it's and it's India. So it gets really tricky and then not knowing when like daylight saving time changes. So you know, and so I try to, you know I'm constantly on Google looking for that.",
    "source_transcript": "transcripts_normalized/Stephanie Ford and Kyra Atekwana 2025-09-24 09_31 transcript.json",
    "source_date": "2025-09-24"
  },
  {
    "name": "AI Research Verification Process",
    "type": "process_framework",
    "confidence": 0.88,
    "description": "Two-step approach to using AI tools with validation step to ensure accuracy",
    "components": [
      "Use Gemini to research information",
      "Cross-check AI results for accuracy",
      "Validate information before using"
    ],
    "evidence_quote": "And then I'm, I use Gemini here and there to kind of research something. But you know, but then I'm like, okay, well let me cross check that. Let me see if that's actually correct.",
    "source_transcript": "transcripts_normalized/Stephanie Ford and Kyra Atekwana 2025-09-24 09_31 transcript.json",
    "source_date": "2025-09-24"
  },
  {
    "name": "Email Thread Management Process",
    "type": "process_framework",
    "confidence": 0.9,
    "description": "Workflow for managing complex email threads using AI summarization to maintain context",
    "components": [
      "Get copied on email threads",
      "Use Superhuman to generate thread summaries",
      "Review summaries instead of reading full threads",
      "Extract key information from multi-response conversations"
    ],
    "evidence_quote": "I just recently started using Superhuman for email. So I could see I get a summary of these threads. Sometimes I just get copied on and the threads, before I know it, there's like nine responses. And I'm like, okay, I don't have time to read through all this. So I do use Superhuman for that.",
    "source_transcript": "transcripts_normalized/Stephanie Ford and Kyra Atekwana 2025-09-24 09_31 transcript.json",
    "source_date": "2025-09-24"
  },
  {
    "name": "Upskilling Workshop Development Methodology",
    "type": "process_framework",
    "confidence": 0.93,
    "description": "Discovery-driven approach to designing AI training programs based on user workflows and pain points",
    "components": [
      "Conduct discovery conversations with end users",
      "Understand current workflows",
      "Identify pain points and recurring challenges",
      "Design AI solutions mapped to specific workflows",
      "Build customized workshop content"
    ],
    "evidence_quote": "And really my approach to doing that is have conversations like these so I can understand what are your workflows, what are your pain points, what are the things that trip you up again and again So I can think of ways that AI can better support the work that you're doing.",
    "source_transcript": "transcripts_normalized/Stephanie Ford and Kyra Atekwana 2025-09-24 09_31 transcript.json",
    "source_date": "2025-09-24"
  },
  {
    "name": "Information Control Decision Framework",
    "type": "decision_framework",
    "confidence": 0.87,
    "description": "Logic for evaluating automated scheduling tools based on maintaining context and control over meeting information",
    "components": [
      "If executive sends scheduling link directly, then EA loses meeting context",
      "If EA doesn't have background information, then rescheduling becomes difficult",
      "Therefore, maintain EA involvement in initial scheduling"
    ],
    "evidence_quote": "Like if she were like, oh, here, use this. And then it's like, okay, then I don't have the information. If she were to start, let me say if she were to send someone the link to like schedule a meeting, oh, pop it on my calendar. Then if she wanted me to reschedule it, then I wouldn't even know the background of what the meeting was for.",
    "source_transcript": "transcripts_normalized/Stephanie Ford and Kyra Atekwana 2025-09-24 09_31 transcript.json",
    "source_date": "2025-09-24"
  },
  {
    "name": "Hybrid AI-Human Service Model",
    "type": "model_framework",
    "confidence": 0.88,
    "description": "A two-tiered service approach combining AI automation with human designer support as fallback or enhancement option",
    "components": [
      "AI solution (automated)",
      "Hybrid solution (team of designers)",
      "Security layer (confidentiality emphasis)"
    ],
    "evidence_quote": "it's like you have the AI solution and then you have the hybrid solution. They have this hybrid solution where they have a team of designers who can build slides for you.",
    "source_transcript": "transcripts_normalized/Product Teardown 2025-09-10 16_12 transcript.json",
    "source_date": "2025-09-10"
  },
  {
    "name": "Template-First Onboarding Process",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "A sequential onboarding methodology that establishes brand templates before content creation to avoid reformatting work",
    "components": [
      "Upload brand template (PPTX)",
      "Extract color palette",
      "Validate fonts",
      "Approve layout placement",
      "Confirm color sequence preferences",
      "Confirm font color preferences",
      "Build communication fingerprint"
    ],
    "evidence_quote": "I think you want to do the template first... Because if you do all the entire deck and then have to reformat everything, then that sort of defeats the purpose.",
    "source_transcript": "transcripts_normalized/Product Teardown 2025-09-10 16_12 transcript.json",
    "source_date": "2025-09-10"
  },
  {
    "name": "Content-Then-Format vs Format-Then-Content Decision Framework",
    "type": "decision_framework",
    "confidence": 0.85,
    "description": "Logic for determining optimal workflow sequence in design tools based on efficiency and rework avoidance",
    "components": [
      "If template-first: avoid reformatting entire deck",
      "If content-first: requires template application at end",
      "Decision criterion: minimize rework"
    ],
    "evidence_quote": "Is it better if you do the decks and then put the... Put it into the template or put the template experience? I think you want to do the template first... if you do all the entire deck and then have to reformat everything, then that sort of defeats the purpose.",
    "source_transcript": "transcripts_normalized/Product Teardown 2025-09-10 16_12 transcript.json",
    "source_date": "2025-09-10"
  },
  {
    "name": "Enterprise User Onboarding Scope Framework",
    "type": "scaling_framework",
    "confidence": 0.78,
    "description": "Distinguishes between organization-level setup (done once by admin) versus individual user setup in enterprise context",
    "components": [
      "Organization-level configuration (admin/setup team)",
      "Individual user configuration (optional/limited)",
      "Consideration: manual onboarding vs self-service for enterprise"
    ],
    "evidence_quote": "you wouldn't need every user in the organization to do this... Because it's enterprise, do we want to have, like, an onboarding where somebody actually does this for them?",
    "source_transcript": "transcripts_normalized/Product Teardown 2025-09-10 16_12 transcript.json",
    "source_date": "2025-09-10"
  },
  {
    "name": "AI Automation Pilot Development Framework",
    "type": "process_framework",
    "confidence": 0.95,
    "description": "A phased approach to developing AI automations: identify workflows, build automations, conduct requirements gathering sprint, collect materials, perform deep dives, and pilot",
    "components": [
      "Workflow identification and opportunity assessment",
      "Automation design (3 specific automations)",
      "Requirements gathering sprint (mid-November)",
      "Asynchronous material collection",
      "Deep dive interviews with workflow owners (30-45 minutes)",
      "Pilot execution with internal champions"
    ],
    "evidence_quote": "In order to build these automations effectively and make sure that they deliver on actually improving this workflow, we want to engage in what we're thinking of as a requirements gathering sprint through mid November to capture the different technical specifications that we need to build these custom automations.",
    "source_transcript": "transcripts_normalized/PRD Worflow Automation Kick-off  2025-11-04 16_31 transcript.json",
    "source_date": "2025-11-04"
  },
  {
    "name": "Three-Workflow AI Automation Model",
    "type": "model_framework",
    "confidence": 0.92,
    "description": "A structured model breaking down the PRD process into three distinct workflows for AI augmentation: brief generation, brief evaluation, and PRD creation",
    "components": [
      "Brief generation workflow - standardize varied inputs into notion briefs",
      "Brief evaluation workflow - apply prioritization framework objectively",
      "PRD creation workflow - generate comprehensive PRDs from approved briefs"
    ],
    "evidence_quote": "there were three in particular that we thought would be most ripe for an AI pilot with some sort of an LLM automation, which are the brief generation process and workflow, the brief evaluation workflow, and the PRD creation workflow.",
    "source_transcript": "transcripts_normalized/PRD Worflow Automation Kick-off  2025-11-04 16_31 transcript.json",
    "source_date": "2025-11-04"
  },
  {
    "name": "Requirements Gathering Framework",
    "type": "process_framework",
    "confidence": 0.9,
    "description": "A systematic approach to collecting inputs needed to build effective automations, combining asynchronous material collection with synchronous deep dive sessions",
    "components": [
      "Collect templates and forms",
      "Document decision logic and prioritization framework",
      "Define ideal process flow",
      "Gather completed examples as standards",
      "Conduct deep dive interviews with workflow owners",
      "Understand edge cases and repeatable patterns"
    ],
    "evidence_quote": "So what we need to collect at this point are basically all of the templates and forms that currently exist...the decision logic and prioritization framework around the review process and also an understanding of what an ideal process looks like...And so most of that will be collected via deep dive interviews",
    "source_transcript": "transcripts_normalized/PRD Worflow Automation Kick-off  2025-11-04 16_31 transcript.json",
    "source_date": "2025-11-04"
  },
  {
    "name": "Pilot Scaling Framework - V0 Vibe Coding Adoption",
    "type": "scaling_framework",
    "confidence": 0.85,
    "description": "A strategy to systematize adoption of new capabilities across the team through custom workshops, moving from pilot to team-wide experimentation to eventual workflow redesign",
    "components": [
      "Create custom V0 vibe coding workshop",
      "Systematize v0 adoption across product team",
      "Enable team-wide experimentation and exploration",
      "Lead to future state redesigned workflow"
    ],
    "evidence_quote": "we thought it could be really valuable to actually use this as an opportunity to system. Systematize v0 adoption across the product team and create that Vibe coding capability for everyone, so that there can be that experimentation and exploration that could eventually lead to a new redesigned workflow in some future state.",
    "source_transcript": "transcripts_normalized/PRD Worflow Automation Kick-off  2025-11-04 16_31 transcript.json",
    "source_date": "2025-11-04"
  },
  {
    "name": "Stakeholder Engagement Framework",
    "type": "engagement_framework",
    "confidence": 0.88,
    "description": "A structured approach to engaging internal teams through regular cadence, champions, and collaborative channels",
    "components": [
      "Establish regular meeting cadence",
      "Identify internal champions",
      "Champions help with process details and materials",
      "Champions participate in pilot",
      "Create collaboration channels (e.g., Slack)",
      "Engage workflow owners in deep dive sessions"
    ],
    "evidence_quote": "we'll need the support of your team to establish a regular meeting cadence and also to identify some internal champions. To help us with the process details, with getting all the materials together and then also have them participate in the pilot.",
    "source_transcript": "transcripts_normalized/PRD Worflow Automation Kick-off  2025-11-04 16_31 transcript.json",
    "source_date": "2025-11-04"
  },
  {
    "name": "AI-Human Hybrid Decision Framework",
    "type": "decision_framework",
    "confidence": 0.82,
    "description": "A future-state model where AI performs objective evaluation using standardized frameworks while humans maintain oversight",
    "components": [
      "AI applies prioritization framework objectively",
      "AI provides standardized comparison",
      "Human oversight of AI evaluation",
      "Gradual transition from human-led to AI-assisted decision making"
    ],
    "evidence_quote": "we want to develop a brief evaluator and apply the prioritization framework objectively as a standard for comparison for a potential future in which, you know, AI could potentially be engaged in doing that evaluation and just having a human oversee that process.",
    "source_transcript": "transcripts_normalized/PRD Worflow Automation Kick-off  2025-11-04 16_31 transcript.json",
    "source_date": "2025-11-04"
  },
  {
    "name": "Super Company Transformation Framework",
    "type": "model_framework",
    "confidence": 0.92,
    "description": "A three-mandate framework for AI transformation leads to drive organizational AI adoption, structured around strategic decisions, workforce adoption, and functional roadmaps",
    "components": [
      "Mandate 1: Make three strategic decisions (tool selection/access, governance strategy, AI manifesto)",
      "Mandate 2: Get 80% of employees using AI every week",
      "Mandate 3: Get functional leads to build AI roadmaps and pilot plans"
    ],
    "evidence_quote": "as a transformation lead in your org you have three things you have to do to drive adoption across the organization. You have to one basically get your leaders or yourself to make three strategic decisions that are required to drive adoption... Then the second mandate I'll just go down here is basically get 80% of your employees using AI every week... And then the third mandate, like week four being you have to get the functional leads to build their AI roadmaps and their pilot plans.",
    "source_transcript": "transcripts_normalized/AI Transformation Lead Bootcamp Biweekly Sync 2025-11-18 17_31 transcript.json",
    "source_date": "2025-11-18"
  },
  {
    "name": "Strategic AI Decisions Framework",
    "type": "decision_framework",
    "confidence": 0.9,
    "description": "Three required strategic decisions for driving AI adoption in an organization",
    "components": [
      "Choose a tool and get everyone access to that tool",
      "Figure out your governance strategy",
      "Have a why of AI (AI manifesto)"
    ],
    "evidence_quote": "you need to choose a tool and get everyone access to that tool. You need to figure out your governance strategy. It's basically right here. And then you need to have a why of AI like an AI manifesto.",
    "source_transcript": "transcripts_normalized/AI Transformation Lead Bootcamp Biweekly Sync 2025-11-18 17_31 transcript.json",
    "source_date": "2025-11-18"
  },
  {
    "name": "80% Weekly AI Usage Framework",
    "type": "measurement_framework",
    "confidence": 0.88,
    "description": "A bottoms-up adoption goal framework measuring workforce AI engagement with supporting best practices",
    "components": [
      "Continuously certifying people",
      "Surfacing use cases",
      "Modeling behavior from the top",
      "Having champions programs"
    ],
    "evidence_quote": "get 80% of your employees using AI every week. So like that bottoms up goal... we would talk about like continuously certifying people, surfacing the use cases... modeling the behavior from the top having champions programs. Like a lot of the recommendations you guys would make usually, but kind of like as the best practices.",
    "source_transcript": "transcripts_normalized/AI Transformation Lead Bootcamp Biweekly Sync 2025-11-18 17_31 transcript.json",
    "source_date": "2025-11-18"
  },
  {
    "name": "Six-Week Bootcamp Curriculum Framework",
    "type": "process_framework",
    "confidence": 0.85,
    "description": "A structured six-week program for training AI transformation leads, progressing from strategy to execution with a capstone",
    "components": [
      "Week 1: Super company foundations and transformation mandate overview",
      "Week 2: Strategic decisions (tool, governance, manifesto)",
      "Week 3: Driving 80% workforce adoption",
      "Week 4: Building functional AI roadmaps and pilots",
      "Week 5: Implementation processes",
      "Week 6: Capstone project"
    ],
    "evidence_quote": "So that's kind of. We had originally scoped that as six. This is six weeks with the last week being the capstone.",
    "source_transcript": "transcripts_normalized/AI Transformation Lead Bootcamp Biweekly Sync 2025-11-18 17_31 transcript.json",
    "source_date": "2025-11-18"
  },
  {
    "name": "Functional Leader Enablement Framework",
    "type": "engagement_framework",
    "confidence": 0.87,
    "description": "A two-part framework for transformation leads to enable functional leaders to drive AI adoption in their departments",
    "components": [
      "What functional leaders need to do to identify AI opportunities",
      "What enablement leads need to do to run the process",
      "Templates for green light process and intake forms"
    ],
    "evidence_quote": "we need to teach them what they need the functional leaders to do to identify the ideas. And then what they need to do is the enablement lead to run the process... it's almost like some of the assets they could get to. Like, here's a template for what the green light process, the intake form looks like",
    "source_transcript": "transcripts_normalized/AI Transformation Lead Bootcamp Biweekly Sync 2025-11-18 17_31 transcript.json",
    "source_date": "2025-11-18"
  },
  {
    "name": "AI-Assisted Deck Creation Process",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "A multi-stage process for creating presentation decks using AI assistance, moving from intent definition through outline generation to slide content creation",
    "components": [
      "Define intent (inform/persuade/recommend)",
      "Describe key message",
      "AI selects appropriate framework",
      "Generate/review outline (action titles)",
      "Refine outline with AI collaboration",
      "Generate slide content/skeleton deck"
    ],
    "evidence_quote": "So they try to describe intent... When they send the key message, I think the AI will actually pick the framework for them or pick the thing and the next step is actually showing the outline... AI will give you the draft of the outline and then you work with AI to hone that in and... once you have the outline developed, then the next thing is then AI generates the actual slide content",
    "source_transcript": "transcripts_normalized/DS Meeting 2025-09-17 18_01 transcript.json",
    "source_date": "2025-09-17"
  },
  {
    "name": "Template-Based Deck Categorization Model",
    "type": "model_framework",
    "confidence": 0.85,
    "description": "A conceptual model distinguishing between different types of business decks with different structural requirements",
    "components": [
      "Pitch decks (go-to-market)",
      "Investor relations decks (organizational updates)",
      "Templated decks (following consistent structure)",
      "Untemplated decks (variable structure)"
    ],
    "evidence_quote": "This pitch deck in this instance is assuming you're going to market. This is like I'm an organization and functioning. I'm giving my investors update or I'm trying to get more investors to invest in me... at least for ours, we follow the same template every time",
    "source_transcript": "transcripts_normalized/DS Meeting 2025-09-17 18_01 transcript.json",
    "source_date": "2025-09-17"
  },
  {
    "name": "Framework Auto-Selection Decision Logic",
    "type": "decision_framework",
    "confidence": 0.88,
    "description": "AI-driven logic that automatically selects the appropriate presentation framework based on user intent and key message rather than manual selection",
    "components": [
      "Analyze user intent and key message",
      "Match to appropriate framework (e.g., recommendation framework)",
      "Auto-apply without user framework selection step"
    ],
    "evidence_quote": "I don't think that's something that they need to do as a step. I think that that's something internal. That's a best practice based on the content, like based on the intent and like the key message that it shares. Like it should be able to be like, oh, what you're doing is sharing a recommendation. So it should follow a recommendation framework as opposed to having a step where they're like do you want pyramid or X?",
    "source_transcript": "transcripts_normalized/DS Meeting 2025-09-17 18_01 transcript.json",
    "source_date": "2025-09-17"
  },
  {
    "name": "Outline-to-Slides Two-Stage Model",
    "type": "process_framework",
    "confidence": 0.9,
    "description": "A staged approach separating outline development from slide content generation, with human-AI collaboration at the outline stage",
    "components": [
      "Stage 1: Outline development (action titles only)",
      "Collaborative refinement between human and AI",
      "Stage 2: Slide content generation based on finalized outline"
    ],
    "evidence_quote": "I think that we should have an intermediary step where you work on the titles and you like you're working on your outline basically. Because AI will give you the draft of the outline and then you work with AI to hone that in... once you have the outline developed, then the next thing is then AI generates the actual slide content",
    "source_transcript": "transcripts_normalized/DS Meeting 2025-09-17 18_01 transcript.json",
    "source_date": "2025-09-17"
  },
  {
    "name": "Enterprise Data Integration Requirement",
    "type": "model_framework",
    "confidence": 0.87,
    "description": "Recognition that enterprise decks require company-specific data integration that AI cannot generate independently",
    "components": [
      "Company-specific information (people, data, metrics)",
      "Data feeding requirement for AI",
      "Content that cannot be 'pulled out of the hat'"
    ],
    "evidence_quote": "This is the type of things you've seen on Enterprise, right, that are very peculiar to that company... The things on this slide, as you can see here, are actual information that you can't pull this out of the hat. You have to feed the AI what to say",
    "source_transcript": "transcripts_normalized/DS Meeting 2025-09-17 18_01 transcript.json",
    "source_date": "2025-09-17"
  },
  {
    "name": "AI for Leaders Workshop Structure",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "A sequential workshop methodology for teaching AI usage to leadership, progressing from conceptual understanding to practical features",
    "components": [
      "Introduction to AI augmentation and multiplying leader impact",
      "Framework for human-AI collaboration (AI as thought partner, not outsourcing thinking)",
      "Getting started in Copilot (reasoning models and personalization)",
      "Leadership-specific features (agents, advanced reasoning, notebooks, projects)"
    ],
    "evidence_quote": "So we start with an introduction of the concept of AI, but really focused on AI augmentation... And then we get into how to get started in copilot... And then we also focus on features that are built for leadership and thought partnerships such as the agents that built into copilot advanced reasoning and thinking through those models and then notebooks and projects.",
    "source_transcript": "transcripts_normalized/Havas x Section Connect 2025-11-06 11_33 transcript.json",
    "source_date": "2025-11-06"
  },
  {
    "name": "Human-AI Collaboration Model",
    "type": "model_framework",
    "confidence": 0.88,
    "description": "A conceptual model positioning AI as a thought process partner rather than a replacement for human thinking",
    "components": [
      "AI as thought process partner",
      "Human retains thinking ownership",
      "Collaborative augmentation approach",
      "Top-down leadership example setting"
    ],
    "evidence_quote": "Because at section we really believe that it's important to use AI as your thought process partner as opposed to outsourcing your thinking to AI... it really should be top down examples in terms of what proper AI usage looks like and establishing this framework for human AI collaboration.",
    "source_transcript": "transcripts_normalized/Havas x Section Connect 2025-11-06 11_33 transcript.json",
    "source_date": "2025-11-06"
  },
  {
    "name": "LLM Portal Access Gating",
    "type": "decision_framework",
    "confidence": 0.85,
    "description": "A decision logic for controlling access to AI tools through certification requirements",
    "components": [
      "Certification requirement as access gate",
      "Prof. AI certification as prerequisite",
      "Portal access granted post-certification"
    ],
    "evidence_quote": "To access the LLM portal. We will have as a gate the certification in Prof. AI.",
    "source_transcript": "transcripts_normalized/Havas x Section Connect 2025-11-06 11_33 transcript.json",
    "source_date": "2025-11-06"
  },
  {
    "name": "Client Engagement Operating Model",
    "type": "engagement_framework",
    "confidence": 0.9,
    "description": "A structured approach for managing client engagements with defined roles and touchpoints",
    "components": [
      "Team introductions and role clarity upfront",
      "Survey and data analyst support (Taylor)",
      "Workshop development and delivery lead (Kyra)",
      "Customer Operations/Project Manager coordination (Chloe)",
      "Regular progress check-ins on critical action items"
    ],
    "evidence_quote": "I'm the customer Operations manager here at Section. So really, for the purpose of our engagement, I'll be acting as that project manager piece, just keeping you in the loop of everything going on. I'll be working really closely with Allie Louise, Kyra and Taylor, as well as our internal folks... we'll kind of get into how. Different ways of working, what you can expect throughout our engagement.",
    "source_transcript": "transcripts_normalized/Havas x Section Connect 2025-11-06 11_33 transcript.json",
    "source_date": "2025-11-06"
  },
  {
    "name": "Three-Step AI Use Case Evaluation Process",
    "type": "process_framework",
    "confidence": 0.98,
    "description": "A systematic three-phase approach for identifying, evaluating, and prioritizing AI use cases across an organization",
    "components": [
      "Step 1: High-level review of compiled use cases (existing AI solutions + new ideas) to ensure completeness",
      "Step 2: Evaluate use cases by potential impact (high/medium/low) considering efficiency gains and quality improvements, identify roadblocks and enablers",
      "Step 3: Align on top 3-5 needle movers for execution"
    ],
    "evidence_quote": "there's three main steps to this session. First, we're going to take a high level view of the list of use cases that we shared... The second step, which is what we asked you guys to take a pass at before, is to evaluate all the use cases based on their potential impact... And then at the end we'll just wrap up and make sure we're all aligned on what are the big needle movers across this whole list? What are those top three to five things that we want to go ahead and execute on",
    "source_transcript": "transcripts_normalized/FW_ Core Connect AI Discovery & Prioritization Session 2025-08-08 08_00 transcript.json",
    "source_date": "2025-08-08"
  },
  {
    "name": "AI Use Case Impact Assessment Framework",
    "type": "measurement_framework",
    "confidence": 0.92,
    "description": "A dual-criteria framework for evaluating the potential impact of AI use cases based on efficiency and quality dimensions",
    "components": [
      "Efficiency potential: measure reduction in workload and time",
      "Quality improvement potential: improvements not possible without AI",
      "Impact categorization: classify as high, medium, or low impact"
    ],
    "evidence_quote": "if we were to split this list into high, medium and low impact, which ones would be bubbling at the top and then why? So do we think this use case has a high efficiency potential, like it'll reduce the workload and the time it takes to do things today, or do we think that this use case has the potential to improve the quality in a way that is kind of not possible if we didn't have an AI tool",
    "source_transcript": "transcripts_normalized/FW_ Core Connect AI Discovery & Prioritization Session 2025-08-08 08_00 transcript.json",
    "source_date": "2025-08-08"
  },
  {
    "name": "AI Adoption Roadblock Identification Framework",
    "type": "decision_framework",
    "confidence": 0.85,
    "description": "A structured approach to identify barriers and prerequisites for successful AI implementation",
    "components": [
      "Identify key enablers required to drive adoption",
      "Identify systematic changes needed for solution implementation"
    ],
    "evidence_quote": "We'd also want to know if there's any roadblocks, like do we think there's key enablers to drive adoption for some of these use cases or key systematic things that need to change in order to find the solution?",
    "source_transcript": "transcripts_normalized/FW_ Core Connect AI Discovery & Prioritization Session 2025-08-08 08_00 transcript.json",
    "source_date": "2025-08-08"
  },
  {
    "name": "AI Tool Implementation and Scaling Process",
    "type": "scaling_framework",
    "confidence": 0.9,
    "description": "A phased approach for moving from use case prioritization to production implementation of AI tools",
    "components": [
      "Research suitable AI tools for top 3-5 use cases",
      "Develop testing plan",
      "Execute pilot program",
      "Track KPIs",
      "Validate tools enhance workflows"
    ],
    "evidence_quote": "we're going to start researching like suitable AI tools, obviously focusing on these top three to five use cases and then coming up with a plan for testing, piloting, tracking KPIs and making sure that the tools are serving the needs and enhancing the workflows as we know them today",
    "source_transcript": "transcripts_normalized/FW_ Core Connect AI Discovery & Prioritization Session 2025-08-08 08_00 transcript.json",
    "source_date": "2025-08-08"
  },
  {
    "name": "Functional Group Engagement Structure",
    "type": "engagement_framework",
    "confidence": 0.88,
    "description": "An organizational approach to conducting AI discovery sessions across different functional groups while enabling cross-functional collaboration",
    "components": [
      "Conduct one-on-one discovery sessions by function",
      "Group similar functions into consolidated sessions",
      "Enable cross-functional use case and tool sharing",
      "Identify AI champions for each function",
      "Create connections between related functional groups (e.g., all product teams)"
    ],
    "evidence_quote": "we've tried to group these sessions in as logical as possible. So we think about it as like high level function sessions, one for hr, for legal, for supply chain... our goal is to also enable like cross functional use cases and tool sharing because I think that's going to be really beneficial to drive adoption at a greater scale... we do have AI champions identified for each function",
    "source_transcript": "transcripts_normalized/FW_ Core Connect AI Discovery & Prioritization Session 2025-08-08 08_00 transcript.json",
    "source_date": "2025-08-08"
  },
  {
    "name": "Three-Step Workshop Development Process",
    "type": "process_framework",
    "confidence": 0.98,
    "description": "A structured methodology for developing customized workshops that progresses from understanding needs to designing structure to creating final content",
    "components": [
      "Discovery and Research",
      "Workshop Design and Structure",
      "Content Development"
    ],
    "evidence_quote": "So we have a three step process that we do for developing these workshops that start with discovery and research and then we go into the actual workshop design and structure, which is where we get some feedback and then finally complete the content development process.",
    "source_transcript": "transcripts_normalized/DoorDash x Section Workshop Alignment  2025-09-12 08_31 transcript.json",
    "source_date": "2025-09-12"
  },
  {
    "name": "Discovery and Research Framework",
    "type": "process_framework",
    "confidence": 0.95,
    "description": "A multi-component discovery approach that includes aligning on objectives, conducting stakeholder interviews, integrating existing work, and researching team functions",
    "components": [
      "Align on learning objectives",
      "Conduct stakeholder interviews with team leads",
      "Integrate existing workflow audit work",
      "Research sub-functions of the team"
    ],
    "evidence_quote": "So, in discovery and research side, what we want to do today is make sure that we align on what the learning objectives are. And then also as part of this, due to the customization and the nature of this, we're going to do just probably a couple of stakeholder interviews, if we can, with the team leads... And then we'll also be integrating some of that existing work that you've done with the workflow audits",
    "source_transcript": "transcripts_normalized/DoorDash x Section Workshop Alignment  2025-09-12 08_31 transcript.json",
    "source_date": "2025-09-12"
  },
  {
    "name": "50/50 Workshop Structure Model",
    "type": "model_framework",
    "confidence": 0.92,
    "description": "A balanced workshop format that splits time equally between learning conceptual content and practical application through exercises",
    "components": [
      "50% Content Delivery (how to find AI use cases)",
      "50% Practical Application (finding use cases and creating prompt library with breakout exercises)"
    ],
    "evidence_quote": "And I know we want to have sort of a 5050 format for this one, being 50% the content of how to find their AI use case. So for that first hour and then probably about another hour actually then finding your use case and creating your prompt library where we'll have some breakout exercises for them",
    "source_transcript": "transcripts_normalized/DoorDash x Section Workshop Alignment  2025-09-12 08_31 transcript.json",
    "source_date": "2025-09-12"
  },
  {
    "name": "AI Adoption Role Framework",
    "type": "model_framework",
    "confidence": 0.9,
    "description": "A three-part role model for leading organizational AI adoption that combines education, motivation, and support",
    "components": [
      "Educator (teaching and informing)",
      "Cheerleader (motivating and encouraging)",
      "Therapist (addressing concerns and resistance)"
    ],
    "evidence_quote": "I think of myself as sort of an educator, a cheerleader, and then a little bit of a therapist. But I think we're getting past the therapy part, which is good.",
    "source_transcript": "transcripts_normalized/DoorDash x Section Workshop Alignment  2025-09-12 08_31 transcript.json",
    "source_date": "2025-09-12"
  },
  {
    "name": "Feedback-Driven Design Framework",
    "type": "process_framework",
    "confidence": 0.88,
    "description": "A validation approach that creates an outline and obtains stakeholder approval before proceeding to full content development",
    "components": [
      "Create workshop outline",
      "Get client feedback on outline",
      "Proceed to full content development only after approval"
    ],
    "evidence_quote": "we'll also create an outline of this entire thing and get your feedback on it before we actually go into the content development.",
    "source_transcript": "transcripts_normalized/DoorDash x Section Workshop Alignment  2025-09-12 08_31 transcript.json",
    "source_date": "2025-09-12"
  },
  {
    "name": "Stakeholder Engagement Framework",
    "type": "engagement_framework",
    "confidence": 0.87,
    "description": "A targeted approach to understanding stakeholder needs through interviews with key team leads to ensure content customization",
    "components": [
      "Identify team leads as key stakeholders",
      "Conduct stakeholder interviews to understand backgrounds",
      "Use insights to customize content appropriately"
    ],
    "evidence_quote": "we're going to do just probably a couple of stakeholder interviews, if we can, with the team leads. Just make sure we understand their backgrounds and where they're coming from so we can make sure that the content is sufficiently customized for them.",
    "source_transcript": "transcripts_normalized/DoorDash x Section Workshop Alignment  2025-09-12 08_31 transcript.json",
    "source_date": "2025-09-12"
  },
  {
    "name": "AI Adoption Maturity Model",
    "type": "model_framework",
    "confidence": 0.88,
    "description": "A progression model for AI usage maturity, from basic operational use to advanced automation and custom solutions",
    "components": [
      "Level 1: Operational efficiency - Using AI for small tasks and workflow optimization",
      "Level 2: Tool exploration - Experimenting with off-the-shelf AI tools",
      "Level 3: Process automation - Building custom GPTs and automating end-to-end workflows",
      "Level 4: Strategic implementation - Leading team-wide AI initiatives and process improvements"
    ],
    "evidence_quote": "Steven: 'I use it right now from a more operational perspective of like hey how do I do small tasks faster...I wouldn't say I have gone deep enough to say try to automate a workflow end to end' | Maha: 'We have also identified some processes which we want to get more efficient...My team has been leading building custom GPTs...trying to dabble with tools'",
    "source_transcript": "transcripts_normalized/Marketing Offsite AI Workshop - Paid Media 2025-09-23 15_00 transcript.json",
    "source_date": "2025-09-23"
  },
  {
    "name": "AI Use Case Discovery Framework",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "Section's structured approach to identifying and implementing AI use cases within teams through workshop methodology",
    "components": [
      "Step 1: Pre-workshop workflow mapping - Document existing team workflows",
      "Step 2: Use case identification - Identify opportunities within workflows",
      "Step 3: Deep-dive session - Understand specific use cases and team goals",
      "Step 4: Workshop implementation - Conduct hands-on training and implementation",
      "Step 5: Team enablement - Apply learnings to specific teams"
    ],
    "evidence_quote": "Kyra: 'Really wanted to use this session to just dig a little bit deeper into understanding the use cases that you came up with during those workflow sessions and then also what you see as the opportunities for your team and then third, what you really would want to get out of the session for both yourselves and your teams'",
    "source_transcript": "transcripts_normalized/Marketing Offsite AI Workshop - Paid Media 2025-09-23 15_00 transcript.json",
    "source_date": "2025-09-23"
  },
  {
    "name": "AI Workflow Integration Pattern",
    "type": "process_framework",
    "confidence": 0.85,
    "description": "A common pattern for integrating AI into knowledge work, specifically for documentation and synthesis tasks",
    "components": [
      "Step 1: Capture - Use AI note-takers in meetings to transcribe conversations",
      "Step 2: Synthesize - Process meeting notes into structured outputs",
      "Step 3: Generate - Use AI to assist with document writing and updates",
      "Step 4: Iterate - Overcome creative blocks with AI assistance"
    ],
    "evidence_quote": "Monica: 'I find AI very helpful is like, and meetings. So like helping me to take notes and actually then using those notes to synthesize like, updates to synthesize like and feed into like my document writing. That's been really helpful because it actually speeds up the process'",
    "source_transcript": "transcripts_normalized/Marketing Offsite AI Workshop - Paid Media 2025-09-23 15_00 transcript.json",
    "source_date": "2025-09-23"
  },
  {
    "name": "AI Skill Self-Assessment Framework",
    "type": "measurement_framework",
    "confidence": 0.79,
    "description": "An implicit categorization system for assessing individual AI proficiency levels",
    "components": [
      "Basic user - Using AI for operational tasks and small optimizations",
      "Intermediate user - Experimenting with multiple tools and exploring automation opportunities",
      "Advanced user - Building custom solutions and leading team implementation"
    ],
    "evidence_quote": "Kyra: 'How you would categorize yourself in terms of your experience with AI' | Maha: 'Maybe an intermediate I would say somewhere like of trying to dabble with tools'",
    "source_transcript": "transcripts_normalized/Marketing Offsite AI Workshop - Paid Media 2025-09-23 15_00 transcript.json",
    "source_date": "2025-09-23"
  },
  {
    "name": "Task-Level AI Implementation Approach",
    "type": "process_framework",
    "confidence": 0.81,
    "description": "A practical approach to AI adoption that focuses on optimizing specific tasks before attempting end-to-end automation",
    "components": [
      "Phase 1: Identify discrete tasks within workflows",
      "Phase 2: Apply AI to individual task optimization",
      "Phase 3: Create templates and standardization",
      "Phase 4: Progress toward end-to-end workflow automation"
    ],
    "evidence_quote": "Steven: 'It's more like taking bits and pieces and figuring out how to optimize it whether it's stock writing, templatization, anything of that nature...I wouldn't say I have gone deep enough to say try to automate a workflow end to end'",
    "source_transcript": "transcripts_normalized/Marketing Offsite AI Workshop - Paid Media 2025-09-23 15_00 transcript.json",
    "source_date": "2025-09-23"
  },
  {
    "name": "AI Use Case Discovery and Implementation Framework",
    "type": "process_framework",
    "confidence": 0.98,
    "description": "A three-step methodology for identifying, evaluating, and prioritizing AI use cases within product teams, followed by tool selection and pilot testing",
    "components": [
      "Step 1: Review and align on all potential AI use cases for the product side",
      "Step 2: Evaluate use cases with lens of impact nature (quality enhancement, efficiency improvement) and identify adoption roadblocks",
      "Step 3: Prioritize 3-5 use cases with greatest potential impact",
      "Step 4: Research and identify potential tools (vendor solutions or internal builds)",
      "Step 5: Design and execute pilots at appropriate scale",
      "Step 6: Roll out to full launch"
    ],
    "evidence_quote": "The first is to just review and make sure we're aligned on all the potential use cases for AI... We'll then want to, as a team, evaluate all the use cases, starting with the highest impact ones... And then the main output that we want from this meeting is to have a list of use cases based on the greatest potential for the team for AI impact... we'll probably circle back internally and start researching what are potential tools... And eventually we'll want to start piloting and testing these",
    "source_transcript": "transcripts_normalized/AI Discovery and Prioritization Session - E&C Product 2025-08-06 09_01 transcript.json",
    "source_date": "2025-08-06"
  },
  {
    "name": "AI Impact Evaluation Framework",
    "type": "measurement_framework",
    "confidence": 0.92,
    "description": "A multi-dimensional framework for evaluating AI opportunities based on impact type and implementation feasibility",
    "components": [
      "Impact level assessment (high vs lower priority)",
      "Nature of impact: quality enhancement",
      "Nature of impact: efficiency improvement (speed)",
      "Roadblock identification",
      "Adoption requirements assessment"
    ],
    "evidence_quote": "we'll then want to, as a team, evaluate all the use cases, starting with the highest impact ones and make sure that we evaluate them with a lens of what is the nature of this impact. So if we think an opportunity is high impact for a team, do we think that it's because it's going to enhance the quality, improve efficiency, so make people work a lot faster. And if there's any roadblocks. Or anything that we think is needed to drive adoption",
    "source_transcript": "transcripts_normalized/AI Discovery and Prioritization Session - E&C Product 2025-08-06 09_01 transcript.json",
    "source_date": "2025-08-06"
  },
  {
    "name": "AI Tool Sourcing Decision Framework",
    "type": "decision_framework",
    "confidence": 0.88,
    "description": "A decision logic for determining whether to use vendor solutions versus internal builds for AI implementation",
    "components": [
      "Vendor/known tool optimization path (e.g., Gamma, Figma)",
      "Internal build path (agents, engineering solutions)",
      "Decision criteria based on use case requirements"
    ],
    "evidence_quote": "This will vary a lot. Sometimes it's working with a vendor or a known tool like Gamma or figma and like improving the utilization of those tools. Sometimes it's building something internally like creating agents or working with the engineers to try to create solutions",
    "source_transcript": "transcripts_normalized/AI Discovery and Prioritization Session - E&C Product 2025-08-06 09_01 transcript.json",
    "source_date": "2025-08-06"
  },
  {
    "name": "AI Pilot Scaling Framework",
    "type": "scaling_framework",
    "confidence": 0.85,
    "description": "A framework for scaling AI solutions from pilot testing to full production launch with considerations for scale size",
    "components": [
      "Pilot/test design phase",
      "Scale determination (small-scale vs larger-scale)",
      "Full launch rollout"
    ],
    "evidence_quote": "And eventually we'll want to start piloting and testing these. So we'll also start thinking through the process of what a pilot or a test should look like, whether it should be small scale, larger scale, and how we can then roll it out to a full launch",
    "source_transcript": "transcripts_normalized/AI Discovery and Prioritization Session - E&C Product 2025-08-06 09_01 transcript.json",
    "source_date": "2025-08-06"
  },
  {
    "name": "Vibe Code Tool Selection Framework",
    "type": "decision_framework",
    "confidence": 0.9,
    "description": "A dual-track decision framework for selecting AI coding tools based on use case: non-IDE tools for prototyping and IDE tools for production deployment",
    "components": [
      "Non-IDE track: for rapid prototyping (not production deployment)",
      "IDE track: for design, product, and engineering collaboration on production assets",
      "Vendor evaluation: multiple options per track with winnowing process",
      "Specific tools evaluated: Lovable and v0 (non-IDE), Cursor or Claude Co (IDE)"
    ],
    "evidence_quote": "3 with the getting down to 2 like 1 is a non ID, so not something that would deploy into production... Rapid prototyping and then the IDE is one where design and product engineering would leverage the same software like Cursor or Claude Co and that allows us to actually like work on the same assets",
    "source_transcript": "transcripts_normalized/AI Discovery and Prioritization Session - E&C Product 2025-08-06 09_01 transcript.json",
    "source_date": "2025-08-06"
  },
  {
    "name": "AI Workshop Training Structure",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "A structured 180-minute workshop methodology broken into sequential segments: introduction/policy review, workflow demonstrations with activities, and a final hands-on activation exercise",
    "components": [
      "Welcome and introduction (60 minutes) - policy review, tool features, responsible AI overview",
      "Workflow review with embedded activities - three specific workflows with use cases",
      "Extended activation activity - longer hands-on practice session"
    ],
    "evidence_quote": "So the first 60 minutes is really spent reviewing, you know, have the welcome and introduction set the expectations and we'll, we'll review the policy, key features of the tools that people have access to and then some overview of how they should be using AI responsibly. Before we go into the actual workflows, we have those three workflows that we identify that we'll be talking about some specific use cases within each workflow that will be supportive for their AI journey. And then within those, we have activities that are throughout each of the workflows. Before we go into our longer activate activity section",
    "source_transcript": "transcripts_normalized/Review Section AI Workshop Materials 2025-09-15 16_01 transcript.json",
    "source_date": "2025-09-15"
  },
  {
    "name": "Workshop Delivery Engagement Model",
    "type": "engagement_framework",
    "confidence": 0.88,
    "description": "A dual-facilitator approach where a primary facilitator leads content delivery while a supporting facilitator manages activities and participant engagement",
    "components": [
      "Primary facilitator (Tani) - leads slides and main content",
      "Support facilitator (Mary) - assists with activities, monitors chat, handles questions",
      "Pre-briefing session - stakeholder alignment meeting before delivery"
    ],
    "evidence_quote": "Yeah, so Tani's gonna lead most of the slides that are here, and then I'm gonna be there with her to support in some of the activities. So that way she can kind of take a break and, and address questions in chat and all of that.",
    "source_transcript": "transcripts_normalized/Review Section AI Workshop Materials 2025-09-15 16_01 transcript.json",
    "source_date": "2025-09-15"
  },
  {
    "name": "Workshop Preparation Protocol",
    "type": "process_framework",
    "confidence": 0.85,
    "description": "A pre-workshop coordination process involving dry runs, use case collection, stakeholder briefings, and facilitator alignment sessions",
    "components": [
      "Collect use cases from stakeholders",
      "Schedule dry run presentation",
      "Brief facilitators on organizational context",
      "Conduct stakeholder alignment call (15 minutes)"
    ],
    "evidence_quote": "I've sent over the use cases from. From Joyce and for Matt... tomorrow we have a dry run and Marcella has her five... If you all have the time, I'm sure she would love, you know, 15 minutes or so to just get your insights on what you all are looking for. We've briefed her on, you know, all of the conversations we've had so far, but an additional touch point is always welcome.",
    "source_transcript": "transcripts_normalized/Review Section AI Workshop Materials 2025-09-15 16_01 transcript.json",
    "source_date": "2025-09-15"
  },
  {
    "name": "Section AI Workshop Development Playbook",
    "type": "process_framework",
    "confidence": 0.85,
    "description": "A repeatable methodology for creating AI workshops and curriculum at Section, developed through iterative learning during rapid organizational growth",
    "components": [
      "Curriculum development",
      "Workshop creation process",
      "Educational frameworks for AI"
    ],
    "evidence_quote": "I was leading all of the development around the curriculum of AI. So develop the current frameworks that we have and pretty much the playbook for how we create workshops at Section",
    "source_transcript": "transcripts_normalized/Sandra Noonan __ Kyra (Section) 2025-08-26 20_31 transcript.json",
    "source_date": "2025-08-26"
  },
  {
    "name": "Two-Stage AI Adoption Framework",
    "type": "model_framework",
    "confidence": 0.9,
    "description": "A conceptual model separating AI adoption into two distinct phases: initial upskilling followed by workflow integration",
    "components": [
      "Stage 1: Upskilling (learning AI capabilities)",
      "Stage 2: Workflow redesign (embedding AI into daily work)"
    ],
    "evidence_quote": "teaching people the next step after upskilling, which is like, okay, how do you actually apply this to your work and actually change the way that you're doing things so that you're not just going to AI every once in a while, but having it deeply embedded in the work that you do",
    "source_transcript": "transcripts_normalized/Sandra Noonan __ Kyra (Section) 2025-08-26 20_31 transcript.json",
    "source_date": "2025-08-26"
  },
  {
    "name": "AI Workflow Automation Assessment Framework",
    "type": "decision_framework",
    "confidence": 0.92,
    "description": "A framework for analyzing organizational workflows to identify which are most suitable for AI automation",
    "components": [
      "Workflow breakdown analysis",
      "Readiness assessment",
      "Automation suitability scoring"
    ],
    "evidence_quote": "there was a great framework, maybe it was developed by you, but it was this PDF on how to break down an organization's workflows and identify those that are most ready and lend themselves to AI automation",
    "source_transcript": "transcripts_normalized/Sandra Noonan __ Kyra (Section) 2025-08-26 20_31 transcript.json",
    "source_date": "2025-08-26"
  },
  {
    "name": "Transcript Analysis for Pain Point Identification",
    "type": "process_framework",
    "confidence": 0.88,
    "description": "A systematic approach to analyzing stakeholder interviews to identify automation opportunities",
    "components": [
      "Initial transcript review",
      "Context setting with AI tool",
      "Pain point identification prompting",
      "Workflow parsing",
      "Framework-guided prioritization"
    ],
    "evidence_quote": "copied and pasted them into ChatGPT... inserted a prompt that provided context on what they were, what the goal of the exercise was... my first prompt was something to the effect of read these transcripts, understand what each of the stakeholders is saying, and then did a series of other prompts asking it to identify common pain points",
    "source_transcript": "transcripts_normalized/Sandra Noonan __ Kyra (Section) 2025-08-26 20_31 transcript.json",
    "source_date": "2025-08-26"
  },
  {
    "name": "AI Transformation Insertion Strategy",
    "type": "engagement_framework",
    "confidence": 0.87,
    "description": "A grassroots approach to driving AI adoption in organizations resistant to technology change",
    "components": [
      "Individual workflow transformation",
      "Tool building for team use",
      "Advisory role on rollout",
      "Use case development",
      "Colleague training"
    ],
    "evidence_quote": "I've essentially turned everything I touch into an AI workflow and have inserted myself into the AI transformation there... I've joined, I've helped shape AI transformation team. I was on the enterprise trial of ChatGPT, I advised on the rollout, I developed use cases... I spend a lot of my time training my colleagues",
    "source_transcript": "transcripts_normalized/Sandra Noonan __ Kyra (Section) 2025-08-26 20_31 transcript.json",
    "source_date": "2025-08-26"
  },
  {
    "name": "Framework-Augmented AI Analysis Method",
    "type": "process_framework",
    "confidence": 0.91,
    "description": "A methodology for enhancing AI analysis by uploading existing frameworks to guide the LLM's evaluation process",
    "components": [
      "Upload reference framework to LLM",
      "Instruct AI to apply framework lens",
      "Analyze source material through framework",
      "Generate framework-aligned outputs"
    ],
    "evidence_quote": "I uploaded the PDF to the LLM and I said, listen, this is the framework I want you to be taking into account as we analyze these transcripts together",
    "source_transcript": "transcripts_normalized/Sandra Noonan __ Kyra (Section) 2025-08-26 20_31 transcript.json",
    "source_date": "2025-08-26"
  },
  {
    "name": "AI Workflow Redesign Process",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "A sequential methodology for identifying, prioritizing, and implementing AI solutions across organizational functions",
    "components": [
      "Function-by-function interviews to identify current AI use and potential use cases",
      "Collection of use cases across functions",
      "Prioritization sessions to select top 3-5 use cases per function",
      "Tool identification and solutioning phase",
      "Pilot implementation"
    ],
    "evidence_quote": "I've had a lot of those early conversations on where they're using AI today, where their heaviest lift or potential for most impact from AI is. And so we're kind of collecting use cases... our next steps coming up here, we have some meetings with some teams in the functions to kind of go through the long list of use cases we've collected for each and try to prioritize those and say, hey, what are the top three five plus use cases that are ones we'd like to pilot first? And then from there we'll go in and start looking for tools to solve that.",
    "source_transcript": "transcripts_normalized/Asurion x Section 2025-07-24 12_37 transcript.json",
    "source_date": "2025-07-24"
  },
  {
    "name": "AI Adoption Engagement Framework",
    "type": "engagement_framework",
    "confidence": 0.88,
    "description": "A structured approach to onboard and engage employees with AI tools through hands-on experience and education",
    "components": [
      "Non-work related AI activities to build familiarity",
      "Hands-on tool exposure during events",
      "Introduction to AI content/video training",
      "Tester group rollout before broader deployment"
    ],
    "evidence_quote": "heard some like fun ideas of like non work related ways to get people using AI and so I think that would be great like when we do get to event planning and things like that, just like get people in the tools right away",
    "source_transcript": "transcripts_normalized/Asurion x Section 2025-07-24 12_37 transcript.json",
    "source_date": "2025-07-24"
  },
  {
    "name": "Consultant Handoff Decision Framework",
    "type": "decision_framework",
    "confidence": 0.85,
    "description": "Logic for determining when and how to engage external consultants in the workflow redesign process",
    "components": [
      "If long list of use cases exists: consultants help prioritize together",
      "If prioritized list exists: consultants work on specific workflows",
      "Consultants participate in initial prioritization sessions",
      "Define clear function focus for consultant engagement"
    ],
    "evidence_quote": "I think for us, it would be a great scenario to have a function to focus on, and it could be a long list of use cases that we prioritize together. Or it could be... maybe you just tell us these are the five workflows we want you to work on... I think we were kind of landing on. We'd definitely like you at least early on in some of these prioritization sessions",
    "source_transcript": "transcripts_normalized/Asurion x Section 2025-07-24 12_37 transcript.json",
    "source_date": "2025-07-24"
  },
  {
    "name": "Function-Agnostic Workflow Redesign Model",
    "type": "model_framework",
    "confidence": 0.87,
    "description": "A consultant approach that focuses on universal workflow augmentation and automation patterns regardless of specific team, function, or industry",
    "components": [
      "Knowledge worker workflow analysis",
      "Use case identification through interviews",
      "Industry and function agnostic pattern recognition",
      "AI augmentation and automation opportunities",
      "Workflow solutions design"
    ],
    "evidence_quote": "I have a lot of experience with supporting knowledge workers and augmenting and automating their workflows with AI. Conducted scores of interviews at this point and come up with hundreds of use cases for AI and bring a industry and function agnostic approach to workflow redesign and just focus on where can AI support the where can AI best support workflows regardless of the team, the function and the industry",
    "source_transcript": "transcripts_normalized/Asurion x Section 2025-07-24 12_37 transcript.json",
    "source_date": "2025-07-24"
  },
  {
    "name": "Survey-Driven Assessment Framework",
    "type": "measurement_framework",
    "confidence": 0.8,
    "description": "Using broad organizational survey response to gather insights and inform AI transformation strategy",
    "components": [
      "Survey deployment across organization",
      "Response rate tracking (935 responses achieved)",
      "Insights extraction and readout sessions",
      "Findings inform transformation planning"
    ],
    "evidence_quote": "I wanted to give a brief update on the survey response. It closed this morning, so we are sitting at a final number of 935. So that would be great to pull a lot of insights from with that... I'll follow up with you after this call so we can try and get some readouts scheduled",
    "source_transcript": "transcripts_normalized/Asurion x Section 2025-07-24 12_37 transcript.json",
    "source_date": "2025-07-24"
  },
  {
    "name": "Three-Category Use Case Prioritization Framework",
    "type": "model_framework",
    "confidence": 0.92,
    "description": "A categorization model for AI use cases based on implementation readiness and complexity, dividing opportunities into three buckets to guide resource allocation and next steps",
    "components": [
      "Category 1: Justifies further refinement (requires more discovery)",
      "Category 2: Can be prototyped now in GPT (ready for immediate pilot)",
      "Category 3: Requires IT or vendor involvement (technical dependencies)"
    ],
    "evidence_quote": "he basically put them into three categories. One was like yeah, justifies further refinement. One was like can be prototyped now in. In GPT essentially they didn't have GPT so it's easier for you guys. And one was like requires like either it or a vendor.",
    "source_transcript": "transcripts_normalized/Asurion Brainstorm 2025-09-19 12_02 transcript.json",
    "source_date": "2025-09-19"
  },
  {
    "name": "Discovery-to-Pilot Process Framework",
    "type": "process_framework",
    "confidence": 0.88,
    "description": "A phased approach starting with discovery interviews, followed by prioritization, and culminating in detailed specifications for top use cases before moving to pilot phase",
    "components": [
      "Step 1: Conduct stakeholder interviews (e.g., 10 interviews)",
      "Step 2: Create prioritized list of use cases based on impact and feasibility",
      "Step 3: Develop one-slide specifications for top 5 use cases",
      "Step 4: Define next steps/prototyping approach for each prioritized use case",
      "Step 5: Move to AI use case development and pilot"
    ],
    "evidence_quote": "we definitely have more of a challenge once we get to AI use case development and pilot. But it feels pretty clear that they need the discovery piece which would culminate in. And I think you could. I think we could make that a little less complicated for ourselves by just like the output of that is the top. A prioritized list. The things we prioritize based on impact, feasibility, whatever. And then like a one slide on each.",
    "source_transcript": "transcripts_normalized/Asurion Brainstorm 2025-09-19 12_02 transcript.json",
    "source_date": "2025-09-19"
  },
  {
    "name": "Show Don't Tell Engagement Framework",
    "type": "engagement_framework",
    "confidence": 0.85,
    "description": "An approach to overcome client resistance by demonstrating methodology on a single function rather than debating approach, used when clients believe they've already done discovery work",
    "components": [
      "Select one function as demonstration target",
      "Execute proper discovery methodology on that function",
      "Deliver concrete example output to show quality difference",
      "Use results to gain buy-in for broader rollout"
    ],
    "evidence_quote": "So I think there we could propose that but for one function and just kind of ignore like I wonder show them what they would. What you would do kind of exactly like",
    "source_transcript": "transcripts_normalized/Asurion Brainstorm 2025-09-19 12_02 transcript.json",
    "source_date": "2025-09-19"
  },
  {
    "name": "Divide and Conquer Engagement Framework",
    "type": "engagement_framework",
    "confidence": 0.83,
    "description": "A parallel workstream approach for working with overwhelmed clients, splitting functions between consultant and client teams to maintain momentum while demonstrating methodology",
    "components": [
      "Identify that client team is underwater/overwhelmed",
      "Propose splitting functions or workstreams",
      "Consultant takes one function to execute properly",
      "Client takes another function with their approach",
      "Compare results to demonstrate value of methodology"
    ],
    "evidence_quote": "let us just like, take a stab at this and come. Not take a stab at this, but like, let us do this and come back. Or do they want to also be. Because the other thing you could do is kind of do a bit with them of like, listen, guys, like, you're underwater. Let's divide and conquer. Why don't we take this function and you take this function",
    "source_transcript": "transcripts_normalized/Asurion Brainstorm 2025-09-19 12_02 transcript.json",
    "source_date": "2025-09-19"
  },
  {
    "name": "Three-Option Decision Framework",
    "type": "decision_framework",
    "confidence": 0.75,
    "description": "A decision approach for projects with unclear scope completion, presenting three pathways forward based on whether to continue with existing participants or start fresh",
    "components": [
      "Option 1: Let existing groups continue independently and start new cohort",
      "Option 2: [Implied - work with existing seven teams]",
      "Option 3: [Implied - different approach to be defined]"
    ],
    "evidence_quote": "I think that I sort of see three options from moving forward. One is we. Because it's still a little unclear to me if they've done. I know we talked to seven teams but is that everybody? One is that we like to just let those seven teams sort of do their thing and we start a new group of people.",
    "source_transcript": "transcripts_normalized/Asurion Brainstorm 2025-09-19 12_02 transcript.json",
    "source_date": "2025-09-19"
  },
  {
    "name": "AI Tool Adoption Gating Framework",
    "type": "decision_framework",
    "confidence": 0.95,
    "description": "Decision logic for determining which AI tools employees can use based on enterprise agreements, security requirements, and IT approval",
    "components": [
      "Enterprise agreement acquisition required",
      "NDA and vendor agreements in place",
      "Secure ID connector configuration",
      "IT team approval and provisioning",
      "Prohibition of unauthorized tools"
    ],
    "evidence_quote": "our AI policy is you can use it as long as we provide you an account. This doesn't mean that you can sign up with your General Catalyst account... We need to acquire the enterprise agreement because we also have an NDA and other agreements in place with the company... extremely forbidden to use tools that we did not provide you",
    "source_transcript": "transcripts_normalized/Kyra __ Jose_ GC AI Tools Chat 2025-09-19 16_02 transcript.json",
    "source_date": "2025-09-19"
  },
  {
    "name": "Make Platform Onboarding Process",
    "type": "process_framework",
    "confidence": 0.92,
    "description": "Step-by-step methodology for onboarding users to the Make automation platform",
    "components": [
      "User requests access to Make",
      "Schedule onboarding session with IT",
      "Guide through base principles of Make",
      "Understand user's intended use case",
      "Set up user to start working",
      "Iterative troubleshooting as user encounters limitations"
    ],
    "evidence_quote": "Whenever the request make, they will go through an onboarding session with me, I will get on a call, call with them and we'll guide them through the base principles of make and I will try to get out of them what they're trying to build and set them up on their way. My goal is to set them so they can start working and complaining about what they cannot do",
    "source_transcript": "transcripts_normalized/Kyra __ Jose_ GC AI Tools Chat 2025-09-19 16_02 transcript.json",
    "source_date": "2025-09-19"
  },
  {
    "name": "AI Tool Rollout Scaling Framework",
    "type": "scaling_framework",
    "confidence": 0.9,
    "description": "Phased approach to rolling out new AI tools from pilot group to company-wide deployment",
    "components": [
      "Identify highest-need user group (investors)",
      "Deploy to pilot group first",
      "Vet and validate proper functionality",
      "Roll out to rest of company after validation"
    ],
    "evidence_quote": "at the beginning it will only be the investors because they are the one who needed the most. And then once is, you know, vetted, working properly is going to be laid out to the rest of the company",
    "source_transcript": "transcripts_normalized/Kyra __ Jose_ GC AI Tools Chat 2025-09-19 16_02 transcript.json",
    "source_date": "2025-09-19"
  },
  {
    "name": "AI Policy Communication Framework",
    "type": "engagement_framework",
    "confidence": 0.88,
    "description": "Multi-channel approach to ensuring stakeholder awareness of AI policies and tools",
    "components": [
      "Multiple training sessions",
      "Company-wide broadcasts",
      "Town hall announcements",
      "Ongoing reinforcement campaigns",
      "IT team as point of contact for questions"
    ],
    "evidence_quote": "everybody is aware that we have done several training sessions and we continue to do them. We will continue to elaborate. This message has been widely broadcasted across the company, even in the town hall meeting",
    "source_transcript": "transcripts_normalized/Kyra __ Jose_ GC AI Tools Chat 2025-09-19 16_02 transcript.json",
    "source_date": "2025-09-19"
  },
  {
    "name": "Workshop Content Structure Framework",
    "type": "model_framework",
    "confidence": 0.85,
    "description": "Two-part workshop model for AI training consisting of foundational education followed by practical application",
    "components": [
      "Part 1: LLM fundamentals and prompting basics",
      "Part 2: Tool-specific guidance and use cases",
      "Comparative analysis of available tools",
      "Context-specific tool recommendations"
    ],
    "evidence_quote": "Basically the first half of this is going to be setting people up for, you know, this is how you use an LLM. This is how to prompt. Here are some use cases that you should be thinking about and so I'll review for them the different tools that you all have access to and just some use cases of, you know, here's how you might leverage NotebookLM versus Claude versus ChatGPT versus Gemini",
    "source_transcript": "transcripts_normalized/Kyra __ Jose_ GC AI Tools Chat 2025-09-19 16_02 transcript.json",
    "source_date": "2025-09-19"
  }
]